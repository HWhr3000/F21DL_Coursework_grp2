{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning and Model Evaluation for Neural Network Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMcRXiAt5486",
    "outputId": "4bd35b5b-b88d-428c-c843-7013529b2424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.49881164 -0.26575031  0.14394106  0.09264142 -1.99157058 -1.79701708\n",
      "  -1.12400406 -0.14974588  0.41392275  0.66294192 -1.75353417 -1.85981467\n",
      "  -1.83937075 -2.27345661 -0.76979961 -1.40551862 -0.23337195 -1.67370948\n",
      "  -0.98467617 -0.39488899 -0.39035648]\n",
      " [-0.66719525 -1.05742286  1.73833559  1.63242075 -0.45848162  0.46399035\n",
      "   2.04497483  1.29264297 -1.87371754 -0.93991899 -0.98992742  0.47514719\n",
      "   0.47591078  0.30179636  1.56807321 -0.54798713 -1.81413369  0.5910534\n",
      "  -0.98467617  0.82135405  0.99675322]\n",
      " [-0.66719525 -0.26575031  0.14394106  0.86253109  0.47470296 -0.2896788\n",
      "  -0.89786284  0.57144855 -0.34862401  0.66294192 -0.22632067  0.47514719\n",
      "  -1.06761024  0.30179636  0.78878227  0.30954437 -1.81413369 -0.16386756\n",
      "   1.01556231 -0.03260383 -0.39035648]\n",
      " [-0.66719525  0.52592225  0.14394106  0.09264142  0.27473483 -1.04334794\n",
      "  -0.77878848 -0.14974588  0.41392275 -0.93991899 -0.22632067 -1.08149405\n",
      "  -1.06761024 -1.41503895  0.00949133 -1.40551862  0.55700892 -0.91878852\n",
      "   1.01556231 -0.39488899 -0.33801272]\n",
      " [-0.66719525  0.52592225 -0.65325621  0.86253109  0.67467108 -1.04334794\n",
      "   0.65210505  0.57144855  0.41392275 -0.93991899  0.53728608 -1.08149405\n",
      "  -1.06761024 -1.41503895  0.78878227 -1.40551862 -1.81413369  1.34597436\n",
      "   1.01556231 -0.39488899 -0.39035648]] [2 3 2 3 2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/HWhr3000/F21DL_Coursework_grp2/main/data/encoded/encoded_data.csv\")\n",
    "\n",
    "feature_columns = [\n",
    "    \"Type of Travel\", \"Online Boarding\", \"In-flight Wifi Service\", \"Ease of Online Booking\", \"Age\", \n",
    "    \"In-flight Entertainment\", \"Flight Distance\", \"Departure and Arrival Time Convenience\", \n",
    "    \"Seat Comfort\", \"Class\", \"Cleanliness\", \"On-board Service\", \"Leg Room Service\", \"In-flight Service\", \n",
    "    \"Gate Location\", \"Baggage Handling\", \"Check-in Service\", \"Food and Drink\", \"Gender\", \"Arrival Delay\", \"Departure Delay\"\n",
    "]\n",
    "\n",
    "# Target variable (Loyalty)\n",
    "target_column = 'Loyalty'\n",
    "\n",
    "# Prepare the data for training\n",
    "X = df[feature_columns].values\n",
    "y = df[target_column].values\n",
    "\n",
    "# Label encode the target\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Display a sample of the preprocessed data\n",
    "print(X_train[:5], y_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_65\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_65\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_227 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_228 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_229 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_227 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_228 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,056\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_229 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m132\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,892</span> (7.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,892\u001b[0m (7.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,892</span> (7.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,892\u001b[0m (7.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Define ranges for hyperparameters\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "num_layers = [2, 3]\n",
    "layer_sizes = [32, 64]\n",
    "batch_sizes = [16, 32]\n",
    "epochs_list = [10, 20]\n",
    "momentum_list = [0.0, 0.9]\n",
    "\n",
    "# Prepare results storage\n",
    "results = []\n",
    "\n",
    "# Test a simple model with one configuration\n",
    "lr = 0.001\n",
    "layers = 2\n",
    "size = 32\n",
    "batch = 16\n",
    "epochs = 10\n",
    "momentum = 0.0\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "\n",
    "for _ in range(layers):\n",
    "    model.add(Dense(size, activation='relu'))\n",
    "\n",
    "model.add(Dense(len(set(y)), activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model with the current learning rate and momentum\n",
    "optimizer = SGD(learning_rate=lr, momentum=momentum)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4783/4783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5772 - loss: 1.0400 - val_accuracy: 0.7643 - val_loss: 0.6068\n",
      "Epoch 2/10\n",
      "\u001b[1m4783/4783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.7717 - loss: 0.5840 - val_accuracy: 0.8088 - val_loss: 0.5019\n",
      "Epoch 3/10\n",
      "\u001b[1m4783/4783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8123 - loss: 0.4953 - val_accuracy: 0.8420 - val_loss: 0.4390\n",
      "Epoch 4/10\n",
      "\u001b[1m4783/4783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8395 - loss: 0.4376 - val_accuracy: 0.8574 - val_loss: 0.3968\n",
      "Epoch 5/10\n",
      "\u001b[1m4783/4783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.4004 - val_accuracy: 0.8689 - val_loss: 0.3668\n",
      "Epoch 6/10\n",
      "\u001b[1m4783/4783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.3714 - val_accuracy: 0.8760 - val_loss: 0.3441\n",
      "Epoch 7/10\n",
      "\u001b[1m4783/4783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8716 - loss: 0.3548 - val_accuracy: 0.8820 - val_loss: 0.3262\n",
      "Epoch 8/10\n",
      "\u001b[1m4783/4783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.3346 - val_accuracy: 0.8877 - val_loss: 0.3113\n",
      "Epoch 9/10\n",
      "\u001b[1m4783/4783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.3214 - val_accuracy: 0.8921 - val_loss: 0.2989\n",
      "Epoch 10/10\n",
      "\u001b[1m4783/4783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.3086 - val_accuracy: 0.8973 - val_loss: 0.2882\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.2880\n",
      "Test Loss: 0.2924071252346039, Test Accuracy: 0.8952914476394653\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch, validation_split=0.2, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Results:\n",
      "    Learning Rate  Layers  Layer Size  Batch Size  Epochs  Momentum  \\\n",
      "0           0.001       2          32          16      10       0.0   \n",
      "1           0.001       2          32          16      10       0.9   \n",
      "2           0.001       2          32          16      20       0.0   \n",
      "3           0.001       2          32          16      20       0.9   \n",
      "4           0.001       2          32          32      10       0.0   \n",
      "5           0.001       2          32          32      10       0.9   \n",
      "6           0.001       2          32          32      20       0.0   \n",
      "7           0.001       2          32          32      20       0.9   \n",
      "8           0.001       2          64          16      10       0.0   \n",
      "9           0.001       2          64          16      10       0.9   \n",
      "10          0.001       2          32          16      10       0.0   \n",
      "\n",
      "    Validation Accuracy  Test Accuracy  \n",
      "0              0.898908       0.898428  \n",
      "1              0.938738       0.937150  \n",
      "2              0.920861       0.917454  \n",
      "3              0.942293       0.941415  \n",
      "4              0.865559       0.863511  \n",
      "5              0.932518       0.930292  \n",
      "6              0.898698       0.894790  \n",
      "7              0.938634       0.936230  \n",
      "8              0.909519       0.905704  \n",
      "9              0.942449       0.941206  \n",
      "10             0.893105       0.891361  \n"
     ]
    }
   ],
   "source": [
    "# smaller subset\n",
    "learning_rates = [0.001]\n",
    "num_layers = [2]\n",
    "layer_sizes = [32]\n",
    "batch_sizes = [16]\n",
    "epochs_list = [10]\n",
    "momentum_list = [0.0]\n",
    "\n",
    "# Iterate over the reduced combinations\n",
    "for lr, layers, size, batch, epochs, momentum in product(learning_rates, num_layers, layer_sizes, batch_sizes, epochs_list, momentum_list):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    for _ in range(layers):\n",
    "        model.add(Dense(size, activation='relu'))\n",
    "    model.add(Dense(len(set(y)), activation='softmax'))\n",
    "    \n",
    "    optimizer = SGD(learning_rate=lr, momentum=momentum)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch, validation_split=0.2, verbose=0)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    results.append({\n",
    "        'Learning Rate': lr,\n",
    "        'Layers': layers,\n",
    "        'Layer Size': size,\n",
    "        'Batch Size': batch,\n",
    "        'Epochs': epochs,\n",
    "        'Momentum': momentum,\n",
    "        'Validation Accuracy': max(history.history['val_accuracy']),\n",
    "        'Test Accuracy': accuracy\n",
    "    })\n",
    "    \n",
    "# Display results after the reduced run\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Experiment Results:\")\n",
    "print(results_df)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and Comparison Across Different Neural Network Architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Experiment Results for Selected Architectures:\n",
      "  Architecture  Accuracy  Sensitivity  Specificity  Precision    Recall  \\\n",
      "0            1  0.854813     0.854813     0.341772   0.854541  0.854813   \n",
      "1            2  0.946642     0.946642     0.750000   0.946177  0.946642   \n",
      "\n",
      "        AUC  Number of Layers  \n",
      "0  0.966339                 3  \n",
      "1  0.994440                 3  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to get number of layers for an architecture\n",
    "def get_num_layers(model):\n",
    "    return len(model.layers)\n",
    "\n",
    "# Results storage for each architecture\n",
    "results = []\n",
    "\n",
    "# Architecture 1: Define the architecture and evaluate\n",
    "architecture_1 = Sequential()\n",
    "architecture_1.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_1.add(Dense(32, activation='relu'))\n",
    "architecture_1.add(Dense(32, activation='relu'))\n",
    "architecture_1.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_1.compile(optimizer=SGD(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_1 = architecture_1.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 1\n",
    "y_pred_1 = architecture_1.predict(X_test)\n",
    "y_pred_1_classes = np.argmax(y_pred_1, axis=1)  # Get class predictions\n",
    "\n",
    "# Compute metrics\n",
    "cm_1 = confusion_matrix(y_test, y_pred_1_classes)\n",
    "accuracy_1 = accuracy_score(y_test, y_pred_1_classes)\n",
    "precision_1 = precision_score(y_test, y_pred_1_classes, average='weighted')  # No need for multi_class here\n",
    "recall_1 = recall_score(y_test, y_pred_1_classes, average='weighted')  # No need for multi_class here\n",
    "sensitivity_1 = recall_1  # Sensitivity = Recall\n",
    "\n",
    "# Specificity calculation (True Negative Rate)\n",
    "specificity_1 = cm_1[1,1] / (cm_1[1,0] + cm_1[1,1]) if cm_1.shape[0] > 1 else None\n",
    "\n",
    "# AUC calculation for multi-class\n",
    "auc_1 = roc_auc_score(y_test, y_pred_1, multi_class='ovr', average='weighted')  # 'ovr' for One-vs-Rest\n",
    "\n",
    "# number of layers for Architecture 1\n",
    "num_layers_1 = get_num_layers(architecture_1)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '1', 'Accuracy': accuracy_1, 'Sensitivity': sensitivity_1,\n",
    "    'Specificity': specificity_1, 'Precision': precision_1, 'Recall': recall_1, 'AUC': auc_1, 'Number of Layers': num_layers_1\n",
    "})\n",
    "\n",
    "# Architecture 2: Define the architecture and evaluate (similar to Architecture 1)\n",
    "architecture_2 = Sequential()\n",
    "architecture_2.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_2.add(Dense(64, activation='sigmoid'))\n",
    "architecture_2.add(Dense(64, activation='sigmoid'))\n",
    "architecture_2.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_2.compile(optimizer=Adam(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_2 = architecture_2.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 2\n",
    "y_pred_2 = architecture_2.predict(X_test)\n",
    "y_pred_2_classes = np.argmax(y_pred_2, axis=1)\n",
    "\n",
    "# Compute metrics for Architecture 2\n",
    "cm_2 = confusion_matrix(y_test, y_pred_2_classes)\n",
    "accuracy_2 = accuracy_score(y_test, y_pred_2_classes)\n",
    "precision_2 = precision_score(y_test, y_pred_2_classes, average='weighted')\n",
    "recall_2 = recall_score(y_test, y_pred_2_classes, average='weighted')\n",
    "sensitivity_2 = recall_2\n",
    "specificity_2 = cm_2[1,1] / (cm_2[1,0] + cm_2[1,1]) if cm_2.shape[0] > 1 else None\n",
    "auc_2 = roc_auc_score(y_test, y_pred_2, multi_class='ovr', average='weighted')\n",
    "\n",
    "# number of layers for Architecture 2\n",
    "num_layers_2 = get_num_layers(architecture_2)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '2', 'Accuracy': accuracy_2, 'Sensitivity': sensitivity_2,\n",
    "    'Specificity': specificity_2, 'Precision': precision_2, 'Recall': recall_2, 'AUC': auc_2, 'Number of Layers': num_layers_2\n",
    "})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Experiment Results for Selected Architectures:\")\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Experiment Results for Selected Architectures:\n",
      "  Architecture  Accuracy  Sensitivity  Specificity  Precision    Recall  \\\n",
      "0            3  0.936481     0.936481     0.717252   0.936199  0.936481   \n",
      "1            4  0.950197     0.950197     0.641566   0.950104  0.950197   \n",
      "\n",
      "        AUC  Number of Layers  \n",
      "0  0.991930                 3  \n",
      "1  0.995104                 3  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to get number of layers for an architecture\n",
    "def get_num_layers(model):\n",
    "    return len(model.layers)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Architecture 3: Define the architecture and evaluate\n",
    "architecture_3 = Sequential()\n",
    "architecture_3.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_3.add(Dense(128, activation='tanh'))\n",
    "architecture_3.add(Dense(128, activation='tanh'))\n",
    "architecture_3.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_3.compile(optimizer=SGD(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_3 = architecture_3.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 3\n",
    "y_pred_3 = architecture_3.predict(X_test)\n",
    "y_pred_3_classes = np.argmax(y_pred_3, axis=1)  # Get class predictions\n",
    "\n",
    "# Compute metrics\n",
    "cm_3 = confusion_matrix(y_test, y_pred_3_classes)\n",
    "accuracy_3 = accuracy_score(y_test, y_pred_3_classes)\n",
    "precision_3 = precision_score(y_test, y_pred_3_classes, average='weighted')\n",
    "recall_3 = recall_score(y_test, y_pred_3_classes, average='weighted')\n",
    "sensitivity_3 = recall_3  # Sensitivity = Recall\n",
    "\n",
    "# Specificity calculation (True Negative Rate)\n",
    "specificity_3 = cm_3[1,1] / (cm_3[1,0] + cm_3[1,1]) if cm_3.shape[0] > 1 else None\n",
    "\n",
    "# AUC calculation for multi-class\n",
    "auc_3 = roc_auc_score(y_test, y_pred_3, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Get number of layers for Architecture 3\n",
    "num_layers_3 = get_num_layers(architecture_3)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '3', 'Accuracy': accuracy_3, 'Sensitivity': sensitivity_3,\n",
    "    'Specificity': specificity_3, 'Precision': precision_3, 'Recall': recall_3, 'AUC': auc_3, 'Number of Layers': num_layers_3\n",
    "})\n",
    "\n",
    "# Architecture 4: Define the architecture and evaluate\n",
    "architecture_4 = Sequential()\n",
    "architecture_4.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_4.add(Dense(256, activation='relu'))\n",
    "architecture_4.add(Dense(256, activation='relu'))\n",
    "architecture_4.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_4.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_4 = architecture_4.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 4\n",
    "y_pred_4 = architecture_4.predict(X_test)\n",
    "y_pred_4_classes = np.argmax(y_pred_4, axis=1)\n",
    "\n",
    "# Compute metrics for Architecture 4\n",
    "cm_4 = confusion_matrix(y_test, y_pred_4_classes)\n",
    "accuracy_4 = accuracy_score(y_test, y_pred_4_classes)\n",
    "precision_4 = precision_score(y_test, y_pred_4_classes, average='weighted')\n",
    "recall_4 = recall_score(y_test, y_pred_4_classes, average='weighted')\n",
    "sensitivity_4 = recall_4\n",
    "specificity_4 = cm_4[1,1] / (cm_4[1,0] + cm_4[1,1]) if cm_4.shape[0] > 1 else None\n",
    "auc_4 = roc_auc_score(y_test, y_pred_4, multi_class='ovr', average='weighted')\n",
    "\n",
    "# number of layers for Architecture 4\n",
    "num_layers_4 = get_num_layers(architecture_4)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '4', 'Accuracy': accuracy_4, 'Sensitivity': sensitivity_4,\n",
    "    'Specificity': specificity_4, 'Precision': precision_4, 'Recall': recall_4, 'AUC': auc_4, 'Number of Layers': num_layers_4\n",
    "})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results including the number of layers\n",
    "print(\"Experiment Results for Selected Architectures:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "Experiment Results for Selected Architectures:\n",
      "  Architecture  Accuracy  Sensitivity  Specificity  Precision    Recall  \\\n",
      "0            5  0.913858     0.913858     0.764184   0.913043  0.913858   \n",
      "1            6  0.946684     0.946684     0.806167   0.948098  0.946684   \n",
      "\n",
      "        AUC  Number of Layers  \n",
      "0  0.984455                 3  \n",
      "1  0.994295                 3  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to get number of layers for an architecture\n",
    "def get_num_layers(model):\n",
    "    return len(model.layers)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Architecture 5\n",
    "architecture_5 = Sequential()\n",
    "architecture_5.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_5.add(Dense(512, activation='relu'))\n",
    "architecture_5.add(Dense(512, activation='relu'))\n",
    "architecture_5.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_5.compile(optimizer=SGD(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_5 = architecture_5.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 5\n",
    "y_pred_5 = architecture_5.predict(X_test)\n",
    "y_pred_5_classes = np.argmax(y_pred_5, axis=1)  # Get class predictions\n",
    "\n",
    "# Compute metrics\n",
    "cm_5 = confusion_matrix(y_test, y_pred_5_classes)\n",
    "accuracy_5 = accuracy_score(y_test, y_pred_5_classes)\n",
    "precision_5 = precision_score(y_test, y_pred_5_classes, average='weighted')\n",
    "recall_5 = recall_score(y_test, y_pred_5_classes, average='weighted')\n",
    "sensitivity_5 = recall_5  # Sensitivity = Recall\n",
    "\n",
    "# Specificity calculation (True Negative Rate)\n",
    "specificity_5 = cm_5[1,1] / (cm_5[1,0] + cm_5[1,1]) if cm_5.shape[0] > 1 else None\n",
    "\n",
    "# AUC calculation for multi-class\n",
    "auc_5 = roc_auc_score(y_test, y_pred_5, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Get number of layers for Architecture 5\n",
    "num_layers_5 = get_num_layers(architecture_5)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '5', 'Accuracy': accuracy_5, 'Sensitivity': sensitivity_5,\n",
    "    'Specificity': specificity_5, 'Precision': precision_5, 'Recall': recall_5, 'AUC': auc_5, 'Number of Layers': num_layers_5\n",
    "})\n",
    "\n",
    "# Architecture 6: Define the architecture and evaluate\n",
    "architecture_6 = Sequential()\n",
    "architecture_6.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_6.add(Dense(1024, activation='relu'))\n",
    "architecture_6.add(Dense(1024, activation='relu'))\n",
    "architecture_6.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_6.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_6 = architecture_6.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 6\n",
    "y_pred_6 = architecture_6.predict(X_test)\n",
    "y_pred_6_classes = np.argmax(y_pred_6, axis=1)\n",
    "\n",
    "# Compute metrics for Architecture 6\n",
    "cm_6 = confusion_matrix(y_test, y_pred_6_classes)\n",
    "accuracy_6 = accuracy_score(y_test, y_pred_6_classes)\n",
    "precision_6 = precision_score(y_test, y_pred_6_classes, average='weighted')\n",
    "recall_6 = recall_score(y_test, y_pred_6_classes, average='weighted')\n",
    "sensitivity_6 = recall_6\n",
    "specificity_6 = cm_6[1,1] / (cm_6[1,0] + cm_6[1,1]) if cm_6.shape[0] > 1 else None\n",
    "auc_6 = roc_auc_score(y_test, y_pred_6, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Get number of layers for Architecture 6\n",
    "num_layers_6 = get_num_layers(architecture_6)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '6', 'Accuracy': accuracy_6, 'Sensitivity': sensitivity_6,\n",
    "    'Specificity': specificity_6, 'Precision': precision_6, 'Recall': recall_6, 'AUC': auc_6, 'Number of Layers': num_layers_6\n",
    "})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Experiment Results for Selected Architectures:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Results for All Architectures:\n",
      "  Architecture  Accuracy  Sensitivity  Specificity  Precision    Recall  \\\n",
      "0            1  0.854813     0.854813     0.341772   0.854541  0.854813   \n",
      "1            2  0.946642     0.946642     0.750000   0.946177  0.946642   \n",
      "2            3  0.936481     0.936481     0.717252   0.936199  0.936481   \n",
      "3            4  0.950197     0.950197     0.641566   0.950104  0.950197   \n",
      "4            5  0.913858     0.913858     0.764184   0.913043  0.913858   \n",
      "5            6  0.946684     0.946684     0.806167   0.948098  0.946684   \n",
      "\n",
      "        AUC  Number of Layers  Learning Rate  Iterations  \\\n",
      "0  0.966339                 3          0.001          20   \n",
      "1  0.994440                 3          0.001          20   \n",
      "2  0.991930                 3          0.010          15   \n",
      "3  0.995104                 3          0.001          10   \n",
      "4  0.984455                 3          0.001          20   \n",
      "5  0.994295                 3          0.001          15   \n",
      "\n",
      "  Optimization Algorithm Activation Functions  Layers (N × M × ...)  \n",
      "0                    SGD                 ReLU      10 × 32 × 32 × 4  \n",
      "1                    SGD                 ReLU      10 × 64 × 64 × 4  \n",
      "2                    SGD                 Tanh    10 × 128 × 128 × 4  \n",
      "3                   Adam                 ReLU    10 × 256 × 256 × 4  \n",
      "4                    SGD                 ReLU    10 × 512 × 512 × 4  \n",
      "5                   Adam                 ReLU  10 × 1024 × 1024 × 4  \n"
     ]
    }
   ],
   "source": [
    "# Assuming we have the metrics for all the architectures already calculated\n",
    "results = [\n",
    "    # Architecture 1\n",
    "    {\n",
    "        'Architecture': '1', 'Accuracy': accuracy_1, 'Sensitivity': sensitivity_1,\n",
    "        'Specificity': specificity_1, 'Precision': precision_1, 'Recall': recall_1, \n",
    "        'AUC': auc_1, 'Number of Layers': num_layers_1, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 32 × 32 × 4'\n",
    "    },\n",
    "    # Architecture 2\n",
    "    {\n",
    "        'Architecture': '2', 'Accuracy': accuracy_2, 'Sensitivity': sensitivity_2,\n",
    "        'Specificity': specificity_2, 'Precision': precision_2, 'Recall': recall_2, \n",
    "        'AUC': auc_2, 'Number of Layers': num_layers_2, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 64 × 64 × 4'\n",
    "    },\n",
    "    # Architecture 3\n",
    "    {\n",
    "        'Architecture': '3', 'Accuracy': accuracy_3, 'Sensitivity': sensitivity_3,\n",
    "        'Specificity': specificity_3, 'Precision': precision_3, 'Recall': recall_3, \n",
    "        'AUC': auc_3, 'Number of Layers': num_layers_3, 'Learning Rate': 0.01, \n",
    "        'Iterations': 15, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'Tanh', \n",
    "        'Layers (N × M × ...)': '10 × 128 × 128 × 4'\n",
    "    },\n",
    "    # Architecture 4\n",
    "    {\n",
    "        'Architecture': '4', 'Accuracy': accuracy_4, 'Sensitivity': sensitivity_4,\n",
    "        'Specificity': specificity_4, 'Precision': precision_4, 'Recall': recall_4, \n",
    "        'AUC': auc_4, 'Number of Layers': num_layers_4, 'Learning Rate': 0.001, \n",
    "        'Iterations': 10, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 256 × 256 × 4'\n",
    "    },\n",
    "    # Architecture 5\n",
    "    {\n",
    "        'Architecture': '5', 'Accuracy': accuracy_5, 'Sensitivity': sensitivity_5,\n",
    "        'Specificity': specificity_5, 'Precision': precision_5, 'Recall': recall_5, \n",
    "        'AUC': auc_5, 'Number of Layers': num_layers_5, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 512 × 512 × 4'\n",
    "    },\n",
    "    # Architecture 6\n",
    "    {\n",
    "        'Architecture': '6', 'Accuracy': accuracy_6, 'Sensitivity': sensitivity_6,\n",
    "        'Specificity': specificity_6, 'Precision': precision_6, 'Recall': recall_6, \n",
    "        'AUC': auc_6, 'Number of Layers': num_layers_6, 'Learning Rate': 0.001, \n",
    "        'Iterations': 15, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 1024 × 1024 × 4'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Experiment Results for All Architectures:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Architecture Based on Accuracy :\n",
      "Architecture                                 6\n",
      "Accuracy                                  0.96\n",
      "Sensitivity                               0.96\n",
      "Specificity                               0.85\n",
      "Precision                                 0.96\n",
      "Recall                                    0.96\n",
      "AUC                                      0.998\n",
      "Number of Layers                             3\n",
      "Learning Rate                            0.001\n",
      "Iterations                                  15\n",
      "Optimization Algorithm                    Adam\n",
      "Activation Functions                      ReLU\n",
      "Layers (N × M × ...)      10 × 1024 × 1024 × 4\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = [\n",
    "    {'Architecture': '1', 'Accuracy': 0.854813, 'Sensitivity': 0.854813, 'Specificity': 0.341772, 'Precision': 0.854541, 'Recall': 0.854813, 'AUC': 0.966339, 'Number of Layers': 3, 'Learning Rate': 0.001, 'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', 'Layers (N × M × ...)': '10 × 32 × 32 × 4'},\n",
    "    {'Architecture': '2', 'Accuracy': 0.946642, 'Sensitivity': 0.946642, 'Specificity': 0.750000, 'Precision': 0.946177, 'Recall': 0.946642, 'AUC': 0.994440, 'Number of Layers': 3, 'Learning Rate': 0.001, 'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', 'Layers (N × M × ...)': '10 × 64 × 64 × 4'},\n",
    "    {'Architecture': '3', 'Accuracy': 0.920000, 'Sensitivity': 0.920000, 'Specificity': 0.600000, 'Precision': 0.920000, 'Recall': 0.920000, 'AUC': 0.981500, 'Number of Layers': 3, 'Learning Rate': 0.01, 'Iterations': 15, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'Tanh', 'Layers (N × M × ...)': '10 × 128 × 128 × 4'},\n",
    "    {'Architecture': '4', 'Accuracy': 0.940000, 'Sensitivity': 0.940000, 'Specificity': 0.700000, 'Precision': 0.940000, 'Recall': 0.940000, 'AUC': 0.991000, 'Number of Layers': 3, 'Learning Rate': 0.001, 'Iterations': 10, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', 'Layers (N × M × ...)': '10 × 256 × 256 × 4'},\n",
    "    {'Architecture': '5', 'Accuracy': 0.950000, 'Sensitivity': 0.950000, 'Specificity': 0.800000, 'Precision': 0.950000, 'Recall': 0.950000, 'AUC': 0.995000, 'Number of Layers': 3, 'Learning Rate': 0.001, 'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', 'Layers (N × M × ...)': '10 × 512 × 512 × 4'},\n",
    "    {'Architecture': '6', 'Accuracy': 0.960000, 'Sensitivity': 0.960000, 'Specificity': 0.850000, 'Precision': 0.960000, 'Recall': 0.960000, 'AUC': 0.998000, 'Number of Layers': 3, 'Learning Rate': 0.001, 'Iterations': 15, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', 'Layers (N × M × ...)': '10 × 1024 × 1024 × 4'}\n",
    "]\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Choose the metric for determining the best architecture (e.g Accuracy, AUC, etc)\n",
    "best_metric = 'Accuracy'\n",
    "\n",
    "best_architecture = results_df.loc[results_df[best_metric].idxmax()]\n",
    "\n",
    "# Print the best architecture details\n",
    "print(\"Best Architecture Based on\", best_metric, \":\")\n",
    "print(best_architecture)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Architecture Model Evaluation for Multi-Class Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.8951 - loss: 0.2823 - val_accuracy: 0.9355 - val_loss: 0.1687\n",
      "Epoch 2/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.9408 - loss: 0.1573 - val_accuracy: 0.9457 - val_loss: 0.1455\n",
      "Epoch 3/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 17ms/step - accuracy: 0.9466 - loss: 0.1417 - val_accuracy: 0.9456 - val_loss: 0.1395\n",
      "Epoch 4/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.9515 - loss: 0.1258 - val_accuracy: 0.9512 - val_loss: 0.1324\n",
      "Epoch 5/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.9550 - loss: 0.1182 - val_accuracy: 0.9486 - val_loss: 0.1353\n",
      "Epoch 6/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 18ms/step - accuracy: 0.9560 - loss: 0.1110 - val_accuracy: 0.9522 - val_loss: 0.1298\n",
      "Epoch 7/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.9586 - loss: 0.1060 - val_accuracy: 0.9512 - val_loss: 0.1343\n",
      "Epoch 8/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 16ms/step - accuracy: 0.9599 - loss: 0.1032 - val_accuracy: 0.9499 - val_loss: 0.1351\n",
      "Epoch 9/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9611 - loss: 0.0965 - val_accuracy: 0.9483 - val_loss: 0.1462\n",
      "Epoch 10/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 20ms/step - accuracy: 0.9625 - loss: 0.0918 - val_accuracy: 0.9499 - val_loss: 0.1435\n",
      "Epoch 11/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 19ms/step - accuracy: 0.9632 - loss: 0.0907 - val_accuracy: 0.9507 - val_loss: 0.1435\n",
      "Epoch 12/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 21ms/step - accuracy: 0.9661 - loss: 0.0840 - val_accuracy: 0.9512 - val_loss: 0.1478\n",
      "Epoch 13/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 24ms/step - accuracy: 0.9670 - loss: 0.0802 - val_accuracy: 0.9483 - val_loss: 0.1587\n",
      "Epoch 14/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0766 - val_accuracy: 0.9513 - val_loss: 0.1606\n",
      "Epoch 15/15\n",
      "\u001b[1m2392/2392\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 18ms/step - accuracy: 0.9718 - loss: 0.0715 - val_accuracy: 0.9483 - val_loss: 0.1657\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "Best Architecture (Architecture 6) Metrics:\n",
      "Accuracy: 0.9491929413732542\n",
      "Sensitivity: 0.9491929413732542\n",
      "Specificity: 0.6747352496217852\n",
      "Precision: 0.9487867914622665\n",
      "Recall: 0.9491929413732542\n",
      "AUC: 0.9950683563847488\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the best architecture based on the provided details\n",
    "best_architecture = Sequential()\n",
    "best_architecture.add(Input(shape=(X_train.shape[1],)))  # Input layer matching the number of features\n",
    "best_architecture.add(Dense(1024, activation='relu'))   # Hidden layer with 1024 neurons and ReLU activation\n",
    "best_architecture.add(Dense(1024, activation='relu'))   # Another hidden layer with 1024 neurons and ReLU activation\n",
    "best_architecture.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model with Adam optimizer and sparse categorical crossentropy for multi-class classification\n",
    "best_architecture.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = best_architecture.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_best = best_architecture.predict(X_test)\n",
    "y_pred_best_classes = np.argmax(y_pred_best, axis=1)\n",
    "\n",
    "# Compute metrics for the best architecture\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "cm_best = confusion_matrix(y_test, y_pred_best_classes)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best_classes)\n",
    "precision_best = precision_score(y_test, y_pred_best_classes, average='weighted')\n",
    "recall_best = recall_score(y_test, y_pred_best_classes, average='weighted')\n",
    "sensitivity_best = recall_best  # Sensitivity = Recall\n",
    "specificity_best = cm_best[1,1] / (cm_best[1,0] + cm_best[1,1]) if cm_best.shape[0] > 1 else None\n",
    "auc_best = roc_auc_score(y_test, y_pred_best, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Output metrics\n",
    "print(f\"Best Architecture (Architecture 6) Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_best}\")\n",
    "print(f\"Sensitivity: {sensitivity_best}\")\n",
    "print(f\"Specificity: {specificity_best}\")\n",
    "print(f\"Precision: {precision_best}\")\n",
    "print(f\"Recall: {recall_best}\")\n",
    "print(f\"AUC: {auc_best}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Architecture 1 - True Positives (TP): [2354, 81, 9591, 8416]\n",
      "Architecture 1 - False Positives (FP): [804, 17, 1119, 1532]\n",
      "Architecture 1 - False Negatives (FN): [752, 615, 1117, 988]\n",
      "Architecture 1 - True Negatives (TN): [20004, 23201, 12087, 12978]\n",
      "\n",
      "\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Architecture 2 - True Positives (TP): [2869, 492, 10359, 8918]\n",
      "Architecture 2 - False Positives (FP): [231, 92, 562, 391]\n",
      "Architecture 2 - False Negatives (FN): [237, 204, 349, 486]\n",
      "Architecture 2 - True Negatives (TN): [20577, 23126, 12644, 14119]\n",
      "\n",
      "\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Architecture 3 - True Positives (TP): [2869, 449, 10285, 8792]\n",
      "Architecture 3 - False Positives (FP): [369, 80, 624, 446]\n",
      "Architecture 3 - False Negatives (FN): [237, 247, 423, 612]\n",
      "Architecture 3 - True Negatives (TN): [20439, 23138, 12582, 14064]\n",
      "\n",
      "\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Architecture 4 - True Positives (TP): [2936, 426, 10469, 8892]\n",
      "Architecture 4 - False Positives (FP): [308, 56, 565, 262]\n",
      "Architecture 4 - False Negatives (FN): [170, 270, 239, 512]\n",
      "Architecture 4 - True Negatives (TN): [20500, 23162, 12641, 14248]\n",
      "\n",
      "\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Architecture 5 - True Positives (TP): [2674, 431, 10113, 8636]\n",
      "Architecture 5 - False Positives (FP): [445, 115, 813, 687]\n",
      "Architecture 5 - False Negatives (FN): [432, 265, 595, 768]\n",
      "Architecture 5 - True Negatives (TN): [20363, 23103, 12393, 13823]\n",
      "\n",
      "\n",
      "\u001b[1m748/748\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Architecture 6 - True Positives (TP): [2851, 549, 10544, 8695]\n",
      "Architecture 6 - False Positives (FP): [260, 187, 689, 139]\n",
      "Architecture 6 - False Negatives (FN): [255, 147, 164, 709]\n",
      "Architecture 6 - True Negatives (TN): [20548, 23031, 12517, 14371]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "architectures = [architecture_1, architecture_2, architecture_3, architecture_4, architecture_5, architecture_6]\n",
    "tp_all = []\n",
    "fp_all = []\n",
    "fn_all = []\n",
    "tn_all = []\n",
    "\n",
    "# Loop over each architecture to compute metrics\n",
    "for idx, architecture in enumerate(architectures, 1):\n",
    "    # Fit the architecture if not already trained\n",
    "    # Assuming you already trained the models and have `y_test` and `X_test` ready\n",
    "    y_pred = architecture.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)  # Get class predictions\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "    # Initialize lists to store TP, FP, FN, TN for each class\n",
    "    tp = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    tn = []\n",
    "\n",
    "    # Calculate TP, FP, FN, TN for each class\n",
    "    n_classes = cm.shape[0]  # Number of classes\n",
    "    for i in range(n_classes):\n",
    "        tp_i = cm[i, i]  # Diagonal element for class i\n",
    "        fp_i = cm[:, i].sum() - tp_i  # Sum of predicted class i excluding TP\n",
    "        fn_i = cm[i, :].sum() - tp_i  # Sum of true class i excluding TP\n",
    "        tn_i = cm.sum() - (tp_i + fp_i + fn_i)  # Total sum excluding TP, FP, FN\n",
    "        \n",
    "        tp.append(tp_i)\n",
    "        fp.append(fp_i)\n",
    "        fn.append(fn_i)\n",
    "        tn.append(tn_i)\n",
    "\n",
    "    # Store TP, FP, FN, TN for this architecture\n",
    "    tp_all.append(tp)\n",
    "    fp_all.append(fp)\n",
    "    fn_all.append(fn)\n",
    "    tn_all.append(tn)\n",
    "\n",
    "    # Print out TP, FP, FN, TN for the current architecture\n",
    "    print(f\"Architecture {idx} - True Positives (TP): {tp}\")\n",
    "    print(f\"Architecture {idx} - False Positives (FP): {fp}\")\n",
    "    print(f\"Architecture {idx} - False Negatives (FN): {fn}\")\n",
    "    print(f\"Architecture {idx} - True Negatives (TN): {tn}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Results for All Architectures:\n",
      "  Architecture  Accuracy  Sensitivity  Specificity  Precision    Recall  \\\n",
      "0            1  0.854813     0.854813     0.341772   0.854541  0.854813   \n",
      "1            2  0.946642     0.946642     0.750000   0.946177  0.946642   \n",
      "2            3  0.936481     0.936481     0.717252   0.936199  0.936481   \n",
      "3            4  0.950197     0.950197     0.641566   0.950104  0.950197   \n",
      "4            5  0.913858     0.913858     0.764184   0.913043  0.913858   \n",
      "5            6  0.946684     0.946684     0.806167   0.948098  0.946684   \n",
      "\n",
      "        AUC  Number of Layers  Learning Rate  Iterations  \\\n",
      "0  0.966339                 3          0.001          20   \n",
      "1  0.994440                 3          0.001          20   \n",
      "2  0.991930                 3          0.010          15   \n",
      "3  0.995104                 3          0.001          10   \n",
      "4  0.984455                 3          0.001          20   \n",
      "5  0.994295                 3          0.001          15   \n",
      "\n",
      "  Optimization Algorithm Activation Functions  Layers (N × M × ...)  \\\n",
      "0                    SGD                 ReLU      10 × 32 × 32 × 4   \n",
      "1                    SGD                 ReLU      10 × 64 × 64 × 4   \n",
      "2                    SGD                 Tanh    10 × 128 × 128 × 4   \n",
      "3                   Adam                 ReLU    10 × 256 × 256 × 4   \n",
      "4                    SGD                 ReLU    10 × 512 × 512 × 4   \n",
      "5                   Adam                 ReLU  10 × 1024 × 1024 × 4   \n",
      "\n",
      "        True Positives (TP)   False Positives (FP)   False Negatives (FN)  \\\n",
      "0    [2354, 81, 9591, 8416]  [804, 17, 1119, 1532]  [752, 615, 1117, 988]   \n",
      "1  [2869, 492, 10359, 8918]    [231, 92, 562, 391]   [237, 204, 349, 486]   \n",
      "2  [2869, 449, 10285, 8792]    [369, 80, 624, 446]   [237, 247, 423, 612]   \n",
      "3  [2936, 426, 10469, 8892]    [308, 56, 565, 262]   [170, 270, 239, 512]   \n",
      "4  [2674, 431, 10113, 8636]   [445, 115, 813, 687]   [432, 265, 595, 768]   \n",
      "5  [2851, 549, 10544, 8695]   [260, 187, 689, 139]   [255, 147, 164, 709]   \n",
      "\n",
      "            True Negatives (TN)  \n",
      "0  [20004, 23201, 12087, 12978]  \n",
      "1  [20577, 23126, 12644, 14119]  \n",
      "2  [20439, 23138, 12582, 14064]  \n",
      "3  [20500, 23162, 12641, 14248]  \n",
      "4  [20363, 23103, 12393, 13823]  \n",
      "5  [20548, 23031, 12517, 14371]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have the metrics for all the architectures already calculated\n",
    "results = [\n",
    "    # Architecture 1\n",
    "    {\n",
    "        'Architecture': '1', 'Accuracy': accuracy_1, 'Sensitivity': sensitivity_1,\n",
    "        'Specificity': specificity_1, 'Precision': precision_1, 'Recall': recall_1, \n",
    "        'AUC': auc_1, 'Number of Layers': num_layers_1, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 32 × 32 × 4', \n",
    "        'True Positives (TP)': [2354, 81, 9591, 8416],\n",
    "        'False Positives (FP)': [804, 17, 1119, 1532],\n",
    "        'False Negatives (FN)': [752, 615, 1117, 988],\n",
    "        'True Negatives (TN)': [20004, 23201, 12087, 12978]\n",
    "    },\n",
    "    # Architecture 2\n",
    "    {\n",
    "        'Architecture': '2', 'Accuracy': accuracy_2, 'Sensitivity': sensitivity_2,\n",
    "        'Specificity': specificity_2, 'Precision': precision_2, 'Recall': recall_2, \n",
    "        'AUC': auc_2, 'Number of Layers': num_layers_2, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 64 × 64 × 4', \n",
    "        'True Positives (TP)': [2869, 492, 10359, 8918],\n",
    "        'False Positives (FP)': [231, 92, 562, 391],\n",
    "        'False Negatives (FN)': [237, 204, 349, 486],\n",
    "        'True Negatives (TN)': [20577, 23126, 12644, 14119]\n",
    "    },\n",
    "    # Architecture 3\n",
    "    {\n",
    "        'Architecture': '3', 'Accuracy': accuracy_3, 'Sensitivity': sensitivity_3,\n",
    "        'Specificity': specificity_3, 'Precision': precision_3, 'Recall': recall_3, \n",
    "        'AUC': auc_3, 'Number of Layers': num_layers_3, 'Learning Rate': 0.01, \n",
    "        'Iterations': 15, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'Tanh', \n",
    "        'Layers (N × M × ...)': '10 × 128 × 128 × 4', \n",
    "        'True Positives (TP)': [2869, 449, 10285, 8792],\n",
    "        'False Positives (FP)': [369, 80, 624, 446],\n",
    "        'False Negatives (FN)': [237, 247, 423, 612],\n",
    "        'True Negatives (TN)': [20439, 23138, 12582, 14064]\n",
    "    },\n",
    "    # Architecture 4\n",
    "    {\n",
    "        'Architecture': '4', 'Accuracy': accuracy_4, 'Sensitivity': sensitivity_4,\n",
    "        'Specificity': specificity_4, 'Precision': precision_4, 'Recall': recall_4, \n",
    "        'AUC': auc_4, 'Number of Layers': num_layers_4, 'Learning Rate': 0.001, \n",
    "        'Iterations': 10, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 256 × 256 × 4', \n",
    "        'True Positives (TP)': [2936, 426, 10469, 8892],\n",
    "        'False Positives (FP)': [308, 56, 565, 262],\n",
    "        'False Negatives (FN)': [170, 270, 239, 512],\n",
    "        'True Negatives (TN)': [20500, 23162, 12641, 14248]\n",
    "    },\n",
    "    # Architecture 5\n",
    "    {\n",
    "        'Architecture': '5', 'Accuracy': accuracy_5, 'Sensitivity': sensitivity_5,\n",
    "        'Specificity': specificity_5, 'Precision': precision_5, 'Recall': recall_5, \n",
    "        'AUC': auc_5, 'Number of Layers': num_layers_5, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 512 × 512 × 4', \n",
    "        'True Positives (TP)': [2674, 431, 10113, 8636],\n",
    "        'False Positives (FP)': [445, 115, 813, 687],\n",
    "        'False Negatives (FN)': [432, 265, 595, 768],\n",
    "        'True Negatives (TN)': [20363, 23103, 12393, 13823]\n",
    "    },\n",
    "    # Architecture 6\n",
    "    {\n",
    "        'Architecture': '6', 'Accuracy': accuracy_6, 'Sensitivity': sensitivity_6,\n",
    "        'Specificity': specificity_6, 'Precision': precision_6, 'Recall': recall_6, \n",
    "        'AUC': auc_6, 'Number of Layers': num_layers_6, 'Learning Rate': 0.001, \n",
    "        'Iterations': 15, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 1024 × 1024 × 4', \n",
    "        'True Positives (TP)': [2851, 549, 10544, 8695],\n",
    "        'False Positives (FP)': [260, 187, 689, 139],\n",
    "        'False Negatives (FN)': [255, 147, 164, 709],\n",
    "        'True Negatives (TN)': [20548, 23031, 12517, 14371]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results including all architectures\n",
    "print(\"Experiment Results for All Architectures:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP with Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Architecture 1: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.001, 'activation': 'relu'}\n",
      "Training Architecture 2: {'hidden_layer_sizes': (128,), 'learning_rate_init': 0.001, 'activation': 'relu'}\n",
      "Training Architecture 3: {'hidden_layer_sizes': (64, 32), 'learning_rate_init': 0.01, 'activation': 'relu'}\n",
      "Training Architecture 4: {'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001, 'activation': 'tanh'}\n",
      "Training Architecture 5: {'hidden_layer_sizes': (256,), 'learning_rate_init': 0.0001, 'activation': 'relu'}\n",
      "Training Architecture 6: {'hidden_layer_sizes': (64, 64, 32), 'learning_rate_init': 0.001, 'activation': 'logistic'}\n",
      "\n",
      "Model Evaluation Results:\n",
      "     Architecture                                         Parameters  \\\n",
      "0  Architecture 1  {'hidden_layer_sizes': (64,), 'learning_rate_i...   \n",
      "1  Architecture 2  {'hidden_layer_sizes': (128,), 'learning_rate_...   \n",
      "2  Architecture 3  {'hidden_layer_sizes': (64, 32), 'learning_rat...   \n",
      "3  Architecture 4  {'hidden_layer_sizes': (128, 64), 'learning_ra...   \n",
      "4  Architecture 5  {'hidden_layer_sizes': (256,), 'learning_rate_...   \n",
      "5  Architecture 6  {'hidden_layer_sizes': (64, 64, 32), 'learning...   \n",
      "\n",
      "   Accuracy   ROC AUC                              Classification Report  \n",
      "0  0.880962  0.975847  {'1': {'precision': 0.8553181607059916, 'recal...  \n",
      "1  0.853837  0.968889  {'1': {'precision': 0.7950191570881227, 'recal...  \n",
      "2  0.896880  0.980105  {'1': {'precision': 0.8767783940197733, 'recal...  \n",
      "3  0.920660  0.987406  {'1': {'precision': 0.9240418118466899, 'recal...  \n",
      "4  0.914388  0.985158  {'1': {'precision': 0.8820415078356628, 'recal...  \n",
      "5  0.922305  0.987512  {'1': {'precision': 0.8991944263008926, 'recal...  \n",
      "\n",
      "Best Performing Architecture:\n",
      "Architecture                                                Architecture 6\n",
      "Parameters               {'hidden_layer_sizes': (64, 64, 32), 'learning...\n",
      "Accuracy                                                          0.922305\n",
      "ROC AUC                                                           0.987512\n",
      "Classification Report    {'1': {'precision': 0.8991944263008926, 'recal...\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"https://raw.githubusercontent.com/HWhr3000/F21DL_Coursework_grp2/main/data/encoded/encoded_data.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.drop(\"Loyalty\", axis=1)\n",
    "y = df[\"Loyalty\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define architectures to test\n",
    "architectures = [\n",
    "    {\"hidden_layer_sizes\": (64,), \"learning_rate_init\": 0.001, \"activation\": \"relu\"},\n",
    "    {\"hidden_layer_sizes\": (128,), \"learning_rate_init\": 0.001, \"activation\": \"relu\"},\n",
    "    {\"hidden_layer_sizes\": (64, 32), \"learning_rate_init\": 0.01, \"activation\": \"relu\"},\n",
    "    {\"hidden_layer_sizes\": (128, 64), \"learning_rate_init\": 0.001, \"activation\": \"tanh\"},\n",
    "    {\"hidden_layer_sizes\": (256,), \"learning_rate_init\": 0.0001, \"activation\": \"relu\"},\n",
    "    {\"hidden_layer_sizes\": (64, 64, 32), \"learning_rate_init\": 0.001, \"activation\": \"logistic\"},\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for i, arch in enumerate(architectures, 1):\n",
    "    print(f\"Training Architecture {i}: {arch}\")\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=arch[\"hidden_layer_sizes\"],\n",
    "        learning_rate_init=arch[\"learning_rate_init\"],\n",
    "        activation=arch[\"activation\"],\n",
    "        max_iter=500,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    y_prob = mlp.predict_proba(X_test)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Metrics for multi-class classification\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Collect the metrics for each class\n",
    "    class_metrics = {key: value for key, value in report.items() if key not in ['accuracy', 'macro avg', 'weighted avg']}\n",
    "\n",
    "    # For ROC AUC, we calculate it for each class (one-vs-rest)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='macro')\n",
    "\n",
    "    # Store the metrics\n",
    "    results.append({\n",
    "        \"Architecture\": f\"Architecture {i}\",\n",
    "        \"Parameters\": arch,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Classification Report\": class_metrics,\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame \n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Identify the best-performing architecture based on ROC AUC\n",
    "best_arch = results_df.loc[results_df[\"ROC AUC\"].idxmax()]\n",
    "print(\"\\nBest Performing Architecture:\")\n",
    "print(best_arch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPL Experiments for selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.46086466  1.08083029  1.48185841 -1.26716478  0.49355045  1.24974804\n",
      "  -0.73686944 -1.38019181  1.13448656 -0.80763248  1.31041661  1.21518363\n",
      "  -0.91849868]\n",
      " [-0.46086466  0.47510465  0.69363437  0.66773433 -0.91820488 -0.98304994\n",
      "  -0.82080344 -0.99984732 -0.99203742 -0.80763248 -0.94755279  0.48830629\n",
      "  -0.30227829]\n",
      " [-0.46086466  0.47510465  0.69363437  0.66773433 -0.49467828  0.56796574\n",
      "  -0.29650336  0.53767594  0.55532683  2.65776566  0.62094826  1.32434253\n",
      "  -1.96464567]\n",
      " [ 2.1698344   0.47510465 -0.8828137  -1.67027328  1.76413024 -0.21507242\n",
      "  -0.28155621  1.31015194  1.33652156 -0.80763248  0.62094826 -0.36396608\n",
      "  -1.96464567]\n",
      " [ 2.1698344  -1.42066039 -1.1352965  -1.14057317 -1.12996818 -0.46589409\n",
      "  -0.75411615  0.56783671 -0.47609907  0.92506659 -0.42456678  1.05394422\n",
      "  -0.56852186]] [3 1 3 2 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Load the dataset from the URL\n",
    "# Step 1: Load the data\n",
    "url = \"https://raw.githubusercontent.com/HWhr3000/F21DL_Coursework_grp2/main/data/feature_selected_data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "#'Loyalty' is the target column and rest are features\n",
    "X = data.drop(columns=['Loyalty'])  # Features\n",
    "y = data['Loyalty']  # Target\n",
    "\n",
    "# Label encode the target\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Display a sample of the preprocessed data\n",
    "print(X_train[:5], y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m1,056\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m132\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,636</span> (6.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,636\u001b[0m (6.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,636</span> (6.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,636\u001b[0m (6.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Define ranges for hyperparameters\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "num_layers = [2, 3]\n",
    "layer_sizes = [32, 64]\n",
    "batch_sizes = [16, 32]\n",
    "epochs_list = [10, 20]\n",
    "momentum_list = [0.0, 0.9]\n",
    "\n",
    "# Prepare results storage\n",
    "results = []\n",
    "\n",
    "# Test building a simple model with one configuration\n",
    "lr = 0.001\n",
    "layers = 2\n",
    "size = 32\n",
    "batch = 16\n",
    "epochs = 10\n",
    "momentum = 0.0\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "\n",
    "# Add the specified number of layers\n",
    "for _ in range(layers):\n",
    "    model.add(Dense(size, activation='relu'))\n",
    "\n",
    "model.add(Dense(len(set(y)), activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model with the current learning rate and momentum\n",
    "optimizer = SGD(learning_rate=lr, momentum=momentum)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8450/8450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3ms/step - accuracy: 0.5847 - loss: 1.0046 - val_accuracy: 0.8050 - val_loss: 0.5429\n",
      "Epoch 2/10\n",
      "\u001b[1m8450/8450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.8146 - loss: 0.5164 - val_accuracy: 0.8340 - val_loss: 0.4648\n",
      "Epoch 3/10\n",
      "\u001b[1m8450/8450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.8361 - loss: 0.4584 - val_accuracy: 0.8483 - val_loss: 0.4258\n",
      "Epoch 4/10\n",
      "\u001b[1m8450/8450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 3ms/step - accuracy: 0.8507 - loss: 0.4207 - val_accuracy: 0.8592 - val_loss: 0.3955\n",
      "Epoch 5/10\n",
      "\u001b[1m8450/8450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.8620 - loss: 0.3900 - val_accuracy: 0.8690 - val_loss: 0.3725\n",
      "Epoch 6/10\n",
      "\u001b[1m8450/8450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 0.3673 - val_accuracy: 0.8736 - val_loss: 0.3555\n",
      "Epoch 7/10\n",
      "\u001b[1m8450/8450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.8751 - loss: 0.3550 - val_accuracy: 0.8781 - val_loss: 0.3426\n",
      "Epoch 8/10\n",
      "\u001b[1m8450/8450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3ms/step - accuracy: 0.8788 - loss: 0.3419 - val_accuracy: 0.8816 - val_loss: 0.3329\n",
      "Epoch 9/10\n",
      "\u001b[1m8450/8450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.3327 - val_accuracy: 0.8849 - val_loss: 0.3246\n",
      "Epoch 10/10\n",
      "\u001b[1m8450/8450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.3235 - val_accuracy: 0.8858 - val_loss: 0.3185\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8841 - loss: 0.3206\n",
      "Test Loss: 0.32203832268714905, Test Accuracy: 0.8832343220710754\n"
     ]
    }
   ],
   "source": [
    "# Train the model for the selected hyperparameters\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# Output the results for the test accuracy\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Results:\n",
      "   Learning Rate  Layers  Layer Size  Batch Size  Epochs  Momentum  \\\n",
      "0          0.001       2          32          16      10       0.0   \n",
      "\n",
      "   Validation Accuracy  Test Accuracy  \n",
      "0             0.887386       0.885459  \n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Use a smaller subset for debugging\n",
    "learning_rates = [0.001]\n",
    "num_layers = [2]\n",
    "layer_sizes = [32]\n",
    "batch_sizes = [16]\n",
    "epochs_list = [10]\n",
    "momentum_list = [0.0]\n",
    "\n",
    "# Iterate over the reduced combinations\n",
    "for lr, layers, size, batch, epochs, momentum in product(learning_rates, num_layers, layer_sizes, batch_sizes, epochs_list, momentum_list):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    for _ in range(layers):\n",
    "        model.add(Dense(size, activation='relu'))\n",
    "    model.add(Dense(len(set(y)), activation='softmax'))\n",
    "    \n",
    "    optimizer = SGD(learning_rate=lr, momentum=momentum)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch, validation_split=0.2, verbose=0)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    results.append({\n",
    "        'Learning Rate': lr,\n",
    "        'Layers': layers,\n",
    "        'Layer Size': size,\n",
    "        'Batch Size': batch,\n",
    "        'Epochs': epochs,\n",
    "        'Momentum': momentum,\n",
    "        'Validation Accuracy': max(history.history['val_accuracy']),\n",
    "        'Test Accuracy': accuracy\n",
    "    })\n",
    "    \n",
    "# Display results after the reduced run\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Experiment Results:\")\n",
    "print(results_df)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Experiment Results for Selected Architectures:\n",
      "  Architecture  Accuracy  Sensitivity  Specificity  Precision    Recall  \\\n",
      "0            1  0.864345     0.864345     0.933379   0.865007  0.864345   \n",
      "1            2  0.927119     0.927119     0.941733   0.927145  0.927119   \n",
      "\n",
      "        AUC  Number of Layers  \n",
      "0  0.975007                 3  \n",
      "1  0.993078                 3  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function get number of layers for an architecture\n",
    "def get_num_layers(model):\n",
    "    return len(model.layers)\n",
    "\n",
    "# Results storage for each architecture\n",
    "results = []\n",
    "\n",
    "# Architecture 1: Define the architecture and evaluate\n",
    "architecture_1 = Sequential()\n",
    "architecture_1.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_1.add(Dense(32, activation='relu'))\n",
    "architecture_1.add(Dense(32, activation='relu'))\n",
    "architecture_1.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_1.compile(optimizer=SGD(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_1 = architecture_1.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 1\n",
    "y_pred_1 = architecture_1.predict(X_test)\n",
    "y_pred_1_classes = np.argmax(y_pred_1, axis=1)  # Get class predictions\n",
    "\n",
    "# Compute metrics\n",
    "cm_1 = confusion_matrix(y_test, y_pred_1_classes)\n",
    "accuracy_1 = accuracy_score(y_test, y_pred_1_classes)\n",
    "precision_1 = precision_score(y_test, y_pred_1_classes, average='weighted')  # No need for multi_class here\n",
    "recall_1 = recall_score(y_test, y_pred_1_classes, average='weighted')  # No need for multi_class here\n",
    "sensitivity_1 = recall_1  # Sensitivity = Recall\n",
    "\n",
    "# Specificity calculation (True Negative Rate)\n",
    "specificity_1 = cm_1[1,1] / (cm_1[1,0] + cm_1[1,1]) if cm_1.shape[0] > 1 else None\n",
    "\n",
    "# AUC calculation for multi-class\n",
    "auc_1 = roc_auc_score(y_test, y_pred_1, multi_class='ovr', average='weighted')  # 'ovr' for One-vs-Rest\n",
    "\n",
    "# Get number of layers for Architecture 1\n",
    "num_layers_1 = get_num_layers(architecture_1)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '1', 'Accuracy': accuracy_1, 'Sensitivity': sensitivity_1,\n",
    "    'Specificity': specificity_1, 'Precision': precision_1, 'Recall': recall_1, 'AUC': auc_1, 'Number of Layers': num_layers_1\n",
    "})\n",
    "\n",
    "# Architecture 2: Define the architecture and evaluate \n",
    "architecture_2 = Sequential()\n",
    "architecture_2.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_2.add(Dense(64, activation='sigmoid'))\n",
    "architecture_2.add(Dense(64, activation='sigmoid'))\n",
    "architecture_2.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_2.compile(optimizer=Adam(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_2 = architecture_2.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 2\n",
    "y_pred_2 = architecture_2.predict(X_test)\n",
    "y_pred_2_classes = np.argmax(y_pred_2, axis=1)\n",
    "\n",
    "# Compute metrics for Architecture 2\n",
    "cm_2 = confusion_matrix(y_test, y_pred_2_classes)\n",
    "accuracy_2 = accuracy_score(y_test, y_pred_2_classes)\n",
    "precision_2 = precision_score(y_test, y_pred_2_classes, average='weighted')\n",
    "recall_2 = recall_score(y_test, y_pred_2_classes, average='weighted')\n",
    "sensitivity_2 = recall_2\n",
    "specificity_2 = cm_2[1,1] / (cm_2[1,0] + cm_2[1,1]) if cm_2.shape[0] > 1 else None\n",
    "auc_2 = roc_auc_score(y_test, y_pred_2, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Get number of layers for Architecture 2\n",
    "num_layers_2 = get_num_layers(architecture_2)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '2', 'Accuracy': accuracy_2, 'Sensitivity': sensitivity_2,\n",
    "    'Specificity': specificity_2, 'Precision': precision_2, 'Recall': recall_2, 'AUC': auc_2, 'Number of Layers': num_layers_2\n",
    "})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Experiment Results for Selected Architectures:\")\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Experiment Results for Selected Architectures:\n",
      "  Architecture  Accuracy  Sensitivity  Specificity  Precision    Recall  \\\n",
      "0            3  0.913296     0.913296     0.940881   0.913344  0.913296   \n",
      "1            4  0.931403     0.931403     0.957151   0.931505  0.931403   \n",
      "\n",
      "        AUC  Number of Layers  \n",
      "0  0.989748                 3  \n",
      "1  0.993879                 3  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to get number of layers for an architecture\n",
    "def get_num_layers(model):\n",
    "    return len(model.layers)\n",
    "\n",
    "# Results storage for each architecture\n",
    "results = []\n",
    "\n",
    "# Architecture 3: Define the architecture and evaluate\n",
    "architecture_3 = Sequential()\n",
    "architecture_3.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_3.add(Dense(128, activation='tanh'))\n",
    "architecture_3.add(Dense(128, activation='tanh'))\n",
    "architecture_3.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_3.compile(optimizer=SGD(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_3 = architecture_3.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 3\n",
    "y_pred_3 = architecture_3.predict(X_test)\n",
    "y_pred_3_classes = np.argmax(y_pred_3, axis=1)  # Get class predictions\n",
    "\n",
    "# Compute metrics\n",
    "cm_3 = confusion_matrix(y_test, y_pred_3_classes)\n",
    "accuracy_3 = accuracy_score(y_test, y_pred_3_classes)\n",
    "precision_3 = precision_score(y_test, y_pred_3_classes, average='weighted')\n",
    "recall_3 = recall_score(y_test, y_pred_3_classes, average='weighted')\n",
    "sensitivity_3 = recall_3  # Sensitivity = Recall\n",
    "\n",
    "# Specificity calculation (True Negative Rate)\n",
    "specificity_3 = cm_3[1,1] / (cm_3[1,0] + cm_3[1,1]) if cm_3.shape[0] > 1 else None\n",
    "\n",
    "# AUC calculation for multi-class\n",
    "auc_3 = roc_auc_score(y_test, y_pred_3, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Get number of layers for Architecture 3\n",
    "num_layers_3 = get_num_layers(architecture_3)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '3', 'Accuracy': accuracy_3, 'Sensitivity': sensitivity_3,\n",
    "    'Specificity': specificity_3, 'Precision': precision_3, 'Recall': recall_3, 'AUC': auc_3, 'Number of Layers': num_layers_3\n",
    "})\n",
    "\n",
    "# Architecture 4: Define the architecture and evaluate\n",
    "architecture_4 = Sequential()\n",
    "architecture_4.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_4.add(Dense(256, activation='relu'))\n",
    "architecture_4.add(Dense(256, activation='relu'))\n",
    "architecture_4.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_4.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_4 = architecture_4.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 4\n",
    "y_pred_4 = architecture_4.predict(X_test)\n",
    "y_pred_4_classes = np.argmax(y_pred_4, axis=1)\n",
    "\n",
    "# Compute metrics for Architecture 4\n",
    "cm_4 = confusion_matrix(y_test, y_pred_4_classes)\n",
    "accuracy_4 = accuracy_score(y_test, y_pred_4_classes)\n",
    "precision_4 = precision_score(y_test, y_pred_4_classes, average='weighted')\n",
    "recall_4 = recall_score(y_test, y_pred_4_classes, average='weighted')\n",
    "sensitivity_4 = recall_4\n",
    "specificity_4 = cm_4[1,1] / (cm_4[1,0] + cm_4[1,1]) if cm_4.shape[0] > 1 else None\n",
    "auc_4 = roc_auc_score(y_test, y_pred_4, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Get number of layers for Architecture 4\n",
    "num_layers_4 = get_num_layers(architecture_4)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '4', 'Accuracy': accuracy_4, 'Sensitivity': sensitivity_4,\n",
    "    'Specificity': specificity_4, 'Precision': precision_4, 'Recall': recall_4, 'AUC': auc_4, 'Number of Layers': num_layers_4\n",
    "})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Experiment Results for Selected Architectures:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step\n",
      "Experiment Results for Selected Architectures:\n",
      "  Architecture  Accuracy  Sensitivity  Specificity  Precision    Recall  \\\n",
      "0            5  0.893839     0.893839     0.938048   0.894169  0.893839   \n",
      "1            6  0.938718     0.938718     0.962762   0.938868  0.938718   \n",
      "\n",
      "        AUC  Number of Layers  \n",
      "0  0.983789                 3  \n",
      "1  0.994206                 3  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to get number of layers for an architecture\n",
    "def get_num_layers(model):\n",
    "    return len(model.layers)\n",
    "\n",
    "# Results storage for each architecture\n",
    "results = []\n",
    "\n",
    "# Architecture 5: Define the architecture and evaluate\n",
    "architecture_5 = Sequential()\n",
    "architecture_5.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_5.add(Dense(512, activation='relu'))\n",
    "architecture_5.add(Dense(512, activation='relu'))\n",
    "architecture_5.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_5.compile(optimizer=SGD(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_5 = architecture_5.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 5\n",
    "y_pred_5 = architecture_5.predict(X_test)\n",
    "y_pred_5_classes = np.argmax(y_pred_5, axis=1)  # Get class predictions\n",
    "\n",
    "# Compute metrics\n",
    "cm_5 = confusion_matrix(y_test, y_pred_5_classes)\n",
    "accuracy_5 = accuracy_score(y_test, y_pred_5_classes)\n",
    "precision_5 = precision_score(y_test, y_pred_5_classes, average='weighted')\n",
    "recall_5 = recall_score(y_test, y_pred_5_classes, average='weighted')\n",
    "sensitivity_5 = recall_5  # Sensitivity = Recall\n",
    "\n",
    "# Specificity calculation (True Negative Rate)\n",
    "specificity_5 = cm_5[1,1] / (cm_5[1,0] + cm_5[1,1]) if cm_5.shape[0] > 1 else None\n",
    "\n",
    "# AUC calculation for multi-class\n",
    "auc_5 = roc_auc_score(y_test, y_pred_5, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Get number of layers for Architecture 5\n",
    "num_layers_5 = get_num_layers(architecture_5)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '5', 'Accuracy': accuracy_5, 'Sensitivity': sensitivity_5,\n",
    "    'Specificity': specificity_5, 'Precision': precision_5, 'Recall': recall_5, 'AUC': auc_5, 'Number of Layers': num_layers_5\n",
    "})\n",
    "\n",
    "# Architecture 6: Define the architecture and evaluate\n",
    "architecture_6 = Sequential()\n",
    "architecture_6.add(Input(shape=(X_train.shape[1],)))\n",
    "architecture_6.add(Dense(1024, activation='relu'))\n",
    "architecture_6.add(Dense(1024, activation='relu'))\n",
    "architecture_6.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer\n",
    "architecture_6.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_6 = architecture_6.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2, verbose=0)\n",
    "\n",
    "# Evaluate Architecture 6\n",
    "y_pred_6 = architecture_6.predict(X_test)\n",
    "y_pred_6_classes = np.argmax(y_pred_6, axis=1)\n",
    "\n",
    "# Compute metrics for Architecture 6\n",
    "cm_6 = confusion_matrix(y_test, y_pred_6_classes)\n",
    "accuracy_6 = accuracy_score(y_test, y_pred_6_classes)\n",
    "precision_6 = precision_score(y_test, y_pred_6_classes, average='weighted')\n",
    "recall_6 = recall_score(y_test, y_pred_6_classes, average='weighted')\n",
    "sensitivity_6 = recall_6\n",
    "specificity_6 = cm_6[1,1] / (cm_6[1,0] + cm_6[1,1]) if cm_6.shape[0] > 1 else None\n",
    "auc_6 = roc_auc_score(y_test, y_pred_6, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Get number of layers for Architecture 6\n",
    "num_layers_6 = get_num_layers(architecture_6)\n",
    "\n",
    "results.append({\n",
    "    'Architecture': '6', 'Accuracy': accuracy_6, 'Sensitivity': sensitivity_6,\n",
    "    'Specificity': specificity_6, 'Precision': precision_6, 'Recall': recall_6, 'AUC': auc_6, 'Number of Layers': num_layers_6\n",
    "})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results including the number of layers\n",
    "print(\"Experiment Results for Selected Architectures:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Results for All Architectures:\n",
      "  Architecture  Accuracy  Sensitivity  Specificity  Precision    Recall  \\\n",
      "0            1  0.864345     0.864345     0.933379   0.865007  0.864345   \n",
      "1            2  0.927119     0.927119     0.941733   0.927145  0.927119   \n",
      "2            3  0.913296     0.913296     0.940881   0.913344  0.913296   \n",
      "3            4  0.931403     0.931403     0.957151   0.931505  0.931403   \n",
      "4            5  0.893839     0.893839     0.938048   0.894169  0.893839   \n",
      "5            6  0.938718     0.938718     0.962762   0.938868  0.938718   \n",
      "\n",
      "        AUC  Number of Layers  Learning Rate  Iterations  \\\n",
      "0  0.975007                 3          0.001          20   \n",
      "1  0.993078                 3          0.001          20   \n",
      "2  0.989748                 3          0.010          15   \n",
      "3  0.993879                 3          0.001          10   \n",
      "4  0.983789                 3          0.001          20   \n",
      "5  0.994206                 3          0.001          15   \n",
      "\n",
      "  Optimization Algorithm Activation Functions  Layers (N × M × ...)  \n",
      "0                    SGD                 ReLU      10 × 32 × 32 × 4  \n",
      "1                    SGD                 ReLU      10 × 64 × 64 × 4  \n",
      "2                    SGD                 Tanh    10 × 128 × 128 × 4  \n",
      "3                   Adam                 ReLU    10 × 256 × 256 × 4  \n",
      "4                    SGD                 ReLU    10 × 512 × 512 × 4  \n",
      "5                   Adam                 ReLU  10 × 1024 × 1024 × 4  \n"
     ]
    }
   ],
   "source": [
    "# Assuming metrics for all the architectures already calculated\n",
    "results = [\n",
    "    # Architecture 1\n",
    "    {\n",
    "        'Architecture': '1', 'Accuracy': accuracy_1, 'Sensitivity': sensitivity_1,\n",
    "        'Specificity': specificity_1, 'Precision': precision_1, 'Recall': recall_1, \n",
    "        'AUC': auc_1, 'Number of Layers': num_layers_1, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 32 × 32 × 4'\n",
    "    },\n",
    "    # Architecture 2\n",
    "    {\n",
    "        'Architecture': '2', 'Accuracy': accuracy_2, 'Sensitivity': sensitivity_2,\n",
    "        'Specificity': specificity_2, 'Precision': precision_2, 'Recall': recall_2, \n",
    "        'AUC': auc_2, 'Number of Layers': num_layers_2, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 64 × 64 × 4'\n",
    "    },\n",
    "    # Architecture 3\n",
    "    {\n",
    "        'Architecture': '3', 'Accuracy': accuracy_3, 'Sensitivity': sensitivity_3,\n",
    "        'Specificity': specificity_3, 'Precision': precision_3, 'Recall': recall_3, \n",
    "        'AUC': auc_3, 'Number of Layers': num_layers_3, 'Learning Rate': 0.01, \n",
    "        'Iterations': 15, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'Tanh', \n",
    "        'Layers (N × M × ...)': '10 × 128 × 128 × 4'\n",
    "    },\n",
    "    # Architecture 4\n",
    "    {\n",
    "        'Architecture': '4', 'Accuracy': accuracy_4, 'Sensitivity': sensitivity_4,\n",
    "        'Specificity': specificity_4, 'Precision': precision_4, 'Recall': recall_4, \n",
    "        'AUC': auc_4, 'Number of Layers': num_layers_4, 'Learning Rate': 0.001, \n",
    "        'Iterations': 10, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 256 × 256 × 4'\n",
    "    },\n",
    "    # Architecture 5\n",
    "    {\n",
    "        'Architecture': '5', 'Accuracy': accuracy_5, 'Sensitivity': sensitivity_5,\n",
    "        'Specificity': specificity_5, 'Precision': precision_5, 'Recall': recall_5, \n",
    "        'AUC': auc_5, 'Number of Layers': num_layers_5, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 512 × 512 × 4'\n",
    "    },\n",
    "    # Architecture 6\n",
    "    {\n",
    "        'Architecture': '6', 'Accuracy': accuracy_6, 'Sensitivity': sensitivity_6,\n",
    "        'Specificity': specificity_6, 'Precision': precision_6, 'Recall': recall_6, \n",
    "        'AUC': auc_6, 'Number of Layers': num_layers_6, 'Learning Rate': 0.001, \n",
    "        'Iterations': 15, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 1024 × 1024 × 4'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results including all architectures\n",
    "print(\"Experiment Results for All Architectures:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Architecture Based on Accuracy :\n",
      "Architecture                                 6\n",
      "Accuracy                                  0.96\n",
      "Sensitivity                               0.96\n",
      "Specificity                               0.85\n",
      "Precision                                 0.96\n",
      "Recall                                    0.96\n",
      "AUC                                      0.998\n",
      "Number of Layers                             3\n",
      "Learning Rate                            0.001\n",
      "Iterations                                  15\n",
      "Optimization Algorithm                    Adam\n",
      "Activation Functions                      ReLU\n",
      "Layers (N × M × ...)      10 × 1024 × 1024 × 4\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample result data for architectures 1-6\n",
    "results = [\n",
    "    {'Architecture': '1', 'Accuracy': 0.854813, 'Sensitivity': 0.854813, 'Specificity': 0.341772, 'Precision': 0.854541, 'Recall': 0.854813, 'AUC': 0.966339, 'Number of Layers': 3, 'Learning Rate': 0.001, 'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', 'Layers (N × M × ...)': '10 × 32 × 32 × 4'},\n",
    "    {'Architecture': '2', 'Accuracy': 0.946642, 'Sensitivity': 0.946642, 'Specificity': 0.750000, 'Precision': 0.946177, 'Recall': 0.946642, 'AUC': 0.994440, 'Number of Layers': 3, 'Learning Rate': 0.001, 'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', 'Layers (N × M × ...)': '10 × 64 × 64 × 4'},\n",
    "    {'Architecture': '3', 'Accuracy': 0.920000, 'Sensitivity': 0.920000, 'Specificity': 0.600000, 'Precision': 0.920000, 'Recall': 0.920000, 'AUC': 0.981500, 'Number of Layers': 3, 'Learning Rate': 0.01, 'Iterations': 15, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'Tanh', 'Layers (N × M × ...)': '10 × 128 × 128 × 4'},\n",
    "    {'Architecture': '4', 'Accuracy': 0.940000, 'Sensitivity': 0.940000, 'Specificity': 0.700000, 'Precision': 0.940000, 'Recall': 0.940000, 'AUC': 0.991000, 'Number of Layers': 3, 'Learning Rate': 0.001, 'Iterations': 10, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', 'Layers (N × M × ...)': '10 × 256 × 256 × 4'},\n",
    "    {'Architecture': '5', 'Accuracy': 0.950000, 'Sensitivity': 0.950000, 'Specificity': 0.800000, 'Precision': 0.950000, 'Recall': 0.950000, 'AUC': 0.995000, 'Number of Layers': 3, 'Learning Rate': 0.001, 'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', 'Layers (N × M × ...)': '10 × 512 × 512 × 4'},\n",
    "    {'Architecture': '6', 'Accuracy': 0.960000, 'Sensitivity': 0.960000, 'Specificity': 0.850000, 'Precision': 0.960000, 'Recall': 0.960000, 'AUC': 0.998000, 'Number of Layers': 3, 'Learning Rate': 0.001, 'Iterations': 15, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', 'Layers (N × M × ...)': '10 × 1024 × 1024 × 4'}\n",
    "]\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Choose the metric for determining the best architecture (e.g., Accuracy, AUC, etc.)\n",
    "best_metric = 'Accuracy'\n",
    "\n",
    "# Find the row corresponding to the highest value of the chosen metric\n",
    "best_architecture = results_df.loc[results_df[best_metric].idxmax()]\n",
    "\n",
    "# Print the best architecture details\n",
    "print(\"Best Architecture Based on\", best_metric, \":\")\n",
    "print(best_architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.8835 - loss: 0.3195 - val_accuracy: 0.9161 - val_loss: 0.2303\n",
      "Epoch 2/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 19ms/step - accuracy: 0.9172 - loss: 0.2214 - val_accuracy: 0.9207 - val_loss: 0.2150\n",
      "Epoch 3/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 20ms/step - accuracy: 0.9247 - loss: 0.1985 - val_accuracy: 0.9267 - val_loss: 0.2011\n",
      "Epoch 4/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 20ms/step - accuracy: 0.9293 - loss: 0.1859 - val_accuracy: 0.9289 - val_loss: 0.1913\n",
      "Epoch 5/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 20ms/step - accuracy: 0.9340 - loss: 0.1738 - val_accuracy: 0.9284 - val_loss: 0.1922\n",
      "Epoch 6/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 20ms/step - accuracy: 0.9362 - loss: 0.1665 - val_accuracy: 0.9312 - val_loss: 0.1880\n",
      "Epoch 7/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 19ms/step - accuracy: 0.9388 - loss: 0.1610 - val_accuracy: 0.9340 - val_loss: 0.1818\n",
      "Epoch 8/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 20ms/step - accuracy: 0.9411 - loss: 0.1530 - val_accuracy: 0.9372 - val_loss: 0.1694\n",
      "Epoch 9/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 21ms/step - accuracy: 0.9434 - loss: 0.1458 - val_accuracy: 0.9315 - val_loss: 0.1869\n",
      "Epoch 10/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 20ms/step - accuracy: 0.9442 - loss: 0.1439 - val_accuracy: 0.9356 - val_loss: 0.1755\n",
      "Epoch 11/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 19ms/step - accuracy: 0.9472 - loss: 0.1393 - val_accuracy: 0.9352 - val_loss: 0.1778\n",
      "Epoch 12/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 19ms/step - accuracy: 0.9475 - loss: 0.1350 - val_accuracy: 0.9373 - val_loss: 0.1743\n",
      "Epoch 13/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 19ms/step - accuracy: 0.9498 - loss: 0.1310 - val_accuracy: 0.9360 - val_loss: 0.1769\n",
      "Epoch 14/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 19ms/step - accuracy: 0.9512 - loss: 0.1267 - val_accuracy: 0.9351 - val_loss: 0.1876\n",
      "Epoch 15/15\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 19ms/step - accuracy: 0.9530 - loss: 0.1238 - val_accuracy: 0.9372 - val_loss: 0.1811\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step\n",
      "Best Architecture (Architecture 6) Metrics:\n",
      "Accuracy: 0.9376287073638365\n",
      "Sensitivity: 0.9376287073638365\n",
      "Specificity: 0.9626132930513596\n",
      "Precision: 0.9381876093901156\n",
      "Recall: 0.9376287073638365\n",
      "AUC: 0.9943113239260064\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the best architecture based on the provided details\n",
    "best_architecture = Sequential()\n",
    "best_architecture.add(Input(shape=(X_train.shape[1],)))  # Input layer matching the number of features\n",
    "best_architecture.add(Dense(1024, activation='relu'))   # Hidden layer with 1024 neurons and ReLU activation\n",
    "best_architecture.add(Dense(1024, activation='relu'))   # Another hidden layer with 1024 neurons and ReLU activation\n",
    "best_architecture.add(Dense(len(np.unique(y)), activation='softmax'))  # Output layer with softmax activation for multi-class classification\n",
    "\n",
    "# Compile the model with Adam optimizer and sparse categorical crossentropy for multi-class classification\n",
    "best_architecture.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = best_architecture.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_best = best_architecture.predict(X_test)\n",
    "y_pred_best_classes = np.argmax(y_pred_best, axis=1)\n",
    "\n",
    "# Compute metrics for the best architecture\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "cm_best = confusion_matrix(y_test, y_pred_best_classes)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best_classes)\n",
    "precision_best = precision_score(y_test, y_pred_best_classes, average='weighted')\n",
    "recall_best = recall_score(y_test, y_pred_best_classes, average='weighted')\n",
    "sensitivity_best = recall_best  # Sensitivity = Recall\n",
    "specificity_best = cm_best[1,1] / (cm_best[1,0] + cm_best[1,1]) if cm_best.shape[0] > 1 else None\n",
    "auc_best = roc_auc_score(y_test, y_pred_best, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Output metrics\n",
    "print(f\"Best Architecture (Architecture 6) Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_best}\")\n",
    "print(f\"Sensitivity: {sensitivity_best}\")\n",
    "print(f\"Specificity: {specificity_best}\")\n",
    "print(f\"Precision: {precision_best}\")\n",
    "print(f\"Recall: {recall_best}\")\n",
    "print(f\"AUC: {auc_best}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Architecture 1 - True Positives (TP): [9082, 9471, 9121, 8842]\n",
      "Architecture 1 - False Positives (FP): [1690, 1642, 1004, 1395]\n",
      "Architecture 1 - False Negatives (FN): [1373, 1188, 1440, 1730]\n",
      "Architecture 1 - True Negatives (TN): [30102, 29946, 30682, 30280]\n",
      "\n",
      "\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Architecture 2 - True Positives (TP): [9587, 9762, 10020, 9799]\n",
      "Architecture 2 - False Positives (FP): [906, 679, 712, 782]\n",
      "Architecture 2 - False Negatives (FN): [868, 897, 541, 773]\n",
      "Architecture 2 - True Negatives (TN): [30886, 30909, 30974, 30893]\n",
      "\n",
      "\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Architecture 3 - True Positives (TP): [9458, 9724, 9908, 9494]\n",
      "Architecture 3 - False Positives (FP): [1034, 1040, 783, 806]\n",
      "Architecture 3 - False Negatives (FN): [997, 935, 653, 1078]\n",
      "Architecture 3 - True Negatives (TN): [30758, 30548, 30903, 30869]\n",
      "\n",
      "\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Architecture 4 - True Positives (TP): [9549, 10052, 10012, 9736]\n",
      "Architecture 4 - False Positives (FP): [737, 863, 702, 596]\n",
      "Architecture 4 - False Negatives (FN): [906, 607, 549, 836]\n",
      "Architecture 4 - True Negatives (TN): [31055, 30725, 30984, 31079]\n",
      "\n",
      "\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "Architecture 5 - True Positives (TP): [9324, 9630, 9661, 9147]\n",
      "Architecture 5 - False Positives (FP): [1264, 1391, 809, 1021]\n",
      "Architecture 5 - False Negatives (FN): [1131, 1029, 900, 1425]\n",
      "Architecture 5 - True Negatives (TN): [30528, 30197, 30877, 30654]\n",
      "\n",
      "\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n",
      "Architecture 6 - True Positives (TP): [9706, 10135, 10115, 9702]\n",
      "Architecture 6 - False Positives (FP): [668, 676, 741, 504]\n",
      "Architecture 6 - False Negatives (FN): [749, 524, 446, 870]\n",
      "Architecture 6 - True Negatives (TN): [31124, 30912, 30945, 31171]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# List of architectures \n",
    "architectures = [architecture_1, architecture_2, architecture_3, architecture_4, architecture_5, architecture_6]\n",
    "tp_all = []\n",
    "fp_all = []\n",
    "fn_all = []\n",
    "tn_all = []\n",
    "\n",
    "# Loop over each architecture to compute metrics\n",
    "for idx, architecture in enumerate(architectures, 1):\n",
    "    # Fit the architecture if not already trained\n",
    "    # Assuming we already trained the models and have `y_test` and `X_test` ready\n",
    "    y_pred = architecture.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)  # Get class predictions\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "    # Initialize lists to store TP, FP, FN, TN for each class\n",
    "    tp = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    tn = []\n",
    "\n",
    "    # Calculate TP, FP, FN, TN for each class\n",
    "    n_classes = cm.shape[0]  # Number of classes\n",
    "    for i in range(n_classes):\n",
    "        tp_i = cm[i, i]  # Diagonal element for class i\n",
    "        fp_i = cm[:, i].sum() - tp_i  # Sum of predicted class i excluding TP\n",
    "        fn_i = cm[i, :].sum() - tp_i  # Sum of true class i excluding TP\n",
    "        tn_i = cm.sum() - (tp_i + fp_i + fn_i)  # Total sum excluding TP, FP, FN\n",
    "        \n",
    "        tp.append(tp_i)\n",
    "        fp.append(fp_i)\n",
    "        fn.append(fn_i)\n",
    "        tn.append(tn_i)\n",
    "\n",
    "    # Store TP, FP, FN, TN for this architecture\n",
    "    tp_all.append(tp)\n",
    "    fp_all.append(fp)\n",
    "    fn_all.append(fn)\n",
    "    tn_all.append(tn)\n",
    "\n",
    "    # Print out TP, FP, FN, TN for the current architecture\n",
    "    print(f\"Architecture {idx} - True Positives (TP): {tp}\")\n",
    "    print(f\"Architecture {idx} - False Positives (FP): {fp}\")\n",
    "    print(f\"Architecture {idx} - False Negatives (FN): {fn}\")\n",
    "    print(f\"Architecture {idx} - True Negatives (TN): {tn}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# After running this loop, we will have the TP, FP, FN, TN for each architecture in `tp_all`, `fp_all`, `fn_all`, and `tn_all`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Results for All Architectures:\n",
      "  Architecture  Accuracy  Sensitivity  Specificity  Precision    Recall  \\\n",
      "0            1  0.864345     0.864345     0.933379   0.865007  0.864345   \n",
      "1            2  0.927119     0.927119     0.941733   0.927145  0.927119   \n",
      "2            3  0.913296     0.913296     0.940881   0.913344  0.913296   \n",
      "3            4  0.931403     0.931403     0.957151   0.931505  0.931403   \n",
      "4            5  0.893839     0.893839     0.938048   0.894169  0.893839   \n",
      "5            6  0.938718     0.938718     0.962762   0.938868  0.938718   \n",
      "\n",
      "        AUC  Number of Layers  Learning Rate  Iterations  \\\n",
      "0  0.975007                 3          0.001          20   \n",
      "1  0.993078                 3          0.001          20   \n",
      "2  0.989748                 3          0.010          15   \n",
      "3  0.993879                 3          0.001          10   \n",
      "4  0.983789                 3          0.001          20   \n",
      "5  0.994206                 3          0.001          15   \n",
      "\n",
      "  Optimization Algorithm Activation Functions  Layers (N × M × ...)  \\\n",
      "0                    SGD                 ReLU      10 × 32 × 32 × 4   \n",
      "1                    SGD                 ReLU      10 × 64 × 64 × 4   \n",
      "2                    SGD                 Tanh    10 × 128 × 128 × 4   \n",
      "3                   Adam                 ReLU    10 × 256 × 256 × 4   \n",
      "4                    SGD                 ReLU    10 × 512 × 512 × 4   \n",
      "5                   Adam                 ReLU  10 × 1024 × 1024 × 4   \n",
      "\n",
      "        True Positives (TP)   False Positives (FP)   False Negatives (FN)  \\\n",
      "0    [2354, 81, 9591, 8416]  [804, 17, 1119, 1532]  [752, 615, 1117, 988]   \n",
      "1  [2869, 492, 10359, 8918]    [231, 92, 562, 391]   [237, 204, 349, 486]   \n",
      "2  [2869, 449, 10285, 8792]    [369, 80, 624, 446]   [237, 247, 423, 612]   \n",
      "3  [2936, 426, 10469, 8892]    [308, 56, 565, 262]   [170, 270, 239, 512]   \n",
      "4  [2674, 431, 10113, 8636]   [445, 115, 813, 687]   [432, 265, 595, 768]   \n",
      "5  [2851, 549, 10544, 8695]   [260, 187, 689, 139]   [255, 147, 164, 709]   \n",
      "\n",
      "            True Negatives (TN)  \n",
      "0  [20004, 23201, 12087, 12978]  \n",
      "1  [20577, 23126, 12644, 14119]  \n",
      "2  [20439, 23138, 12582, 14064]  \n",
      "3  [20500, 23162, 12641, 14248]  \n",
      "4  [20363, 23103, 12393, 13823]  \n",
      "5  [20548, 23031, 12517, 14371]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming we have the metrics for all the architectures already calculated\n",
    "results = [\n",
    "    # Architecture 1\n",
    "    {\n",
    "        'Architecture': '1', 'Accuracy': accuracy_1, 'Sensitivity': sensitivity_1,\n",
    "        'Specificity': specificity_1, 'Precision': precision_1, 'Recall': recall_1, \n",
    "        'AUC': auc_1, 'Number of Layers': num_layers_1, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 32 × 32 × 4', \n",
    "        'True Positives (TP)': [2354, 81, 9591, 8416],\n",
    "        'False Positives (FP)': [804, 17, 1119, 1532],\n",
    "        'False Negatives (FN)': [752, 615, 1117, 988],\n",
    "        'True Negatives (TN)': [20004, 23201, 12087, 12978]\n",
    "    },\n",
    "    # Architecture 2\n",
    "    {\n",
    "        'Architecture': '2', 'Accuracy': accuracy_2, 'Sensitivity': sensitivity_2,\n",
    "        'Specificity': specificity_2, 'Precision': precision_2, 'Recall': recall_2, \n",
    "        'AUC': auc_2, 'Number of Layers': num_layers_2, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 64 × 64 × 4', \n",
    "        'True Positives (TP)': [2869, 492, 10359, 8918],\n",
    "        'False Positives (FP)': [231, 92, 562, 391],\n",
    "        'False Negatives (FN)': [237, 204, 349, 486],\n",
    "        'True Negatives (TN)': [20577, 23126, 12644, 14119]\n",
    "    },\n",
    "    # Architecture 3\n",
    "    {\n",
    "        'Architecture': '3', 'Accuracy': accuracy_3, 'Sensitivity': sensitivity_3,\n",
    "        'Specificity': specificity_3, 'Precision': precision_3, 'Recall': recall_3, \n",
    "        'AUC': auc_3, 'Number of Layers': num_layers_3, 'Learning Rate': 0.01, \n",
    "        'Iterations': 15, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'Tanh', \n",
    "        'Layers (N × M × ...)': '10 × 128 × 128 × 4', \n",
    "        'True Positives (TP)': [2869, 449, 10285, 8792],\n",
    "        'False Positives (FP)': [369, 80, 624, 446],\n",
    "        'False Negatives (FN)': [237, 247, 423, 612],\n",
    "        'True Negatives (TN)': [20439, 23138, 12582, 14064]\n",
    "    },\n",
    "    # Architecture 4\n",
    "    {\n",
    "        'Architecture': '4', 'Accuracy': accuracy_4, 'Sensitivity': sensitivity_4,\n",
    "        'Specificity': specificity_4, 'Precision': precision_4, 'Recall': recall_4, \n",
    "        'AUC': auc_4, 'Number of Layers': num_layers_4, 'Learning Rate': 0.001, \n",
    "        'Iterations': 10, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 256 × 256 × 4', \n",
    "        'True Positives (TP)': [2936, 426, 10469, 8892],\n",
    "        'False Positives (FP)': [308, 56, 565, 262],\n",
    "        'False Negatives (FN)': [170, 270, 239, 512],\n",
    "        'True Negatives (TN)': [20500, 23162, 12641, 14248]\n",
    "    },\n",
    "    # Architecture 5\n",
    "    {\n",
    "        'Architecture': '5', 'Accuracy': accuracy_5, 'Sensitivity': sensitivity_5,\n",
    "        'Specificity': specificity_5, 'Precision': precision_5, 'Recall': recall_5, \n",
    "        'AUC': auc_5, 'Number of Layers': num_layers_5, 'Learning Rate': 0.001, \n",
    "        'Iterations': 20, 'Optimization Algorithm': 'SGD', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 512 × 512 × 4', \n",
    "        'True Positives (TP)': [2674, 431, 10113, 8636],\n",
    "        'False Positives (FP)': [445, 115, 813, 687],\n",
    "        'False Negatives (FN)': [432, 265, 595, 768],\n",
    "        'True Negatives (TN)': [20363, 23103, 12393, 13823]\n",
    "    },\n",
    "    # Architecture 6\n",
    "    {\n",
    "        'Architecture': '6', 'Accuracy': accuracy_6, 'Sensitivity': sensitivity_6,\n",
    "        'Specificity': specificity_6, 'Precision': precision_6, 'Recall': recall_6, \n",
    "        'AUC': auc_6, 'Number of Layers': num_layers_6, 'Learning Rate': 0.001, \n",
    "        'Iterations': 15, 'Optimization Algorithm': 'Adam', 'Activation Functions': 'ReLU', \n",
    "        'Layers (N × M × ...)': '10 × 1024 × 1024 × 4', \n",
    "        'True Positives (TP)': [2851, 549, 10544, 8695],\n",
    "        'False Positives (FP)': [260, 187, 689, 139],\n",
    "        'False Negatives (FN)': [255, 147, 164, 709],\n",
    "        'True Negatives (TN)': [20548, 23031, 12517, 14371]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results including all architectures\n",
    "print(\"Experiment Results for All Architectures:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Architecture 1: {'hidden_layer_sizes': (64,), 'learning_rate_init': 0.001, 'activation': 'relu'}\n",
      "Training Architecture 2: {'hidden_layer_sizes': (128,), 'learning_rate_init': 0.001, 'activation': 'relu'}\n",
      "Training Architecture 3: {'hidden_layer_sizes': (64, 32), 'learning_rate_init': 0.01, 'activation': 'relu'}\n",
      "Training Architecture 4: {'hidden_layer_sizes': (128, 64), 'learning_rate_init': 0.001, 'activation': 'tanh'}\n",
      "Training Architecture 5: {'hidden_layer_sizes': (256,), 'learning_rate_init': 0.0001, 'activation': 'relu'}\n",
      "Training Architecture 6: {'hidden_layer_sizes': (64, 64, 32), 'learning_rate_init': 0.001, 'activation': 'logistic'}\n",
      "\n",
      "Model Evaluation Results:\n",
      "     Architecture                                         Parameters  \\\n",
      "0  Architecture 1  {'hidden_layer_sizes': (64,), 'learning_rate_i...   \n",
      "1  Architecture 2  {'hidden_layer_sizes': (128,), 'learning_rate_...   \n",
      "2  Architecture 3  {'hidden_layer_sizes': (64, 32), 'learning_rat...   \n",
      "3  Architecture 4  {'hidden_layer_sizes': (128, 64), 'learning_ra...   \n",
      "4  Architecture 5  {'hidden_layer_sizes': (256,), 'learning_rate_...   \n",
      "5  Architecture 6  {'hidden_layer_sizes': (64, 64, 32), 'learning...   \n",
      "\n",
      "   Accuracy   ROC AUC                              Classification Report  \n",
      "0  0.812593  0.964320  {'1': {'precision': 0.9134746404239212, 'recal...  \n",
      "1  0.893420  0.984714  {'1': {'precision': 0.8802167684066277, 'recal...  \n",
      "2  0.874609  0.978872  {'1': {'precision': 0.8813801154419871, 'recal...  \n",
      "3  0.891889  0.984362  {'1': {'precision': 0.9017909860263728, 'recal...  \n",
      "4  0.877040  0.980893  {'1': {'precision': 0.9066550848590138, 'recal...  \n",
      "5  0.913240  0.989617  {'1': {'precision': 0.9090207676975504, 'recal...  \n",
      "\n",
      "Best Performing Architecture:\n",
      "Architecture                                                Architecture 6\n",
      "Parameters               {'hidden_layer_sizes': (64, 64, 32), 'learning...\n",
      "Accuracy                                                           0.91324\n",
      "ROC AUC                                                           0.989617\n",
      "Classification Report    {'1': {'precision': 0.9090207676975504, 'recal...\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"https://raw.githubusercontent.com/HWhr3000/F21DL_Coursework_grp2/main/data/feature_selected_data.csv\"  #file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.drop(\"Loyalty\", axis=1)\n",
    "y = df[\"Loyalty\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define architectures to test\n",
    "architectures = [\n",
    "    {\"hidden_layer_sizes\": (64,), \"learning_rate_init\": 0.001, \"activation\": \"relu\"},\n",
    "    {\"hidden_layer_sizes\": (128,), \"learning_rate_init\": 0.001, \"activation\": \"relu\"},\n",
    "    {\"hidden_layer_sizes\": (64, 32), \"learning_rate_init\": 0.01, \"activation\": \"relu\"},\n",
    "    {\"hidden_layer_sizes\": (128, 64), \"learning_rate_init\": 0.001, \"activation\": \"tanh\"},\n",
    "    {\"hidden_layer_sizes\": (256,), \"learning_rate_init\": 0.0001, \"activation\": \"relu\"},\n",
    "    {\"hidden_layer_sizes\": (64, 64, 32), \"learning_rate_init\": 0.001, \"activation\": \"logistic\"},\n",
    "]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for i, arch in enumerate(architectures, 1):\n",
    "    print(f\"Training Architecture {i}: {arch}\")\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=arch[\"hidden_layer_sizes\"],\n",
    "        learning_rate_init=arch[\"learning_rate_init\"],\n",
    "        activation=arch[\"activation\"],\n",
    "        max_iter=500,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    y_prob = mlp.predict_proba(X_test)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Metrics for multi-class classification\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    # Collect the metrics for each class\n",
    "    class_metrics = {key: value for key, value in report.items() if key not in ['accuracy', 'macro avg', 'weighted avg']}\n",
    "\n",
    "    # For ROC AUC, we need to calculate it for each class (one-vs-rest)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='macro')\n",
    "\n",
    "    # Store the metrics\n",
    "    results.append({\n",
    "        \"Architecture\": f\"Architecture {i}\",\n",
    "        \"Parameters\": arch,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Classification Report\": class_metrics,\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for easy analysis\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Identify the best-performing architecture based on ROC AUC\n",
    "best_arch = results_df.loc[results_df[\"ROC AUC\"].idxmax()]\n",
    "print(\"\\nBest Performing Architecture:\")\n",
    "print(best_arch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier Performance Comparison with Varying Training and Testing Data Splits for featured data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Classifier  Train Accuracy  Test Accuracy\n",
      "0  Classifier 1        0.928778       0.922305\n",
      "1  Classifier 2        0.904143       0.898961\n",
      "2  Classifier 3        0.908328       0.902246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Best-performing architecture parameters\n",
    "best_arch = {\n",
    "    \"hidden_layer_sizes\": (64, 64, 32),\n",
    "    \"learning_rate_init\": 0.001,\n",
    "    \"activation\": \"logistic\",\n",
    "    \"random_state\": 42,\n",
    "    \"max_iter\": 500\n",
    "}\n",
    "\n",
    "# Helper function to calculate accuracy\n",
    "def calculate_accuracy(clf, X_train, y_train, X_test, y_test):\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict on the training and test datasets\n",
    "    train_pred = clf.predict(X_train)\n",
    "    test_pred = clf.predict(X_test)\n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "# Store metrics for each classifier\n",
    "metrics = {\n",
    "    \"Classifier\": [],\n",
    "    \"Train Accuracy\": [],\n",
    "    \"Test Accuracy\": []\n",
    "}\n",
    "\n",
    "# Classifier 1 - Using training and testing data\n",
    "clf1 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy = calculate_accuracy(clf1, X_train, y_train, X_test, y_test)\n",
    "\n",
    "metrics[\"Classifier\"].append(\"Classifier 1\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "\n",
    "# Classifier 2 - Moving 30% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "clf2 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy = calculate_accuracy(clf2, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "\n",
    "metrics[\"Classifier\"].append(\"Classifier 2\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "\n",
    "# Classifier 3 - Moving 60% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.6, random_state=42)\n",
    "clf3 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy = calculate_accuracy(clf3, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "\n",
    "metrics[\"Classifier\"].append(\"Classifier 3\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "\n",
    "# Create a DataFrame from the metrics dictionary\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the metrics table\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data for plotting\n",
    "classifiers = ['Classifier 1', 'Classifier 2', 'Classifier 3']\n",
    "train_accuracies = [0.928778, 0.904143, 0.908328]  # Replace with actual training accuracies\n",
    "test_accuracies = [0.922305, 0.898961, 0.902246]  # Replace with actual test accuracies\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(classifiers, train_accuracies, label='Train Accuracy', marker='o', color='blue')\n",
    "plt.plot(classifiers, test_accuracies, label='Test Accuracy', marker='o', color='red')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Training vs Test Accuracy for Different Classifiers', fontsize=14)\n",
    "plt.xlabel('Classifiers', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Classifier  Train Accuracy  Test Accuracy  Precision    Recall  F1 Score  \\\n",
      "0  Classifier 1        0.928778       0.922305   0.921902  0.922305  0.922063   \n",
      "1  Classifier 2        0.904143       0.898961   0.898696  0.898961  0.898065   \n",
      "2  Classifier 3        0.908328       0.902246   0.901412  0.902246  0.901065   \n",
      "\n",
      "   Specificity       AUC  \n",
      "0     0.966650  0.987987  \n",
      "1     0.955104  0.981300  \n",
      "2     0.956355  0.982515  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Best-performing architecture parameters\n",
    "best_arch = {\n",
    "    \"hidden_layer_sizes\": (64, 64, 32),\n",
    "    \"learning_rate_init\": 0.001,\n",
    "    \"activation\": \"logistic\",\n",
    "    \"random_state\": 42,\n",
    "    \"max_iter\": 500\n",
    "}\n",
    "\n",
    "# Helper function to calculate various performance metrics\n",
    "def calculate_metrics(clf, X_train, y_train, X_test, y_test):\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict on the training and test datasets\n",
    "    train_pred = clf.predict(X_train)\n",
    "    test_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    # Precision, Recall, F1-Score for Test Set\n",
    "    precision = precision_score(y_test, test_pred, average='weighted', zero_division=1)\n",
    "    recall = recall_score(y_test, test_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, test_pred, average='weighted')\n",
    "    \n",
    "    # Confusion matrix to calculate Specificity\n",
    "    cm = confusion_matrix(y_test, test_pred)\n",
    "    tn = cm.diagonal().sum() - cm.sum(axis=1)\n",
    "    fp = cm.sum(axis=0) - cm.diagonal()\n",
    "    fn = cm.sum(axis=1) - cm.diagonal()\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # Area Under ROC Curve (AUC) - One-vs-Rest strategy\n",
    "    auc = roc_auc_score(y_test, clf.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"specificity\": specificity.mean(),  # Mean specificity for multi-class\n",
    "        \"auc\": auc\n",
    "    }\n",
    "\n",
    "# Store metrics for each classifier\n",
    "metrics = {\n",
    "    \"Classifier\": [],\n",
    "    \"Train Accuracy\": [],\n",
    "    \"Test Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"AUC\": []\n",
    "}\n",
    "\n",
    "# Classifier 1 - Using training and testing data\n",
    "clf1 = MLPClassifier(**best_arch)\n",
    "results = calculate_metrics(clf1, X_train, y_train, X_test, y_test)\n",
    "metrics[\"Classifier\"].append(\"Classifier 1\")\n",
    "metrics[\"Train Accuracy\"].append(results[\"train_accuracy\"])\n",
    "metrics[\"Test Accuracy\"].append(results[\"test_accuracy\"])\n",
    "metrics[\"Precision\"].append(results[\"precision\"])\n",
    "metrics[\"Recall\"].append(results[\"recall\"])\n",
    "metrics[\"F1 Score\"].append(results[\"f1_score\"])\n",
    "metrics[\"Specificity\"].append(results[\"specificity\"])\n",
    "metrics[\"AUC\"].append(results[\"auc\"])\n",
    "\n",
    "# Classifier 2 - Moving 30% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "clf2 = MLPClassifier(**best_arch)\n",
    "results = calculate_metrics(clf2, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "metrics[\"Classifier\"].append(\"Classifier 2\")\n",
    "metrics[\"Train Accuracy\"].append(results[\"train_accuracy\"])\n",
    "metrics[\"Test Accuracy\"].append(results[\"test_accuracy\"])\n",
    "metrics[\"Precision\"].append(results[\"precision\"])\n",
    "metrics[\"Recall\"].append(results[\"recall\"])\n",
    "metrics[\"F1 Score\"].append(results[\"f1_score\"])\n",
    "metrics[\"Specificity\"].append(results[\"specificity\"])\n",
    "metrics[\"AUC\"].append(results[\"auc\"])\n",
    "\n",
    "# Classifier 3 - Moving 60% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.6, random_state=42)\n",
    "clf3 = MLPClassifier(**best_arch)\n",
    "results = calculate_metrics(clf3, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "metrics[\"Classifier\"].append(\"Classifier 3\")\n",
    "metrics[\"Train Accuracy\"].append(results[\"train_accuracy\"])\n",
    "metrics[\"Test Accuracy\"].append(results[\"test_accuracy\"])\n",
    "metrics[\"Precision\"].append(results[\"precision\"])\n",
    "metrics[\"Recall\"].append(results[\"recall\"])\n",
    "metrics[\"F1 Score\"].append(results[\"f1_score\"])\n",
    "metrics[\"Specificity\"].append(results[\"specificity\"])\n",
    "metrics[\"AUC\"].append(results[\"auc\"])\n",
    "\n",
    "# Create a DataFrame from the metrics dictionary\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the metrics table\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation of MLP Classifiers with Varying Training Data Splits: Accuracy, Precision, Recall, F1 Score, and Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Classifier  Train Accuracy  Test Accuracy  \\\n",
      "0  Classifier 1        0.928778       0.922305   \n",
      "1  Classifier 2        0.904143       0.898961   \n",
      "2  Classifier 3        0.908328       0.902246   \n",
      "\n",
      "                                           Precision  \\\n",
      "0  [0.8991944263008926, 0.7619047619047619, 0.934...   \n",
      "1  [0.8808093582042364, 0.7824497257769653, 0.927...   \n",
      "2  [0.8945264986967854, 0.7422839506172839, 0.909...   \n",
      "\n",
      "                                              Recall  \\\n",
      "0  [0.8838005563877595, 0.7117988394584139, 0.942...   \n",
      "1  [0.853292496171516, 0.5839017735334243, 0.9053...   \n",
      "2  [0.7758854559155991, 0.6522033898305085, 0.936...   \n",
      "\n",
      "                                            F1 Score  \\\n",
      "0  [0.8914310382041873, 0.736, 0.9386463085373802...   \n",
      "1  [0.8668326073428749, 0.66875, 0.91611428571428...   \n",
      "2  [0.8309927360774818, 0.6943341753879466, 0.922...   \n",
      "\n",
      "                          TP                            TN  \\\n",
      "0  [4130, 736, 15123, 13095]  [30735, 34607, 18771, 20713]   \n",
      "1   [2786, 428, 10020, 9338]  [21467, 24257, 13254, 13812]   \n",
      "2  [5148, 962, 20623, 18576]  [42976, 48409, 26148, 28212]   \n",
      "\n",
      "                       FP                       FN  \n",
      "0  [463, 230, 1053, 1041]    [543, 298, 924, 1022]  \n",
      "1   [377, 119, 787, 1254]    [479, 305, 1048, 705]  \n",
      "2  [607, 334, 2043, 1925]  [1487, 513, 1404, 1505]  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Best-performing architecture parameters\n",
    "best_arch = {\n",
    "    \"hidden_layer_sizes\": (64, 64, 32),\n",
    "    \"learning_rate_init\": 0.001,\n",
    "    \"activation\": \"logistic\",\n",
    "    \"random_state\": 42,\n",
    "    \"max_iter\": 500\n",
    "}\n",
    "\n",
    "# Helper function to calculate accuracy and confusion matrix\n",
    "def calculate_metrics(clf, X_train, y_train, X_test, y_test):\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict on the training and test datasets\n",
    "    train_pred = clf.predict(X_train)\n",
    "    test_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score for each class\n",
    "    precision = precision_score(y_test, test_pred, average=None)\n",
    "    recall = recall_score(y_test, test_pred, average=None)\n",
    "    f1 = f1_score(y_test, test_pred, average=None)\n",
    "    \n",
    "    # Confusion matrix (multi-class)\n",
    "    cm = confusion_matrix(y_test, test_pred)\n",
    "    \n",
    "    # Calculate TP, TN, FP, FN for each class\n",
    "    TP = np.diag(cm)\n",
    "    FP = np.sum(cm, axis=0) - TP\n",
    "    FN = np.sum(cm, axis=1) - TP\n",
    "    TN = np.sum(cm) - (FP + FN + TP)\n",
    "    \n",
    "    return train_accuracy, test_accuracy, TP, TN, FP, FN, precision, recall, f1\n",
    "\n",
    "# Store metrics for each classifier\n",
    "metrics = {\n",
    "    \"Classifier\": [],\n",
    "    \"Train Accuracy\": [],\n",
    "    \"Test Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": [],\n",
    "    \"TP\": [],\n",
    "    \"TN\": [],\n",
    "    \"FP\": [],\n",
    "    \"FN\": []\n",
    "}\n",
    "\n",
    "# Classifier 1 - Using training and testing data\n",
    "clf1 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy, TP, TN, FP, FN, precision, recall, f1 = calculate_metrics(clf1, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Store metrics\n",
    "metrics[\"Classifier\"].append(\"Classifier 1\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "metrics[\"Precision\"].append(precision)\n",
    "metrics[\"Recall\"].append(recall)\n",
    "metrics[\"F1 Score\"].append(f1)\n",
    "metrics[\"TP\"].append(TP)\n",
    "metrics[\"TN\"].append(TN)\n",
    "metrics[\"FP\"].append(FP)\n",
    "metrics[\"FN\"].append(FN)\n",
    "\n",
    "# Classifier 2 - Moving 30% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "clf2 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy, TP, TN, FP, FN, precision, recall, f1 = calculate_metrics(clf2, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "\n",
    "# Store metrics\n",
    "metrics[\"Classifier\"].append(\"Classifier 2\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "metrics[\"Precision\"].append(precision)\n",
    "metrics[\"Recall\"].append(recall)\n",
    "metrics[\"F1 Score\"].append(f1)\n",
    "metrics[\"TP\"].append(TP)\n",
    "metrics[\"TN\"].append(TN)\n",
    "metrics[\"FP\"].append(FP)\n",
    "metrics[\"FN\"].append(FN)\n",
    "\n",
    "# Classifier 3 - Moving 60% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.6, random_state=42)\n",
    "clf3 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy, TP, TN, FP, FN, precision, recall, f1 = calculate_metrics(clf3, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "\n",
    "# Store metrics\n",
    "metrics[\"Classifier\"].append(\"Classifier 3\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "metrics[\"Precision\"].append(precision)\n",
    "metrics[\"Recall\"].append(recall)\n",
    "metrics[\"F1 Score\"].append(f1)\n",
    "metrics[\"TP\"].append(TP)\n",
    "metrics[\"TN\"].append(TN)\n",
    "metrics[\"FP\"].append(FP)\n",
    "metrics[\"FN\"].append(FN)\n",
    "\n",
    "# Create a DataFrame from the metrics dictionary\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the metrics table\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting Analysis: Identifying Accuracy Gaps Between Train and Test Data for MLP Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Classifier  Train Accuracy  Test Accuracy  Accuracy Gap\n",
      "0  Classifier 1        0.928778       0.922305      0.006473\n",
      "1  Classifier 2        0.904143       0.898961      0.005182\n",
      "2  Classifier 3        0.908328       0.902246      0.006082\n",
      "     Classifier  Accuracy Gap  Overfitting\n",
      "0  Classifier 1      0.006473        False\n",
      "1  Classifier 2      0.005182        False\n",
      "2  Classifier 3      0.006082        False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate accuracy gap (train accuracy - test accuracy)\n",
    "metrics_df[\"Accuracy Gap\"] = metrics_df[\"Train Accuracy\"] - metrics_df[\"Test Accuracy\"]\n",
    "\n",
    "# Print results for overfitting analysis\n",
    "print(metrics_df[[\"Classifier\", \"Train Accuracy\", \"Test Accuracy\", \"Accuracy Gap\"]])\n",
    "\n",
    "# Threshold for overfitting (you can adjust this based on your dataset or domain knowledge)\n",
    "overfitting_threshold = 0.05\n",
    "\n",
    "# Identify classifiers with potential overfitting\n",
    "metrics_df['Overfitting'] = metrics_df['Accuracy Gap'] > overfitting_threshold\n",
    "print(metrics_df[['Classifier', 'Accuracy Gap', 'Overfitting']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIhCAYAAAB5deq6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZI0lEQVR4nO3dd3xO9///8eeVPURIzBARm1pFqbRWrdpas6ooKYpqSKtUa6tWP0WpUUVSrZKqUVVUrNIatWtVqZEiVuyVeX5/+Lm+vSRyEhJX8Ljfbtft5nqf9znndV05OfK83ue8L4thGIYAAAAAAPfkYO8CAAAAACCrIzgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBWZzFYknTY926dQ+0n2HDhslisdzXuuvWrcuQGrKah/XeS9KNGzc0bNiwFLcVHh4ui8WiY8eOPfB+HsTEiRNlsVhUtmxZu9bxKNq5c6dq1aolb29vWSwWTZgwIdP3GRMTo0GDBqlMmTLy8PBQ9uzZ9eyzz2ry5MmKj4/P9P2n5tixY2rSpIl8fHxksVgUEhKiY8eOyWKxKDw83Npv48aNGjZsmC5dupRsG1OmTLHp+99t370de9izZ48sFoucnZ0VHR390PZrsVg0bNiwTNl2ly5dVLhw4UzZNvAocLJ3AQBSt2nTJpvnI0eO1Nq1a7VmzRqb9jJlyjzQfoKDg/Xiiy/e17qVKlXSpk2bHriGrOZhvffS7eA0fPhwSVLt2rVtljVp0kSbNm1S/vz5H3g/D2LWrFmSpH379mnLli2qVq2aXet5lHTt2lXXr1/XvHnzlDNnzkz/4/Ovv/5SgwYNdO3aNYWGhiooKEg3b97U0qVL9fbbb2v+/PlatmyZPDw8MrWOe+nXr5+2bNmiWbNmKV++fMqfP7/y5cunTZs2qWjRotZ+Gzdu1PDhw9WlSxflyJHDZhtTpkxRrly51KVLF5v2/PnzJ9uOPcyYMUOSlJCQoNmzZ+u9996zaz0Z4cMPP9Tbb79t7zIAuyE4AVncs88+a/M8d+7ccnBwSNZ+txs3bqTrj6KCBQuqYMGC91XjnU+yHzf3+95ntNy5cyt37twPdZ9327Ztm3bv3q0mTZro559/1syZM7NscErvsf8w7N27V2+88YYaNWqUIduLj4+XxWKRk1Py/8YTExPVqlUrXblyRX/88YdKlChhXda4cWPVqlVL7du3V//+/TVt2rQMqSctDMPQrVu35O7urr1796pq1apq2bKlTZ+M+N1ydXW1+/koNjZWc+bMUYUKFXT+/HnNmjXrsQhO9g6jgL1xqR7wGKhdu7bKli2r9evXKygoSB4eHurataskKSIiQg0aNFD+/Pnl7u6u0qVLa+DAgbp+/brNNlK6VK9w4cJq2rSpVqxYoUqVKsnd3V2lSpWyjjzckdKlel26dFG2bNl0+PBhNW7cWNmyZZO/v79CQ0MVGxtrs/6JEyfUunVreXl5KUeOHHr11Ve1detW08ttdu/eLYvFopkzZyZbtnz5clksFi1ZskSSdO7cOXXv3l3+/v5ydXVV7ty59dxzz2nVqlWm729q4uLiNGrUKJUqVcq63ddff13nzp2z6bdmzRrVrl1bvr6+cnd3V6FChdSqVSvduHFDx44dswaj4cOHWy8BvPNJekqX6t35mW/dulU1atSQh4eHihQpoo8//lhJSUk2+963b58aNGggDw8P5c6dW71799bPP/+crssM77zHH3/8sYKCgjRv3jzduHEjWb+TJ09a32cXFxf5+fmpdevWOnPmjLXPpUuXFBoaqiJFisjV1VV58uRR48aN9ddff0m696WfKV2Cdec427Nnjxo0aCAvLy/VrVtXkhQZGakWLVqoYMGCcnNzU7FixdSjRw+dP38+Wd1//fWXXnnlFeXNm1eurq4qVKiQOnXqpNjYWB07dkxOTk4aM2ZMsvXWr18vi8Wi+fPnp/i+3fnZJSQkaOrUqdaf7R179+5VixYtlDNnTrm5ualixYr6+uuvbbZx5/345ptvFBoaqgIFCsjV1VWHDx9OcZ+LFi3S/v37NXDgQJvQdEe7du3UoEEDzZw5U6dPn1Z8fLzy5Mmj1157LVnfS5cuyd3dXf3797e2XblyRe+8844CAwPl4uKiAgUKKCQkJNk5xWKxqE+fPpo2bZpKly4tV1dXff3117JYLDp8+LD1d/TOsX33z3fYsGF69913JUmBgYE2l8YWLlxY+/bt06+//mptvzOKl9Jxcuf8tm/fPr3yyivy9vZW3rx51bVrV12+fDnZa+7WrZt8fHyULVs2NWnSREeOHEnXJXCLFy9WTEyMgoOD1blzZ/3999/67bffkvVL6zn23Llz6tWrl8qUKaNs2bIpT548euGFF7Rhw4ZU60jPsZuWc2RKl+rNnz9f1apVk7e3t/U8dOf/H+Bxw4gT8JiIjo5Wx44dNWDAAH300UdycLj9ucihQ4fUuHFjhYSEyNPTU3/99Zc++eQT/fHHH8kuOUvJ7t27FRoaqoEDBypv3ryaMWOGunXrpmLFiqlmzZqprhsfH6/mzZurW7duCg0N1fr16zVy5Eh5e3tryJAhkqTr16+rTp06unDhgj755BMVK1ZMK1asULt27Uxrq1Chgp5++mmFhYWpW7duNsvCw8Otf5BL0muvvaYdO3Zo9OjRKlGihC5duqQdO3YoJibGdD/3kpSUpBYtWmjDhg0aMGCAgoKCdPz4cQ0dOlS1a9fWtm3b5O7ubr2fo0aNGpo1a5Zy5MihkydPasWKFYqLi1P+/Pm1YsUKvfjii+rWrZuCg4MlyXSU6fTp03r11VcVGhqqoUOHatGiRRo0aJD8/PzUqVMnSbePi1q1asnT01NTp05Vnjx5NHfuXPXp0yfNr/PmzZuaO3eunnnmGZUtW1Zdu3ZVcHCw5s+fr86dO1v7nTx5Us8884zi4+P1/vvvq3z58oqJidEvv/yiixcvKm/evLp69aqef/55HTt2TO+9956qVauma9euaf369YqOjlapUqXS/XOIi4tT8+bN1aNHDw0cOFAJCQmSpH/++UfVq1dXcHCwvL29dezYMY0bN07PP/+89uzZI2dnZ0m3j/Hnn39euXLl0ogRI1S8eHFFR0dryZIliouLU+HChdW8eXNNmzZNAwYMkKOjo3XfX3zxhfz8/PTSSy+lWNudyyyrV6+u1q1bKzQ01Lrs4MGDCgoKUp48eTRx4kT5+vrq22+/VZcuXXTmzBkNGDDAZluDBg1S9erVNW3aNDk4OChPnjwp7jMyMlKSko3m/FfLli21cuVKrVu3Tu3bt1fHjh01bdo0TZ48WdmzZ7f2mzt3rm7duqXXX39d0u3RvFq1aunEiRPWn/G+ffs0ZMgQ7dmzR6tWrbIJhosXL9aGDRs0ZMgQ5cuXTz4+Ptq0aZNeeuklFS1aVP/73/8k3b687u77gIKDg3XhwgVNmjRJCxcutF6qWqZMGS1atEitW7eWt7e3pkyZIun2SJOZVq1aqV27durWrZv27NmjQYMGSfq/y1CTkpLUrFkzbdu2TcOGDbNehpzey5hnzpwpV1dXvfrqq7pw4YLGjBmjmTNn6vnnn0/WNy3n2AsXLkiShg4dqnz58unatWtatGiRateurdWrVye7vPeO9By793OO3LRpk9q1a6d27dpp2LBhcnNz0/Hjx9P0fwvwSDIAPFI6d+5seHp62rTVqlXLkGSsXr061XWTkpKM+Ph449dffzUkGbt377YuGzp0qHH3KSEgIMBwc3Mzjh8/bm27efOm4ePjY/To0cPatnbtWkOSsXbtWps6JRnff/+9zTYbN25slCxZ0vp88uTJhiRj+fLlNv169OhhSDLCwsJSfU0TJ040JBkHDx60tl24cMFwdXU1QkNDrW3ZsmUzQkJCUt2Wmbvf+7lz5xqSjAULFtj027p1qyHJmDJlimEYhvHDDz8Ykoxdu3bdc9vnzp0zJBlDhw5NtiwsLMyQZBw9etTadudnvmXLFpu+ZcqUMRo2bGh9/u677xoWi8XYt2+fTb+GDRsm+5ndy+zZsw1JxrRp0wzDMIyrV68a2bJlM2rUqGHTr2vXroazs7Oxf//+e25rxIgRhiQjMjLynn1SOp4MwzCOHj2a7Ji4c5zNmjUr1ddw59g/fvy4Icn48ccfrcteeOEFI0eOHMbZs2dNa1q0aJG17eTJk4aTk5MxfPjwVPdtGIYhyejdu7dNW/v27Q1XV1cjKirKpr1Ro0aGh4eHcenSJZt916xZ03Q/hmEYL774oiHJuHXr1j37LF++3JBkfPLJJ4ZhGMaff/5pSDKmT59u069q1apG5cqVrc/HjBljODg4GFu3brXpd+cYX7Zsmc1r9vb2Ni5cuJBs/wEBAUaTJk1s2lL6+X766afJjv07nnrqKaNWrVrJ2lPazp3z29ixY2369urVy3BzczOSkpIMwzCMn3/+2ZBkTJ061abfmDFj7vn7ebdjx44ZDg4ORvv27a1ttWrVMjw9PY0rV67Y9E3rOfZuCQkJRnx8vFG3bl3jpZdesll2d51pPXbTco7s3LmzERAQYH3+v//9z5BkPVaBxx2X6gGPiZw5c+qFF15I1n7kyBF16NBB+fLlk6Ojo5ydnVWrVi1J0oEDB0y3W7FiRRUqVMj63M3NTSVKlNDx48dN17VYLGrWrJlNW/ny5W3W/fXXX+Xl5ZXsE91XXnnFdPuS9Oqrr8rV1dXmspy5c+cqNjbW+im5JFWtWlXh4eEaNWqUNm/enCGzii1dulQ5cuRQs2bNlJCQYH1UrFhR+fLls15qVrFiRbm4uKh79+76+uuvdeTIkQfetyTly5dPVatWtWlL6f0tW7Zssgks0vr+Src/PXd3d1f79u0lSdmyZVObNm20YcMGHTp0yNpv+fLlqlOnjkqXLn3PbS1fvlwlSpRQvXr10rz/tGjVqlWytrNnz6pnz57y9/eXk5OTnJ2dFRAQIOn/jv0bN27o119/Vdu2bVMd4atdu7YqVKigyZMnW9umTZsmi8Wi7t2731fNa9asUd26deXv72/T3qVLF924cSPZ5CQpvcb7ZRiGJFlHh8qVK6fKlSsrLCzM2ufAgQP6448/bC67Wrp0qcqWLauKFSvaHPMNGzZM8fLKF154QTlz5sywuh9U8+bNbZ6XL19et27d0tmzZyXd/n2RpLZt29r0S8/vS1hYmJKSkmzetzuTg0RERCTrn9Zz7LRp01SpUiW5ublZj+fVq1ebnsfTeuzezznymWeekXT7/fr+++918uRJ03WARxnBCXhMpDTj2rVr11SjRg1t2bJFo0aN0rp167R161YtXLhQ0u1LsMz4+voma3N1dU3Tuh4eHnJzc0u27q1bt6zPY2JilDdv3mTrptSWEh8fHzVv3lyzZ89WYmKipNuX6VWtWlVPPfWUtV9ERIQ6d+6sGTNmqHr16vLx8VGnTp10+vTpNO0nJWfOnNGlS5fk4uIiZ2dnm8fp06et99IULVpUq1atUp48edS7d28VLVpURYsW1eeff37f+5bS9rN50Pf38OHDWr9+vZo0aSLDMHTp0iVdunRJrVu3liSbezHOnTtnOsFIWvqk152ptv8rKSlJDRo00MKFCzVgwACtXr1af/zxhzZv3izp/479ixcvKjExMU019e3bV6tXr9bBgwcVHx+vr776Sq1bt1a+fPnuq+6YmJgUf2/9/Pysy/8rrbMq3vkj/OjRo/fsc+d+uf+Gtq5du2rTpk3We83CwsLk6upqExrOnDmjP//8M9nx7uXlJcMwkt0/Zu+ZIO929+/Mncv77hwPMTExcnJyko+Pj02/tP6+JCUlKTw8XH5+fqpcubL196VevXry9PRM8X7MtPwejxs3Tm+++aaqVaumBQsWaPPmzdq6datefPHFNJ2L03Ls3s85smbNmlq8eLESEhLUqVMnFSxYUGXLltXcuXNNawIeRdzjBDwmUvoOpjVr1ujUqVNat26ddZRJUorfiWIvvr6++uOPP5K1pyfQvP7665o/f74iIyNVqFAhbd26VVOnTrXpkytXLk2YMEETJkxQVFSUlixZooEDB+rs2bNasWLFfdWeK1cu+fr63nN9Ly8v679r1KihGjVqKDExUdu2bdOkSZMUEhKivHnzWkdyMoOvr6/NxAx3pPX9nTVrlgzD0A8//KAffvgh2fKvv/5ao0aNkqOjo3Lnzq0TJ06kur209LkTtu+eRCSlSR2klI/9vXv3avfu3QoPD7e5D+vuCRV8fHzk6OhoWpMkdejQQe+9954mT56sZ599VqdPn1bv3r1N17sXX1/fFL/f59SpU5JuH1//ldbvWatfv76mT5+uxYsXa+DAgSn2Wbx4sZycnGzujXnllVfUv39/hYeHa/To0frmm2/UsmVLmxGjXLlyyd3dPdnkBf9dfj81ZxW+vr5KSEjQhQsXbMJTWn9fVq1aZR0pSikQbd68Wfv370/3Vxh8++23ql27drLz2tWrV9O0flqO3fs9R7Zo0UItWrRQbGysNm/erDFjxqhDhw4qXLiwqlevnq7XCWR1jDgBj7E7f7TcfdP0l19+aY9yUlSrVi1dvXpVy5cvt2mfN29emrfRoEEDFShQQGFhYQoLC5Obm1uql9YUKlRIffr0Uf369bVjx477rr1p06aKiYlRYmKiqlSpkuxRsmTJZOs4OjqqWrVq1stm7uz/7k++M0qtWrW0d+9e7d+/36Y9Le9vYmKivv76axUtWlRr165N9ggNDVV0dLT1Z9eoUSOtXbtWBw8evOc2GzVqpL///jvVm8fvzNr1559/2rTfmSExLdJ67Lu7u6tWrVqaP3/+PYPZHW5ubtbLLceNG6eKFSvqueeeS3NNd6tbt671w43/mj17tjw8PO57Su2XXnpJZcqU0ccff6y///472fKIiAitXLlSwcHBNiMOOXPmVMuWLTV79mwtXbpUp0+fTjY7WtOmTfXPP//I19c3xWM+o7+fKrXfi7SOfKfHnQ+Y7r6kLq3no5kzZ8rBwUGLFy9O9vvyzTffSNI9Q2dqLBZLsmP5zz//THY5572k99i9n3Okq6uratWqpU8++UTS7S99Bh43jDgBj7GgoCDlzJlTPXv21NChQ+Xs7Kw5c+Zo9+7d9i7NqnPnzho/frw6duyoUaNGqVixYlq+fLl++eUXSbLODpgaR0dHderUSePGjVP27Nn18ssvy9vb27r88uXLqlOnjjp06KBSpUrJy8tLW7du1YoVK/Tyyy/fd+3t27fXnDlz1LhxY7399tuqWrWqnJ2ddeLECa1du1YtWrTQSy+9pGnTpmnNmjVq0qSJChUqpFu3bln/eLpzr4+Xl5cCAgL0448/qm7duvLx8VGuXLke+A/RkJAQzZo1S40aNdKIESOUN29efffdd9bLsVJ7f5cvX65Tp07pk08+SXHWrrJly+qLL77QzJkz1bRpU40YMULLly9XzZo19f7776tcuXK6dOmSVqxYof79+6tUqVIKCQlRRESEWrRooYEDB6pq1aq6efOmfv31VzVt2lR16tRRvnz5VK9ePY0ZM0Y5c+ZUQECAVq9ebb3ENC1KlSqlokWLauDAgTIMQz4+Pvrpp5+sM879152Z9qpVq6aBAweqWLFiOnPmjJYsWaIvv/zSZuSwV69eGjt2rLZv3279gtP7NXToUC1dulR16tTRkCFD5OPjozlz5ujnn3/W2LFjbY7h9HB0dNSCBQtUv359Va9eXaGhoapevbpiY2P1008/afr06apVq5Y+++yzZOt27dpVERER6tOnjwoWLJjsXrSQkBAtWLBANWvWVL9+/VS+fHklJSUpKipKK1euVGhoaIZ+v1e5cuUkSZ9//rk6d+4sZ2dnlSxZUl5eXipXrpzmzZuniIgIFSlSRG5ubtb+9+vFF1/Uc889p9DQUF25ckWVK1fWpk2bNHv2bEmp/77ExMToxx9/VMOGDdWiRYsU+4wfP16zZ8/WmDFjrLM6pkXTpk01cuRIDR06VLVq1dLBgwc1YsQIBQYGWmeRNJPasXu/58ghQ4boxIkTqlu3rgoWLKhLly7p888/t7mXFnis2HVqCgDpdq9Z9Z566qkU+2/cuNGoXr264eHhYeTOndsIDg42duzYcc9Zp/4rpZmv7uzvv7NZ3WtWvbvrvNd+oqKijJdfftnIli2b4eXlZbRq1cpYtmxZstnPUvP3338bklKcse3WrVtGz549jfLlyxvZs2c33N3djZIlSxpDhw41rl+/nqbt3+s1xcfHG//73/+MChUqGG5ubka2bNmMUqVKGT169DAOHTpkGIZhbNq0yXjppZeMgIAAw9XV1fD19TVq1aplLFmyxGZbq1atMp5++mnD1dXVkGR07tzZMIx7z6qX0s/87lmvDMMw9u7da9SrV89wc3MzfHx8jG7duhlff/11spkV79ayZUvDxcUl1dnm2rdvbzg5ORmnT582DMMw/v33X6Nr165Gvnz5DGdnZ8PPz89o27atcebMGes6Fy9eNN5++22jUKFChrOzs5EnTx6jSZMmxl9//WXtEx0dbbRu3drw8fExvL29jY4dOxrbtm1LcVa9lI4zwzCM/fv3G/Xr1ze8vLyMnDlzGm3atDGioqJSnB1t//79Rps2bQxfX1/DxcXFKFSokNGlS5cUZ6arXbu24ePjY9y4ceOe78vdlMKseoZhGHv27DGaNWtmeHt7Gy4uLkaFChWSzSR55/dr/vz5ad6fYRjG+fPnjYEDBxqlSpWyHptVq1Y1vvjiCyMuLi7FdRITEw1/f39DkjF48OAU+1y7ds344IMPjJIlSxouLi6Gt7e3Ua5cOaNfv37W4yC112wYaZ9VzzAMY9CgQYafn5/h4OBgc545duyY0aBBA8PLy8uQZD3uU5tV79y5czbbTul368KFC8brr79u5MiRw/Dw8DDq169vbN682ZBkfP755ym+HsMwjAkTJhiSjMWLF9+zz7Rp02xm4kzrOTY2NtZ45513jAIFChhubm5GpUqVjMWLF6f4+57S8X3HvY7dtJ4j797f0qVLjUaNGhkFChQwXFxcjDx58hiNGzc2NmzYcM/3AHiUWQzj/0+tAwBZyEcffaQPPvhAUVFRGT6ZAKTu3btr7ty5iomJkYuLi73LeWScPXtWAQEBeuuttzR27Fh7l4OH5LvvvtOrr76q33//XUFBQfYu575w7AIPjkv1ANjdF198Ien25VXx8fFas2aNJk6cqI4dOxKaMsCIESPk5+enIkWK6Nq1a1q6dKlmzJihDz74gNCURidOnNCRI0f06aefysHBQW+//ba9S0ImmTt3rk6ePKly5crJwcFBmzdv1qeffqqaNWs+kqGJYxfIOAQnAHbn4eGh8ePH69ixY4qNjVWhQoX03nvv6YMPPrB3aY8FZ2dnffrppzpx4oQSEhJUvHhxjRs3jj+g0mHGjBkaMWKEChcurDlz5qhAgQL2LgmZxMvLS/PmzdOoUaN0/fp15c+fX126dNGoUaPsXdp94dgFMg6X6gEAAACACaYjBwAAAAATBCcAAAAAMEFwAgAAAAATT9zkEElJSTp16pS8vLys3ywPAAAA4MljGIauXr0qPz+/VL/kWnoCg9OpU6fk7+9v7zIAAAAAZBH//vuv6VegPHHBycvLS9LtNyd79ux2rgYAAACAvVy5ckX+/v7WjJCaJy443bk8L3v27AQnAAAAAGm6hYfJIQAAAADABMEJAAAAAEwQnAAAAADAxBN3jxMAAACyLsMwlJCQoMTERHuXgseEs7OzHB0dH3g7BCcAAABkCXFxcYqOjtaNGzfsXQoeIxaLRQULFlS2bNkeaDsEJwAAANhdUlKSjh49KkdHR/n5+cnFxSVNM50BqTEMQ+fOndOJEydUvHjxBxp5IjgBAADA7uLi4pSUlCR/f395eHjYuxw8RnLnzq1jx44pPj7+gYITk0MAAAAgy3Bw4M9TZKyMGrnkyAQAAAAAEwQnAAAAADDBPU4AAADI0goP/Pmh7evYx00e2r7upXbt2qpYsaImTJhg71LwH4w4AQAAAPfBYrGk+ujSpct9bXfhwoUaOXJkhtS4ceNGOTo66sUXX8yQ7T3JGHECAAAA7kN0dLT13xERERoyZIgOHjxobXN3d7fpHx8fL2dnZ9Pt+vj4ZFiNs2bN0ltvvaUZM2YoKipKhQoVyrBtp1daX39WxYgTAAAAcB/y5ctnfXh7e8tisVif37p1Szly5ND333+v2rVry83NTd9++61iYmL0yiuvqGDBgvLw8FC5cuU0d+5cm+3Wrl1bISEh1ueFCxfWRx99pK5du8rLy0uFChXS9OnTTeu7fv26vv/+e7355ptq2rSpwsPDk/VZsmSJqlSpIjc3N+XKlUsvv/yydVlsbKwGDBggf39/ubq6qnjx4po5c6YkKTw8XDly5LDZ1uLFi21msBs2bJgqVqyoWbNmqUiRInJ1dZVhGFqxYoWef/555ciRQ76+vmratKn++ecfm22dOHFC7du3l4+Pjzw9PVWlShVt2bJFx44dk4ODg7Zt22bTf9KkSQoICJBhGKbvy/0iOAEAAACZ5L333lPfvn114MABNWzYULdu3VLlypW1dOlS7d27V927d9drr72mLVu2pLqdzz77TFWqVNHOnTvVq1cvvfnmm/rrr79SXSciIkIlS5ZUyZIl1bFjR4WFhdkEi59//lkvv/yymjRpop07d2r16tWqUqWKdXmnTp00b948TZw4UQcOHNC0adOULVu2dL3+w4cP6/vvv9eCBQu0a9cuSbcDXf/+/bV161atXr1aDg4Oeumll5SUlCRJunbtmmrVqqVTp05pyZIl2r17twYMGKCkpCQVLlxY9erVU1hYmM1+wsLC1KVLl0z90mQu1QMAAAAySUhIiM0ojiS988471n+/9dZbWrFihebPn69q1ardczuNGzdWr169JN0OY+PHj9e6detUqlSpe64zc+ZMdezYUZL04osv6tq1a1q9erXq1asnSRo9erTat2+v4cOHW9epUKGCJOnvv//W999/r8jISGv/IkWKpOelS7r9xcbffPONcufObW1r1apVsjrz5Mmj/fv3q2zZsvruu+907tw5bd261XrZYrFixaz9g4OD1bNnT40bN06urq7avXu3du3apYULF6a7vvRgxAkAAADIJP8dwZGkxMREjR49WuXLl5evr6+yZcumlStXKioqKtXtlC9f3vrvO5cEnj179p79Dx48qD/++EPt27eXJDk5Oaldu3aaNWuWtc+uXbtUt27dFNfftWuXHB0dVatWLdPXmJqAgACb0CRJ//zzjzp06KAiRYooe/bsCgwMlCTre7Br1y49/fTT97zXq2XLlnJyctKiRYsk3b6Pq06dOipcuPAD1WqGEScAAAAgk3h6eto8/+yzzzR+/HhNmDBB5cqVk6enp0JCQhQXF5fqdu6eVMFisVgvbUvJzJkzlZCQoAIFCljbDMOQs7OzLl68qJw5cyabvOK/UlsmSQ4ODsnuJ4qPj0/W7+7XL0nNmjWTv7+/vvrqK/n5+SkpKUlly5a1vgdm+3ZxcdFrr72msLAwvfzyy/ruu+8eytTtjDgBAAAAD8mGDRvUokULdezYURUqVFCRIkV06NChDN1HQkKCZs+erc8++0y7du2yPnbv3q2AgADNmTNH0u1RrNWrV6e4jXLlyikpKUm//vpristz586tq1ev6vr169a2O/cwpSYmJkYHDhzQBx98oLp166p06dK6ePGiTZ/y5ctr165dunDhwj23ExwcrFWrVmnKlCmKj49PdjlkZmDE6Qn1ML9ILqvKCl9wBwAAnizFihXTggULtHHjRuXMmVPjxo3T6dOnVbp06Qzbx9KlS3Xx4kV169ZN3t7eNstat26tmTNnqk+fPho6dKjq1q2rokWLqn379kpISNDy5cs1YMAAFS5cWJ07d1bXrl01ceJEVahQQcePH9fZs2fVtm1bVatWTR4eHnr//ff11ltv6Y8//khx1r675cyZU76+vpo+fbry58+vqKgoDRw40KbPK6+8oo8++kgtW7bUmDFjlD9/fu3cuVN+fn6qXr26JKl06dJ69tln9d5776lr166mo1QZgeAEAACALO1x+rDzww8/1NGjR9WwYUN5eHioe/fuatmypS5fvpxh+5g5c6bq1auXLDRJtydm+Oijj7Rjxw7Vrl1b8+fP18iRI/Xxxx8re/bsqlmzprXv1KlT9f7776tXr16KiYlRoUKF9P7770u6/V1T3377rd59911Nnz5d9erV07Bhw9S9e/dUa3NwcNC8efPUt29flS1bViVLltTEiRNVu3Ztax8XFxetXLlSoaGhaty4sRISElSmTBlNnjzZZlvdunXTxo0b1bVr1wd4t9LOYmTmZOdZ0JUrV+Tt7a3Lly8re/bs9i7HbhhxerxOwgAAPOpu3bqlo0ePKjAwUG5ubvYuB4+A0aNHa968edqzZ0+q/VI7ttKTDRhxwpNrWPJPYZ4owzLuky0AAICH5dq1azpw4IAmTZqkkSNHPrT9MjkEAAAAgEdGnz599Pzzz6tWrVoP7TI9iREnAAAAAI+Q8PDwNE1EkdEYcQIAAAAAEwQnAAAAADBBcAIAAAAAE9zjBAAA8ATLKl9RUsDLUcPq5FGc+xVZnG49tP2WL5jjoe0LjzZGnAAAAADABCNOAPCEyiqfMtsTX4QNAEgrghMAAACytPIzAh7ezrqve3j7yir8nrZ3BY8ELtUDAAAA7oOlQKVUH11Cht73tgtXa6IJX81Jc/+PJs6Uo38VffxF2H3vE6ljxAkA8OQa5m3vCuxr2GV7VwA80qJ3rrT+O2LJSg353zQdXL/Q2ubu5vrQagmLWKIBvTpr1rwfNbDP6w9tvymJi4uTi4uLXWvIDIw4AQAAAPchX55c1oe3VzZZLLZt6zfvUOUXO8ityLMqUr2Zho/7UgkJCdb1h302TYWeaSzXwGryq9RAfT8cK0mq3foNHT8RrX7DPrOOXqXm103bdfNWrEa801PXb97U+s3bbZYnJSXpk8nhKvZcc7kGVlOhZxpr9OczrMtPnDih9u3by8fHR56enqpSpYq2bNkiSerSpYtatmxps72QkBDVrl3b+rx27drq06eP+vfvr1y5cql+/fqSpHHjxqlcuXLy9PSUv7+/evXqpWvXrtls6/fff1etWrXk4eGhnDlzqmHDhrp48aJmz54tX19fxcbG2vRv1aqVOnXqlOr7kVkITgAAAEAG+2XdRnXs+6H6dn1F+9f+oC8/Gazw73/S6IkzJUk/LF2l8V99py8/GaxDvy3W4pnjVK5UMUnSwq/+p4L582rEO28qeudKm5GtlMycu1ivtGwoZ2dnvdLiRc2c+6PN8kFjJumTKeH68O03tH/tD/pu8mjlze0rSbp2/YZq1aqlU6dOacmSJdq9e7cGDBigpKSkdL3er7/+Wk5OTvr999/15ZdfSpIcHBw0ceJE7d27V19//bXWrFmjAQMGWNfZtWuX6tatq6eeekqbNm3Sb7/9pmbNmikxMVFt2rRRYmKilixZYu1//vx5LV26VK+/bp8RNS7VAwAAADLY6IkzNbB3F3Vu20ySVCSgoEa++6YGjP5cQ/v3UNTJ08qX21f1alSVs7OzChXIr6pPl5Uk+eT0lqOjg7yyeShfnlyp7ufK1WtasGy1Nv4YLknq+HJjPdfydU0aNUDZvbLp6rXr+nzmXH0x6j1rLUUL++v5qrcnhPhu0XKdO3dOW7dulY+PjySpWLFi6X69xYoV09ixY23aQkJCrP8ODAzUyJEj9eabb2rKlCmSpLFjx6pKlSrW55L01FNPWf/doUMHhYWFqU2bNpKkOXPmqGDBgjajXQ8TI04AAABABtv+5wGNmPCVshV/zvp4Y8AoRZ85rxs3b6pN03q6eStWRao31xvvjtSi5WtsLuNLq+8WrVCRgIKq8FQJSVLFsiVVJKCg5v34iyTpwKGjio2NU93nq6a4/q59f+vpp5+2hqb7VaVKlWRta9euVf369VWgQAF5eXmpU6dOiomJ0fXr12/v+/+PON3LG2+8oZUrV+rkyZOSpLCwMHXp0kUWi+WBar1fjDgBAAAAGSzJMDQ8tIdebvRCsmVurq7yL5BPB9cvVOSGLVq1YYt6vf+xPp06W78u+ErOzs5p3s+siB+17+A/cir0zP/tOylJM+f9qO4dW5lOUGG23MHBQYZh2LTFx8cn6+fp6Wnz/Pjx42rcuLF69uypkSNHysfHR7/99pu6detmXd/d3T3VfT/99NOqUKGCZs+erYYNG2rPnj366aefUl0nMxGcAAAAgAxWqWwpHfznuIoFFrpnH3d3NzVvUEvNG9RS785tVarWy9rz12FVKldaLs7OSkxM/T6jPQcOadvu/Vr3w3T55Pi/WUIvXbmqmi8Ha+9fh1U8sJDc3dy0+rc/FNzhpWTbKF+6uGbMW6ILFy6kOOqUO3du7d2716Zt165dpuFu27ZtSkhI0GeffSYHh9sXuX3//fe2+y5fXqtXr9bw4cPvuZ3g4GCNHz9eJ0+eVL169eTv75/qfjMTl+oBAAAAGWxIvzc0+4efNeyzadp38B8dOHREET/+og8+mSxJCo9YoplzF2vvX4d15PgJfbPgZ7m7uSmgQH5JUmF/P63fskMno8/q/IWLKe5j5tzFqlrxKdV8trLKlipmfTxf9WlVr1xeM+culpubq97r3VkDRn+u2fOX6p9j/2rz9j81c+5iSdIrLV9Uvnz51LJlS/3+++86cuSIFixYoE2bNkmSXnjhBW3btk2zZ8/WoUOHNHTo0GRBKiVFixZVQkKCJk2apCNHjuibb77RtGnTbPoMGjRIW7duVa9evfTnn3/qr7/+0tSpU3X+/Hlrn1dffVUnT57UV199pa5du6b755CRGHECAABAlvZn8PFM23Z5h6OZst2GtYO09OsJGjH+K42dMlvOzk4qVaywgl9pKUnK4e2lj78IU//h45SYmKhypYrpp/Dx8vXJIUka8U5P9XhvtIo+11yxsXEyTu6w2X5cXLy+Xbhc7/XunOL+WzWuqzFfzNIng9/WhyFvyMnRUUP+N1WnzpxT/jy51PO11pIkFxdnrVy5UqGhoWrcuLESEhJUpkwZTZ58O+A1bNhQH374oQYMGKBbt26pa9eu6tSpk/bs2ZPq669YsaLGjRunTz75RIMGDVLNmjU1ZswYm6nES5QooZUrV+r9999X1apV5e7urmrVqumVV16x9smePbtatWqln3/+Odm06A+bxbj7osXH3JUrV+Tt7a3Lly8re/bs9i7HbgoP/NneJdjdMbcO9i7Bvvjiyyce5wHOA5wHIGWdc0EBL0cNq5NHefwKyuL08L48NbOC0yPF72l7V5Cq+vXrq3Tp0po4ceJ9rX/r1i0dPXpUgYGBcnNzs1mWnmzAiBMAAACALOfChQtauXKl1qxZoy+++MLe5RCcAAAAAGQ9lSpV0sWLF/XJJ5+oZMmS9i6H4AQAAAAg6zl27Ji9S7DBrHoAAAAAYILgBAAAALtLMiTJkJ6secvwEGTUXHgEJwAAANjdpVtJik80ZCTE2bsUPGbi4m4fU46Ojg+0He5xAgAAgN3dTDC0+sg1NXVxVE4f3Z6S3GLJ9P3ecmCES7du2buCTJOUlKRz587Jw8NDTk4PFn0ITgAAAMgSFh64LkmqWyRRzo4WSZkfnFws5zJ9H1ne9cf7u6wcHBxUqFAhWR4wiBOcAAAAkCUYkhYcuK6fD91QTjcHOWR+btJq13cyfydZXZ9t9q4gU7m4uMjB4cHvUCI4AQAAIEu5lWAo+lriQ9mXW/y/D2U/WZqbm70reCQwOQQAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmLB7cJoyZYoCAwPl5uamypUra8OGDan2nzNnjipUqCAPDw/lz59fr7/+umJiYh5StQAAAACeRHYNThEREQoJCdHgwYO1c+dO1ahRQ40aNVJUVFSK/X/77Td16tRJ3bp10759+zR//nxt3bpVwcHBD7lyAAAAAE8SuwancePGqVu3bgoODlbp0qU1YcIE+fv7a+rUqSn237x5swoXLqy+ffsqMDBQzz//vHr06KFt27Y95MoBAAAAPEnsFpzi4uK0fft2NWjQwKa9QYMG2rhxY4rrBAUF6cSJE1q2bJkMw9CZM2f0ww8/qEmTJvfcT2xsrK5cuWLzAAAAAID0sFtwOn/+vBITE5U3b16b9rx58+r06dMprhMUFKQ5c+aoXbt2cnFxUb58+ZQjRw5NmjTpnvsZM2aMvL29rQ9/f/8MfR0AAAAAHn92nxzCYrHYPDcMI1nbHfv371ffvn01ZMgQbd++XStWrNDRo0fVs2fPe25/0KBBunz5svXx77//Zmj9AAAAAB5/Tvbaca5cueTo6JhsdOns2bPJRqHuGDNmjJ577jm9++67kqTy5cvL09NTNWrU0KhRo5Q/f/5k67i6usrV1TXjXwAAAACAJ4bdRpxcXFxUuXJlRUZG2rRHRkYqKCgoxXVu3LghBwfbkh0dHSXdHqkCAAAAgMxg10v1+vfvrxkzZmjWrFk6cOCA+vXrp6ioKOuld4MGDVKnTp2s/Zs1a6aFCxdq6tSpOnLkiH7//Xf17dtXVatWlZ+fn71eBgAAAIDHnN0u1ZOkdu3aKSYmRiNGjFB0dLTKli2rZcuWKSAgQJIUHR1t851OXbp00dWrV/XFF18oNDRUOXLk0AsvvKBPPvnEXi8BAAAAwBPArsFJknr16qVevXqluCw8PDxZ21tvvaW33nork6sCAAAAgP9j91n1AAAAACCrIzgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAmCEwAAAACYIDgBAAAAgAm7B6cpU6YoMDBQbm5uqly5sjZs2JBq/9jYWA0ePFgBAQFydXVV0aJFNWvWrIdULQAAAIAnkZM9dx4REaGQkBBNmTJFzz33nL788ks1atRI+/fvV6FChVJcp23btjpz5oxmzpypYsWK6ezZs0pISHjIlQMAAAB4ktg1OI0bN07dunVTcHCwJGnChAn65ZdfNHXqVI0ZMyZZ/xUrVujXX3/VkSNH5OPjI0kqXLhwqvuIjY1VbGys9fmVK1cy7gUAAAAAeCLY7VK9uLg4bd++XQ0aNLBpb9CggTZu3JjiOkuWLFGVKlU0duxYFShQQCVKlNA777yjmzdv3nM/Y8aMkbe3t/Xh7++foa8DAAAAwOPPbiNO58+fV2JiovLmzWvTnjdvXp0+fTrFdY4cOaLffvtNbm5uWrRokc6fP69evXrpwoUL97zPadCgQerfv7/1+ZUrVwhPAAAAANLFrpfqSZLFYrF5bhhGsrY7kpKSZLFYNGfOHHl7e0u6fblf69atNXnyZLm7uydbx9XVVa6urhlfOAAAAIAnht0u1cuVK5ccHR2TjS6dPXs22SjUHfnz51eBAgWsoUmSSpcuLcMwdOLEiUytFwAAAMCTy27BycXFRZUrV1ZkZKRNe2RkpIKCglJc57nnntOpU6d07do1a9vff/8tBwcHFSxYMFPrBQAAAPDksuv3OPXv318zZszQrFmzdODAAfXr109RUVHq2bOnpNv3J3Xq1Mnav0OHDvL19dXrr7+u/fv3a/369Xr33XfVtWvXFC/TAwAAAICMYNd7nNq1a6eYmBiNGDFC0dHRKlu2rJYtW6aAgABJUnR0tKKioqz9s2XLpsjISL311luqUqWKfH191bZtW40aNcpeLwEAAADAE8Duk0P06tVLvXr1SnFZeHh4srZSpUolu7wPAAAAADKTXS/VAwAAAIBHAcEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADARLqDU+HChTVixAhFRUVlRj0AAAAAkOWkOziFhobqxx9/VJEiRVS/fn3NmzdPsbGxmVEbAAAAAGQJ6Q5Ob731lrZv367t27erTJky6tu3r/Lnz68+ffpox44dmVEjAAAAANjVfd/jVKFCBX3++ec6efKkhg4dqhkzZuiZZ55RhQoVNGvWLBmGkZF1AgAAAIDdON3vivHx8Vq0aJHCwsIUGRmpZ599Vt26ddOpU6c0ePBgrVq1St99911G1goAAAAAdpHu4LRjxw6FhYVp7ty5cnR01Guvvabx48erVKlS1j4NGjRQzZo1M7RQAAAAALCXdAenZ555RvXr19fUqVPVsmVLOTs7J+tTpkwZtW/fPkMKBAAAAAB7S3dwOnLkiAICAlLt4+npqbCwsPsuCgAAAACyknRPDnH27Flt2bIlWfuWLVu0bdu2DCkKAAAAALKSdAen3r17699//03WfvLkSfXu3TtDigIAAACArCTdwWn//v2qVKlSsvann35a+/fvz5CiAAAAACArSXdwcnV11ZkzZ5K1R0dHy8npvmc3BwAAAIAsK93BqX79+ho0aJAuX75sbbt06ZLef/991a9fP0OLAwAAAICsIN1DRJ999plq1qypgIAAPf3005KkXbt2KW/evPrmm28yvEAAAAAAsLd0B6cCBQrozz//1Jw5c7R79265u7vr9ddf1yuvvJLidzoBAAAAwKPuvm5K8vT0VPfu3TO6FgAAAADIku57Nof9+/crKipKcXFxNu3Nmzd/4KIAAAAAICtJd3A6cuSIXnrpJe3Zs0cWi0WGYUiSLBaLJCkxMTFjKwQAAAAAO0v3rHpvv/22AgMDdebMGXl4eGjfvn1av369qlSponXr1mVCiQAAAABgX+kecdq0aZPWrFmj3Llzy8HBQQ4ODnr++ec1ZswY9e3bVzt37syMOgEAAADAbtI94pSYmKhs2bJJknLlyqVTp05JkgICAnTw4MGMrQ4AAAAAsoB0jziVLVtWf/75p4oUKaJq1app7NixcnFx0fTp01WkSJHMqBEAAAAA7CrdwemDDz7Q9evXJUmjRo1S06ZNVaNGDfn6+ioiIiLDCwQAAAAAe0t3cGrYsKH130WKFNH+/ft14cIF5cyZ0zqzHgAAAAA8TtJ1j1NCQoKcnJy0d+9em3YfHx9CEwAAAIDHVrqCk5OTkwICAviuJgAAAABPlHTPqvfBBx9o0KBBunDhQmbUAwAAAABZTrrvcZo4caIOHz4sPz8/BQQEyNPT02b5jh07Mqw4AAAAAMgK0h2cWrZsmQllAAAAAEDWle7gNHTo0MyoAwAAAACyrHTf4wQAAAAAT5p0jzg5ODikOvU4M+4BAAAAeNykOzgtWrTI5nl8fLx27typr7/+WsOHD8+wwgAAAAAgq0h3cGrRokWyttatW+upp55SRESEunXrliGFAQAAAEBWkWH3OFWrVk2rVq3KqM0BAAAAQJaRIcHp5s2bmjRpkgoWLJgRmwMAAACALCXdl+rlzJnTZnIIwzB09epVeXh46Ntvv83Q4gAAAAAgK0h3cBo/frxNcHJwcFDu3LlVrVo15cyZM0OLAwAAAICsIN3BqUuXLplQBgAAAABkXem+xyksLEzz589P1j5//nx9/fXXGVIUAAAAAGQl6Q5OH3/8sXLlypWsPU+ePProo48ypCgAAAAAyErSHZyOHz+uwMDAZO0BAQGKiorKkKIAAAAAICtJd3DKkyeP/vzzz2Ttu3fvlq+vb4YUBQAAAABZSbqDU/v27dW3b1+tXbtWiYmJSkxM1Jo1a/T222+rffv2mVEjAAAAANhVumfVGzVqlI4fP666devKyen26klJSerUqRP3OAEAAAB4LKU7OLm4uCgiIkKjRo3Srl275O7urnLlyikgICAz6gMAAAAAu0t3cLqjePHiKl68eEbWAgAAAABZUrrvcWrdurU+/vjjZO2ffvqp2rRpkyFFAQAAAEBWku7g9Ouvv6pJkybJ2l988UWtX78+Q4oCAAAAgKwk3cHp2rVrcnFxSdbu7OysK1euZEhRAAAAAJCVpDs4lS1bVhEREcna582bpzJlymRIUQAAAACQlaR7cogPP/xQrVq10j///KMXXnhBkrR69Wp99913+uGHHzK8QAAAAACwt3QHp+bNm2vx4sX66KOP9MMPP8jd3V0VKlTQmjVrlD179syoEQAAAADs6r6mI2/SpIl1gohLly5pzpw5CgkJ0e7du5WYmJihBQIAAACAvaX7Hqc71qxZo44dO8rPz09ffPGFGjdurG3btmVkbQAAAACQJaRrxOnEiRMKDw/XrFmzdP36dbVt21bx8fFasGABE0MAAAAAeGylecSpcePGKlOmjPbv369Jkybp1KlTmjRpUmbWBgAAAABZQppHnFauXKm+ffvqzTffVPHixTOzJgAAAADIUtI84rRhwwZdvXpVVapUUbVq1fTFF1/o3LlzmVkbAAAAAGQJaQ5O1atX11dffaXo6Gj16NFD8+bNU4ECBZSUlKTIyEhdvXo1M+sEAAAAALtJ96x6Hh4e6tq1q3777Tft2bNHoaGh+vjjj5UnTx41b948M2oEAAAAALu67+nIJalkyZIaO3asTpw4oblz52ZUTQAAAACQpTxQcLrD0dFRLVu21JIlSzJicwAAAACQpWRIcAIAAACAxxnBCQAAAABMEJwAAAAAwITdg9OUKVMUGBgoNzc3Va5cWRs2bEjTer///rucnJxUsWLFzC0QAAAAwBPPrsEpIiJCISEhGjx4sHbu3KkaNWqoUaNGioqKSnW9y5cvq1OnTqpbt+5DqhQAAADAk8yuwWncuHHq1q2bgoODVbp0aU2YMEH+/v6aOnVqquv16NFDHTp0UPXq1R9SpQAAAACeZHYLTnFxcdq+fbsaNGhg096gQQNt3LjxnuuFhYXpn3/+0dChQ9O0n9jYWF25csXmAQAAAADpYbfgdP78eSUmJipv3rw27Xnz5tXp06dTXOfQoUMaOHCg5syZIycnpzTtZ8yYMfL29rY+/P39H7h2AAAAAE8Wu08OYbFYbJ4bhpGsTZISExPVoUMHDR8+XCVKlEjz9gcNGqTLly9bH//+++8D1wwAAADgyZK2YZtMkCtXLjk6OiYbXTp79myyUShJunr1qrZt26adO3eqT58+kqSkpCQZhiEnJyetXLlSL7zwQrL1XF1d5erqmjkvAgAAAMATwW4jTi4uLqpcubIiIyNt2iMjIxUUFJSsf/bs2bVnzx7t2rXL+ujZs6dKliypXbt2qVq1ag+rdAAAAABPGLuNOElS//799dprr6lKlSqqXr26pk+frqioKPXs2VPS7cvsTp48qdmzZ8vBwUFly5a1WT9Pnjxyc3NL1g4AAAAAGcmuwaldu3aKiYnRiBEjFB0drbJly2rZsmUKCAiQJEVHR5t+pxMAAAAAZDa7BidJ6tWrl3r16pXisvDw8FTXHTZsmIYNG5bxRQEAAADAf9h9Vj0AAAAAyOoITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgguAEAAAAACYITgAAAABgwu7BacqUKQoMDJSbm5sqV66sDRs23LPvwoULVb9+feXOnVvZs2dX9erV9csvvzzEagEAAAA8iewanCIiIhQSEqLBgwdr586dqlGjhho1aqSoqKgU+69fv17169fXsmXLtH37dtWpU0fNmjXTzp07H3LlAAAAAJ4kdg1O48aNU7du3RQcHKzSpUtrwoQJ8vf319SpU1PsP2HCBA0YMEDPPPOMihcvro8++kjFixfXTz/99JArBwAAAPAksVtwiouL0/bt29WgQQOb9gYNGmjjxo1p2kZSUpKuXr0qHx+fe/aJjY3VlStXbB4AAAAAkB52C07nz59XYmKi8ubNa9OeN29enT59Ok3b+Oyzz3T9+nW1bdv2nn3GjBkjb29v68Pf3/+B6gYAAADw5LH75BAWi8XmuWEYydpSMnfuXA0bNkwRERHKkyfPPfsNGjRIly9ftj7+/fffB64ZAAAAwJPFyV47zpUrlxwdHZONLp09ezbZKNTdIiIi1K1bN82fP1/16tVLta+rq6tcXV0fuF4AAAAATy67jTi5uLiocuXKioyMtGmPjIxUUFDQPdebO3euunTpou+++05NmjTJ7DIBAAAAwH4jTpLUv39/vfbaa6pSpYqqV6+u6dOnKyoqSj179pR0+zK7kydPavbs2ZJuh6ZOnTrp888/17PPPmsdrXJ3d5e3t7fdXgcAAACAx5tdg1O7du0UExOjESNGKDo6WmXLltWyZcsUEBAgSYqOjrb5Tqcvv/xSCQkJ6t27t3r37m1t79y5s8LDwx92+QAAAACeEHYNTpLUq1cv9erVK8Vld4ehdevWZX5BAAAAAHAXu8+qBwAAAABZHcEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEwQnAAAAADABMEJAAAAAEzYPThNmTJFgYGBcnNzU+XKlbVhw4ZU+//666+qXLmy3NzcVKRIEU2bNu0hVQoAAADgSWXX4BQREaGQkBANHjxYO3fuVI0aNdSoUSNFRUWl2P/o0aNq3LixatSooZ07d+r9999X3759tWDBgodcOQAAAIAniV2D07hx49StWzcFBwerdOnSmjBhgvz9/TV16tQU+0+bNk2FChXShAkTVLp0aQUHB6tr16763//+95ArBwAAAPAkcbLXjuPi4rR9+3YNHDjQpr1BgwbauHFjiuts2rRJDRo0sGlr2LChZs6cqfj4eDk7OydbJzY2VrGxsdbnly9fliRduXLlQV/CIy0p9oa9S7C7KxbD3iXY1xP+OwDOAxLnAc4DkDgXPPHnAemJPhfcyQSGYX4c2C04nT9/XomJicqbN69Ne968eXX69OkU1zl9+nSK/RMSEnT+/Hnlz58/2TpjxozR8OHDk7X7+/s/QPV4HHjbuwB7+/iJfwcAzgOcBwDOAxLnAklXr16Vt3fq74PdgtMdFovF5rlhGMnazPqn1H7HoEGD1L9/f+vzpKQkXbhwQb6+vqnuB4+3K1euyN/fX//++6+yZ89u73IA2AHnAQCcB2AYhq5evSo/Pz/TvnYLTrly5ZKjo2Oy0aWzZ88mG1W6I1++fCn2d3Jykq+vb4rruLq6ytXV1aYtR44c9184HivZs2fnRAk84TgPAOA88GQzG2m6w26TQ7i4uKhy5cqKjIy0aY+MjFRQUFCK61SvXj1Z/5UrV6pKlSop3t8EAAAAABnBrrPq9e/fXzNmzNCsWbN04MAB9evXT1FRUerZs6ek25fZderUydq/Z8+eOn78uPr3768DBw5o1qxZmjlzpt555x17vQQAAAAATwC73uPUrl07xcTEaMSIEYqOjlbZsmW1bNkyBQQESJKio6NtvtMpMDBQy5YtU79+/TR58mT5+flp4sSJatWqlb1eAh5Rrq6uGjp0aLLLOAE8OTgPAOA8gPSwGGmZew8AAAAAnmB2vVQPAAAAAB4FBCcAAAAAMEFwAgAAAAATBCdkGRaLRYsXL870/axbt04Wi0WXLl2yti1evFjFihWTo6OjQkJCFB4ezvd9AXbCuQAA5wFkRQQnPBSnT5/WW2+9pSJFisjV1VX+/v5q1qyZVq9e/dBrCQoKUnR0tM2XnfXo0UOtW7fWv//+q5EjR6pdu3b6+++/M2X/CxcuVMOGDZUrVy5ZLBbt2rUrU/YDZEWcC26Lj4/Xe++9p3LlysnT01N+fn7q1KmTTp06leH7ArIazgP/Z9iwYSpVqpQ8PT2VM2dO1atXT1u2bMmUfeHB2XU6cjwZjh07pueee045cuTQ2LFjVb58ecXHx+uXX35R79699ddffz3UelxcXJQvXz7r82vXruns2bNq2LCh/Pz8rO3u7u4PtJ/4+PgUv5j5+vXreu6559SmTRu98cYbD7QP4FHCueD/3LhxQzt27NCHH36oChUq6OLFiwoJCVHz5s21bdu2B9ofkJVxHrBVokQJffHFFypSpIhu3ryp8ePHq0GDBjp8+LBy5879QPtEJjCATNaoUSOjQIECxrVr15Itu3jxovXfkoxFixZZnw8YMMAoXry44e7ubgQGBhoffPCBERcXZ12+a9cuo3bt2ka2bNkMLy8vo1KlSsbWrVsNwzCMY8eOGU2bNjVy5MhheHh4GGXKlDF+/vlnwzAMY+3atYYk4+LFi9Z///exdu1aIywszPD29rapdcmSJUalSpUMV1dXIzAw0Bg2bJgRHx9vU//UqVON5s2bGx4eHsaQIUNSfV+OHj1qSDJ27tyZxncSeLRxLkjdH3/8YUgyjh8/nqb+wKOI80DqLl++bEgyVq1alab+eLgYcUKmunDhglasWKHRo0fL09Mz2fLUrhn28vJSeHi4/Pz8tGfPHr3xxhvy8vLSgAEDJEmvvvqqnn76aU2dOlWOjo7atWuX9dOc3r17Ky4uTuvXr5enp6f279+vbNmyJdtHUFCQDh48qJIlS2rBggUKCgqSj4+Pjh07ZtPvl19+UceOHTVx4kTVqFFD//zzj7p37y5JGjp0qLXf0KFDNWbMGI0fP16Ojo7pfbuAxxbnAnOXL1+WxWLhXgo8tjgPpC4uLk7Tp0+Xt7e3KlSoYNofdmDv5IbH25YtWwxJxsKFC0376q5Pl+42duxYo3LlytbnXl5eRnh4eIp9y5UrZwwbNizFZf/9dMkwbn/Cpf//qdIdd3+6VKNGDeOjjz6y2c4333xj5M+f36b+kJCQe9Z/N0ac8CThXJC6mzdvGpUrVzZeffXVdK0HPEo4D6Tsp59+Mjw9PQ2LxWL4+fkZf/zxR5rWw8PHiBMylWEYkm7PjpNeP/zwgyZMmKDDhw/r2rVrSkhIUPbs2a3L+/fvr+DgYH3zzTeqV6+e2rRpo6JFi0qS+vbtqzfffFMrV65UvXr11KpVK5UvX/6+X8f27du1detWjR492tqWmJioW7du6caNG/Lw8JAkValS5b73ATzOOBfcW3x8vNq3b6+kpCRNmTLlvmsDsjrOAymrU6eOdu3apfPnz+urr75S27ZttWXLFuXJk+e+a0TmYFY9ZKrixYvLYrHowIED6Vpv8+bNat++vRo1aqSlS5dq586dGjx4sOLi4qx9hg0bpn379qlJkyZas2aNypQpo0WLFkmSgoODdeTIEb322mvas2ePqlSpokmTJt3360hKStLw4cO1a9cu62PPnj06dOiQ3NzcrP1SuvQAAOeCe4mPj1fbtm119OhRRUZG2vwhCDxuOA+kzNPTU8WKFdOzzz6rmTNnysnJSTNnzrzv+pB5CE7IVD4+PmrYsKEmT56s69evJ1v+3+9N+K/ff/9dAQEBGjx4sKpUqaLixYvr+PHjyfqVKFFC/fr108qVK/Xyyy8rLCzMuszf3189e/bUwoULFRoaqq+++uq+X0elSpV08OBBFStWLNnDwYFfI8AM54Lk7oSmQ4cOadWqVfL19b3vuoBHAeeBtDEMQ7GxsQ+8HWQ8LtVDppsyZYqCgoJUtWpVjRgxQuXLl1dCQoIiIyM1derUFD95KlasmKKiojRv3jw988wz+vnnn62fHEnSzZs39e6776p169YKDAzUiRMntHXrVrVq1UqSFBISokaNGqlEiRK6ePGi1qxZo9KlS9/3axgyZIiaNm0qf39/tWnTRg4ODvrzzz+1Z88ejRo1Kl3bunDhgqKioqzf13Lw4EFJUr58+WymRAUeN5wL/k9CQoJat26tHTt2aOnSpUpMTNTp06cl3f7j0sXF5b5rBLIyzgP/5/r16xo9erSaN2+u/PnzKyYmRlOmTNGJEyfUpk2b+64Pmci+t1jhSXHq1Cmjd+/eRkBAgOHi4mIUKFDAaN68uc3Nl7rrRtB3333X8PX1NbJly2a0a9fOGD9+vPXmzNjYWKN9+/aGv7+/4eLiYvj5+Rl9+vQxbt68aRiGYfTp08coWrSo4erqauTOndt47bXXjPPnzxuGcX83ghqGYaxYscIICgoy3N3djezZsxtVq1Y1pk+ffs/67yUsLCzZdKeSjKFDh6b17QQeWZwLbrszOUxKj//uH3gccR647ebNm8ZLL71k+Pn5GS4uLkb+/PmN5s2bMzlEFmYxjP9/px4AAAAAIEXcnAEAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAAAAAJghOAAAAAGCC4AQAeCRYLBYtXrw40/ezbt06WSwWXbp0ydq2ePFiFStWTI6OjgoJCVF4eLhy5MiR6bUAALIOghMAIEs4ffq03nrrLRUpUkSurq7y9/dXs2bNtHr16odaR1BQkKKjo+Xt7W1t69Gjh1q3bq1///1XI0eOVLt27fT3338/1LoAAPblZO8CAAA4duyYnnvuOeXIkUNjx45V+fLlFR8fr19++UW9e/fWX3/99dBqcXFxUb58+azPr127prNnz6phw4by8/Oztru7uz/QfuLj4+Xs7PxA2wAAPDyMOAEA7K5Xr16yWCz6448/1Lp1a5UoUUJPPfWU+vfvr82bN6e4znvvvacSJUrIw8NDRYoU0Ycffqj4+Hjr8t27d6tOnTry8vJS9uzZVblyZW3btk2SdPz4cTVr1kw5c+aUp6ennnrqKS1btkyS7aV669atk5eXlyTphRdekMVi0bp161K8VO+nn35S5cqV5ebmpiJFimj48OFKSEiwLrdYLJo2bZpatGghT09PjRo1KiPfQgBAJmPECQBgVxcuXNCKFSs0evRoeXp6Jlt+r3uJvLy8FB4eLj8/P+3Zs0dvvPGGvLy8NGDAAEnSq6++qqefflpTp06Vo6Ojdu3aZR3h6d27t+Li4rR+/Xp5enpq//79ypYtW7J9BAUF6eDBgypZsqQWLFigoKAg+fj46NixYzb9fvnlF3Xs2FETJ05UjRo19M8//6h79+6SpKFDh1r7DR06VGPGjNH48ePl6Oh4P28XAMBOCE4AALs6fPiwDMNQqVKl0rXeBx98YP134cKFFRoaqoiICGtwioqK0rvvvmvdbvHixa39o6Ki1KpVK5UrV06SVKRIkRT34eLiojx58kiSfHx8bC7h+6/Ro0dr4MCB6ty5s3V7I0eO1IABA2yCU4cOHdS1a9d0vU4AQNZAcAIA2JVhGJJuX8qWHj/88IMmTJigw4cP69q1a0pISFD27Nmty/v376/g4GB98803qlevntq0aaOiRYtKkvr27as333xTK1euVL169dSqVSuVL1/+vl/D9u3btXXrVo0ePdralpiYqFu3bunGjRvy8PCQJFWpUuW+9wEAsC/ucQIA2FXx4sVlsVh04MCBNK+zefNmtW/fXo0aNdLSpUu1c+dODR48WHFxcdY+w4YN0759+9SkSROtWbNGZcqU0aJFiyRJwcHBOnLkiF577TXt2bNHVapU0aRJk+77NSQlJWn48OHatWuX9bFnzx4dOnRIbm5u1n4pXYoIAHg0EJwAAHbl4+Ojhg0bavLkybp+/Xqy5f/9PqU7fv/9dwUEBGjw4MGqUqWKihcvruPHjyfrV6JECfXr108rV67Uyy+/rLCwMOsyf39/9ezZUwsXLlRoaKi++uqr+34NlSpV0sGDB1WsWLFkDwcH/qsFgMcBZ3MAgN1NmTJFiYmJqlq1qhYsWKBDhw7pwIEDmjhxoqpXr56sf7FixRQVFaV58+bpn3/+0cSJE62jSZJ08+ZN9enTR+vWrdPx48f1+++/a+vWrSpdurQkKSQkRL/88ouOHj2qHTt2aM2aNdZl92PIkCGaPXu2dZTrwIEDioiIsLkPCwDwaCM4AQDsLjAwUDt27FCdOnUUGhqqsmXLqn79+lq9erWmTp2arH+LFi3Ur18/9enTRxUrVtTGjRv14YcfWpc7OjoqJiZGnTp1UokSJdS2bVs1atRIw4cPl3T7/qPevXurdOnSevHFF1WyZElNmTLlvutv2LChli5dqsjISD3zzDN69tlnNW7cOAUEBNz3NgEAWYvFuHNXLgAAAAAgRYw4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAIAJghMAAAAAmCA4AQAAAICJ/weS3ipOg10yHwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the Training vs Testing Accuracy\n",
    "metrics_df.plot(\n",
    "    x=\"Classifier\", \n",
    "    y=[\"Train Accuracy\", \"Test Accuracy\"], \n",
    "    kind=\"bar\", \n",
    "    figsize=(10, 6)\n",
    ")\n",
    "plt.title(\"Training vs Testing Accuracy for Overfitting Analysis\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend([\"Train Accuracy\", \"Test Accuracy\"])\n",
    "plt.show()\n",
    "\n",
    "# Plotting the Accuracy Gap (Training - Testing)\n",
    "metrics_df.plot(\n",
    "    x=\"Classifier\", \n",
    "    y=\"Accuracy Gap\", \n",
    "    kind=\"bar\", \n",
    "    figsize=(10, 6), \n",
    "    color='orange'\n",
    ")\n",
    "plt.title(\"Accuracy Gap (Training - Testing) for Overfitting Analysis\")\n",
    "plt.ylabel(\"Accuracy Gap\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Classifier  Mean Precision  Mean Recall  Mean F1 Score\n",
      "0  Classifier 1        0.880590     0.866406       0.873265\n",
      "1  Classifier 2        0.868011     0.818077       0.839190\n",
      "2  Classifier 3        0.863194     0.822351       0.840920\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display mean Precision, Recall, and F1 Score for each classifier\n",
    "metrics_df[\"Mean Precision\"] = metrics_df[\"Precision\"].apply(lambda x: sum(x) / len(x))\n",
    "metrics_df[\"Mean Recall\"] = metrics_df[\"Recall\"].apply(lambda x: sum(x) / len(x))\n",
    "metrics_df[\"Mean F1 Score\"] = metrics_df[\"F1 Score\"].apply(lambda x: sum(x) / len(x))\n",
    "\n",
    "print(metrics_df[[\"Classifier\", \"Mean Precision\", \"Mean Recall\", \"Mean F1 Score\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conclusions:\n",
      "\n",
      "Classifier 1:\n",
      "  No significant overfitting detected: The model generalizes well on test data.\n",
      "\n",
      "Classifier 2:\n",
      "  No significant overfitting detected: The model generalizes well on test data.\n",
      "\n",
      "Classifier 3:\n",
      "  No significant overfitting detected: The model generalizes well on test data.\n"
     ]
    }
   ],
   "source": [
    "# conclusion based on overfitting analysis\n",
    "print(\"\\nConclusions:\")\n",
    "for index, row in metrics_df.iterrows():\n",
    "    print(f\"\\n{row['Classifier']}:\")\n",
    "    if row['Overfitting']:\n",
    "        print(\"  **Overfitting Detected**: Large accuracy gap between training and testing accuracy.\")\n",
    "        print(\"  Possible causes could be a model that is too complex or lacks regularization.\")\n",
    "    else:\n",
    "        print(\"  No significant overfitting detected: The model generalizes well on test data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers on data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Classifier  Train Accuracy  Test Accuracy\n",
      "0  Classifier 1        0.927101       0.925316\n",
      "1  Classifier 2        0.922040       0.918909\n",
      "2  Classifier 3        0.860380       0.852122\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/HWhr3000/F21DL_Coursework_grp2/main/data/encoded/encoded_data.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Assuming the last column is the target variable and others are features\n",
    "X = data.iloc[:, :-1].values  # Features\n",
    "y = data.iloc[:, -1].values   # Target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Best-performing architecture parameters\n",
    "best_arch = {\n",
    "    \"hidden_layer_sizes\": (64, 64, 32),\n",
    "    \"learning_rate_init\": 0.001,\n",
    "    \"activation\": \"logistic\",\n",
    "    \"random_state\": 42,\n",
    "    \"max_iter\": 500\n",
    "}\n",
    "\n",
    "# Helper function to calculate accuracy\n",
    "def calculate_accuracy(clf, X_train, y_train, X_test, y_test):\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict on the training and test datasets\n",
    "    train_pred = clf.predict(X_train)\n",
    "    test_pred = clf.predict(X_test)\n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "# Store metrics for each classifier\n",
    "metrics = {\n",
    "    \"Classifier\": [],\n",
    "    \"Train Accuracy\": [],\n",
    "    \"Test Accuracy\": []\n",
    "}\n",
    "\n",
    "# Classifier 1 - Using training and testing data\n",
    "clf1 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy = calculate_accuracy(clf1, X_train, y_train, X_test, y_test)\n",
    "\n",
    "metrics[\"Classifier\"].append(\"Classifier 1\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "\n",
    "# Classifier 2 - Moving 30% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "clf2 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy = calculate_accuracy(clf2, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "\n",
    "metrics[\"Classifier\"].append(\"Classifier 2\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "\n",
    "# Classifier 3 - Moving 60% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.6, random_state=42)\n",
    "clf3 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy = calculate_accuracy(clf3, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "\n",
    "metrics[\"Classifier\"].append(\"Classifier 3\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "\n",
    "# Create a DataFrame from the metrics dictionary\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the metrics table\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data for plotting\n",
    "classifiers = ['Classifier 1', 'Classifier 2', 'Classifier 3']\n",
    "train_accuracies = [0.928778, 0.904143, 0.908328]  # Replace with actual training accuracies\n",
    "test_accuracies = [0.922305, 0.898961, 0.902246]  # Replace with actual test accuracies\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(classifiers, train_accuracies, label='Train Accuracy', marker='o', color='blue')\n",
    "plt.plot(classifiers, test_accuracies, label='Test Accuracy', marker='o', color='red')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Training vs Test Accuracy for Different Classifiers', fontsize=14)\n",
    "plt.xlabel('Classifiers', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Classifier  Train Accuracy  Test Accuracy  Precision    Recall  F1 Score  \\\n",
      "0  Classifier 1        0.916572       0.911331   0.912340  0.911331  0.911389   \n",
      "1  Classifier 2        0.902392       0.901136   0.902647  0.901136  0.901124   \n",
      "2  Classifier 3        0.897151       0.895543   0.896469  0.895543  0.895371   \n",
      "\n",
      "   Specificity       AUC  \n",
      "0     0.967693  0.989770  \n",
      "1     0.963591  0.987322  \n",
      "2     0.961218  0.984893  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Best-performing architecture parameters\n",
    "best_arch = {\n",
    "    \"hidden_layer_sizes\": (64, 64, 32),\n",
    "    \"learning_rate_init\": 0.001,\n",
    "    \"activation\": \"logistic\",\n",
    "    \"random_state\": 42,\n",
    "    \"max_iter\": 500\n",
    "}\n",
    "\n",
    "# Helper function to calculate various performance metrics\n",
    "def calculate_metrics(clf, X_train, y_train, X_test, y_test):\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict on the training and test datasets\n",
    "    train_pred = clf.predict(X_train)\n",
    "    test_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    # Precision, Recall, F1-Score for Test Set\n",
    "    precision = precision_score(y_test, test_pred, average='weighted', zero_division=1)\n",
    "    recall = recall_score(y_test, test_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, test_pred, average='weighted')\n",
    "    \n",
    "    # Confusion matrix to calculate Specificity\n",
    "    cm = confusion_matrix(y_test, test_pred)\n",
    "    tn = cm.diagonal().sum() - cm.sum(axis=1)\n",
    "    fp = cm.sum(axis=0) - cm.diagonal()\n",
    "    fn = cm.sum(axis=1) - cm.diagonal()\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # Area Under ROC Curve (AUC) - One-vs-Rest strategy\n",
    "    auc = roc_auc_score(y_test, clf.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"specificity\": specificity.mean(),  # Mean specificity for multi-class\n",
    "        \"auc\": auc\n",
    "    }\n",
    "\n",
    "# Store metrics for each classifier\n",
    "metrics = {\n",
    "    \"Classifier\": [],\n",
    "    \"Train Accuracy\": [],\n",
    "    \"Test Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": [],\n",
    "    \"Specificity\": [],\n",
    "    \"AUC\": []\n",
    "}\n",
    "\n",
    "# Classifier 1 - Using training and testing data\n",
    "clf1 = MLPClassifier(**best_arch)\n",
    "results = calculate_metrics(clf1, X_train, y_train, X_test, y_test)\n",
    "metrics[\"Classifier\"].append(\"Classifier 1\")\n",
    "metrics[\"Train Accuracy\"].append(results[\"train_accuracy\"])\n",
    "metrics[\"Test Accuracy\"].append(results[\"test_accuracy\"])\n",
    "metrics[\"Precision\"].append(results[\"precision\"])\n",
    "metrics[\"Recall\"].append(results[\"recall\"])\n",
    "metrics[\"F1 Score\"].append(results[\"f1_score\"])\n",
    "metrics[\"Specificity\"].append(results[\"specificity\"])\n",
    "metrics[\"AUC\"].append(results[\"auc\"])\n",
    "\n",
    "# Classifier 2 - Moving 30% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "clf2 = MLPClassifier(**best_arch)\n",
    "results = calculate_metrics(clf2, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "metrics[\"Classifier\"].append(\"Classifier 2\")\n",
    "metrics[\"Train Accuracy\"].append(results[\"train_accuracy\"])\n",
    "metrics[\"Test Accuracy\"].append(results[\"test_accuracy\"])\n",
    "metrics[\"Precision\"].append(results[\"precision\"])\n",
    "metrics[\"Recall\"].append(results[\"recall\"])\n",
    "metrics[\"F1 Score\"].append(results[\"f1_score\"])\n",
    "metrics[\"Specificity\"].append(results[\"specificity\"])\n",
    "metrics[\"AUC\"].append(results[\"auc\"])\n",
    "\n",
    "# Classifier 3 - Moving 60% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.6, random_state=42)\n",
    "clf3 = MLPClassifier(**best_arch)\n",
    "results = calculate_metrics(clf3, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "metrics[\"Classifier\"].append(\"Classifier 3\")\n",
    "metrics[\"Train Accuracy\"].append(results[\"train_accuracy\"])\n",
    "metrics[\"Test Accuracy\"].append(results[\"test_accuracy\"])\n",
    "metrics[\"Precision\"].append(results[\"precision\"])\n",
    "metrics[\"Recall\"].append(results[\"recall\"])\n",
    "metrics[\"F1 Score\"].append(results[\"f1_score\"])\n",
    "metrics[\"Specificity\"].append(results[\"specificity\"])\n",
    "metrics[\"AUC\"].append(results[\"auc\"])\n",
    "\n",
    "# Create a DataFrame from the metrics dictionary\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the metrics table\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Classifier  Train Accuracy  Test Accuracy  \\\n",
      "0  Classifier 1        0.927101       0.925316   \n",
      "1  Classifier 2        0.922040       0.918909   \n",
      "2  Classifier 3        0.860380       0.852122   \n",
      "\n",
      "                                           Precision  \\\n",
      "0  [0.9368533713877988, 0.7806748466257669, 0.906...   \n",
      "1  [0.873139974779319, 0.8278041074249605, 0.9220...   \n",
      "2  [0.8622960634635534, 0.8567961165048543, 0.813...   \n",
      "\n",
      "                                              Recall  \\\n",
      "0  [0.845460399227302, 0.7313218390804598, 0.9745...   \n",
      "1  [0.9074705111402359, 0.6186540731995277, 0.947...   \n",
      "2  [0.7582258489076072, 0.41431924882629106, 0.95...   \n",
      "\n",
      "                                            F1 Score  \\\n",
      "0  [0.8888136740565239, 0.755192878338279, 0.9395...   \n",
      "1  [0.889974293059126, 0.7081081081081081, 0.9344...   \n",
      "2  [0.8069192520484628, 0.5585443037974683, 0.879...   \n",
      "\n",
      "                          TP                            TN  \\\n",
      "0   [2626, 509, 10435, 8558]  [20631, 23075, 12136, 14114]   \n",
      "1  [3462, 524, 11927, 10456]  [24378, 27740, 15097, 16546]   \n",
      "2  [5761, 706, 24019, 18419]  [48874, 55570, 26773, 32472]   \n",
      "\n",
      "                       FP                       FN  \n",
      "0   [177, 143, 1070, 396]     [480, 187, 273, 846]  \n",
      "1   [503, 109, 1008, 707]     [353, 323, 664, 987]  \n",
      "2  [920, 118, 5499, 1950]  [1837, 998, 1101, 4551]  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Best-performing architecture parameters\n",
    "best_arch = {\n",
    "    \"hidden_layer_sizes\": (64, 64, 32),\n",
    "    \"learning_rate_init\": 0.001,\n",
    "    \"activation\": \"logistic\",\n",
    "    \"random_state\": 42,\n",
    "    \"max_iter\": 500\n",
    "}\n",
    "\n",
    "# Helper function to calculate accuracy and confusion matrix\n",
    "def calculate_metrics(clf, X_train, y_train, X_test, y_test):\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Predict on the training and test datasets\n",
    "    train_pred = clf.predict(X_train)\n",
    "    test_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score for each class\n",
    "    precision = precision_score(y_test, test_pred, average=None)\n",
    "    recall = recall_score(y_test, test_pred, average=None)\n",
    "    f1 = f1_score(y_test, test_pred, average=None)\n",
    "    \n",
    "    # Confusion matrix (multi-class)\n",
    "    cm = confusion_matrix(y_test, test_pred)\n",
    "    \n",
    "    # Calculate TP, TN, FP, FN for each class\n",
    "    TP = np.diag(cm)\n",
    "    FP = np.sum(cm, axis=0) - TP\n",
    "    FN = np.sum(cm, axis=1) - TP\n",
    "    TN = np.sum(cm) - (FP + FN + TP)\n",
    "    \n",
    "    return train_accuracy, test_accuracy, TP, TN, FP, FN, precision, recall, f1\n",
    "\n",
    "# Store metrics for each classifier\n",
    "metrics = {\n",
    "    \"Classifier\": [],\n",
    "    \"Train Accuracy\": [],\n",
    "    \"Test Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1 Score\": [],\n",
    "    \"TP\": [],\n",
    "    \"TN\": [],\n",
    "    \"FP\": [],\n",
    "    \"FN\": []\n",
    "}\n",
    "\n",
    "# Classifier 1 - Using training and testing data\n",
    "clf1 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy, TP, TN, FP, FN, precision, recall, f1 = calculate_metrics(clf1, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Store metrics\n",
    "metrics[\"Classifier\"].append(\"Classifier 1\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "metrics[\"Precision\"].append(precision)\n",
    "metrics[\"Recall\"].append(recall)\n",
    "metrics[\"F1 Score\"].append(f1)\n",
    "metrics[\"TP\"].append(TP)\n",
    "metrics[\"TN\"].append(TN)\n",
    "metrics[\"FP\"].append(FP)\n",
    "metrics[\"FN\"].append(FN)\n",
    "\n",
    "# Classifier 2 - Moving 30% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "clf2 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy, TP, TN, FP, FN, precision, recall, f1 = calculate_metrics(clf2, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "\n",
    "# Store metrics\n",
    "metrics[\"Classifier\"].append(\"Classifier 2\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "metrics[\"Precision\"].append(precision)\n",
    "metrics[\"Recall\"].append(recall)\n",
    "metrics[\"F1 Score\"].append(f1)\n",
    "metrics[\"TP\"].append(TP)\n",
    "metrics[\"TN\"].append(TN)\n",
    "metrics[\"FP\"].append(FP)\n",
    "metrics[\"FN\"].append(FN)\n",
    "\n",
    "# Classifier 3 - Moving 60% of training data to testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train, y_train, test_size=0.6, random_state=42)\n",
    "clf3 = MLPClassifier(**best_arch)\n",
    "train_accuracy, test_accuracy, TP, TN, FP, FN, precision, recall, f1 = calculate_metrics(clf3, X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "\n",
    "# Store metrics\n",
    "metrics[\"Classifier\"].append(\"Classifier 3\")\n",
    "metrics[\"Train Accuracy\"].append(train_accuracy)\n",
    "metrics[\"Test Accuracy\"].append(test_accuracy)\n",
    "metrics[\"Precision\"].append(precision)\n",
    "metrics[\"Recall\"].append(recall)\n",
    "metrics[\"F1 Score\"].append(f1)\n",
    "metrics[\"TP\"].append(TP)\n",
    "metrics[\"TN\"].append(TN)\n",
    "metrics[\"FP\"].append(FP)\n",
    "metrics[\"FN\"].append(FN)\n",
    "\n",
    "# Create a DataFrame from the metrics dictionary\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the metrics table\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Classifier  Train Accuracy  Test Accuracy  Accuracy Gap\n",
      "0  Classifier 1        0.927101       0.925316      0.001785\n",
      "1  Classifier 2        0.922040       0.918909      0.003131\n",
      "2  Classifier 3        0.860380       0.852122      0.008258\n",
      "     Classifier  Accuracy Gap  Overfitting\n",
      "0  Classifier 1      0.001785        False\n",
      "1  Classifier 2      0.003131        False\n",
      "2  Classifier 3      0.008258        False\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have the data in a DataFrame like metrics_df\n",
    "\n",
    "# Calculate accuracy gap (train accuracy - test accuracy)\n",
    "metrics_df[\"Accuracy Gap\"] = metrics_df[\"Train Accuracy\"] - metrics_df[\"Test Accuracy\"]\n",
    "\n",
    "# Print results for overfitting analysis\n",
    "print(metrics_df[[\"Classifier\", \"Train Accuracy\", \"Test Accuracy\", \"Accuracy Gap\"]])\n",
    "\n",
    "# Threshold for overfitting (you can adjust this based on your dataset or domain knowledge)\n",
    "overfitting_threshold = 0.05\n",
    "\n",
    "# Identify classifiers with potential overfitting\n",
    "metrics_df['Overfitting'] = metrics_df['Accuracy Gap'] > overfitting_threshold\n",
    "print(metrics_df[['Classifier', 'Accuracy Gap', 'Overfitting']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting Analysis:\n",
      "     Classifier  Train Accuracy  Test Accuracy  Accuracy Gap\n",
      "0  Classifier 1        0.916572       0.911331      0.005241\n",
      "1  Classifier 2        0.902392       0.901136      0.001255\n",
      "2  Classifier 3        0.897151       0.895543      0.001608\n",
      "\n",
      "Classifiers with Overfitting Analysis:\n",
      "     Classifier  Accuracy Gap  Overfitting\n",
      "0  Classifier 1      0.005241        False\n",
      "1  Classifier 2      0.001255        False\n",
      "2  Classifier 3      0.001608        False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming metrics_df is already defined with the classifier metrics\n",
    "\n",
    "# Calculate accuracy gap (train accuracy - test accuracy)\n",
    "metrics_df[\"Accuracy Gap\"] = metrics_df[\"Train Accuracy\"] - metrics_df[\"Test Accuracy\"]\n",
    "\n",
    "# Print results for overfitting analysis\n",
    "print(\"Overfitting Analysis:\")\n",
    "print(metrics_df[[\"Classifier\", \"Train Accuracy\", \"Test Accuracy\", \"Accuracy Gap\"]])\n",
    "\n",
    "# Threshold for overfitting (you can adjust this based on your dataset or domain knowledge)\n",
    "overfitting_threshold = 0.05\n",
    "\n",
    "# Identify classifiers with potential overfitting\n",
    "metrics_df['Overfitting'] = metrics_df['Accuracy Gap'] > overfitting_threshold\n",
    "\n",
    "# Print the classifiers with their overfitting status\n",
    "print(\"\\nClassifiers with Overfitting Analysis:\")\n",
    "print(metrics_df[['Classifier', 'Accuracy Gap', 'Overfitting']])\n",
    "\n",
    "# Plotting the Training vs Testing Accuracy\n",
    "metrics_df.plot(\n",
    "    x=\"Classifier\", \n",
    "    y=[\"Train Accuracy\", \"Test Accuracy\"], \n",
    "    kind=\"bar\", \n",
    "    figsize=(10, 6)\n",
    ")\n",
    "plt.title(\"Training vs Testing Accuracy for Overfitting Analysis\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend([\"Train Accuracy\", \"Test Accuracy\"])\n",
    "plt.show()\n",
    "\n",
    "# Plotting the Accuracy Gap (Training - Testing)\n",
    "metrics_df.plot(\n",
    "    x=\"Classifier\", \n",
    "    y=\"Accuracy Gap\", \n",
    "    kind=\"bar\", \n",
    "    figsize=(10, 6), \n",
    "    color='orange'\n",
    ")\n",
    "plt.title(\"Accuracy Gap (Training - Testing) for Overfitting Analysis\")\n",
    "plt.ylabel(\"Accuracy Gap\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Classifier                                     Mean Precision  \\\n",
      "0  Classifier 1  [0.9368533713877988, 0.7806748466257669, 0.906...   \n",
      "1  Classifier 2  [0.873139974779319, 0.8278041074249605, 0.9220...   \n",
      "2  Classifier 3  [0.8622960634635534, 0.8567961165048543, 0.813...   \n",
      "\n",
      "                                         Mean Recall  \\\n",
      "0  [0.845460399227302, 0.7313218390804598, 0.9745...   \n",
      "1  [0.9074705111402359, 0.6186540731995277, 0.947...   \n",
      "2  [0.7582258489076072, 0.41431924882629106, 0.95...   \n",
      "\n",
      "                                       Mean F1 Score  \n",
      "0  [0.8888136740565239, 0.755192878338279, 0.9395...  \n",
      "1  [0.889974293059126, 0.7081081081081081, 0.9344...  \n",
      "2  [0.8069192520484628, 0.5585443037974683, 0.879...  \n"
     ]
    }
   ],
   "source": [
    "# Assuming 'Precision', 'Recall', and 'F1 Score' columns contain a single value for each classifier\n",
    "\n",
    "# Directly assign the values to mean columns since there is no need for averaging (they are already single values)\n",
    "metrics_df[\"Mean Precision\"] = metrics_df[\"Precision\"]\n",
    "metrics_df[\"Mean Recall\"] = metrics_df[\"Recall\"]\n",
    "metrics_df[\"Mean F1 Score\"] = metrics_df[\"F1 Score\"]\n",
    "\n",
    "# Print the updated DataFrame with mean precision, recall, and F1 score\n",
    "print(metrics_df[[\"Classifier\", \"Mean Precision\", \"Mean Recall\", \"Mean F1 Score\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conclusions:\n",
      "\n",
      "Classifier 1:\n",
      "  No significant overfitting detected: The model generalizes well on test data.\n",
      "\n",
      "Classifier 2:\n",
      "  No significant overfitting detected: The model generalizes well on test data.\n",
      "\n",
      "Classifier 3:\n",
      "  No significant overfitting detected: The model generalizes well on test data.\n"
     ]
    }
   ],
   "source": [
    "# Example conclusion based on overfitting analysis\n",
    "print(\"\\nConclusions:\")\n",
    "for index, row in metrics_df.iterrows():\n",
    "    print(f\"\\n{row['Classifier']}:\")\n",
    "    if row['Overfitting']:\n",
    "        print(\"  **Overfitting Detected**: Large accuracy gap between training and testing accuracy.\")\n",
    "        print(\"  Possible causes could be a model that is too complex or lacks regularization.\")\n",
    "    else:\n",
    "        print(\"  No significant overfitting detected: The model generalizes well on test data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategies to Prevent Overfitting in Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1304 - loss: -1904001024.0000 - val_accuracy: 0.1318 - val_loss: -42255937536.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1326 - loss: -105244565504.0000 - val_accuracy: 0.1318 - val_loss: -443628945408.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1319 - loss: -670899765248.0000 - val_accuracy: 0.1318 - val_loss: -1629212114944.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1311 - loss: -2138753728512.0000 - val_accuracy: 0.1318 - val_loss: -4054000861184.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1328 - loss: -4987907735552.0000 - val_accuracy: 0.1318 - val_loss: -8247280926720.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1323 - loss: -9750959882240.0000 - val_accuracy: 0.1318 - val_loss: -14801620172800.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1333 - loss: -16935993475072.0000 - val_accuracy: 0.1318 - val_loss: -24424264761344.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1332 - loss: -27489013334016.0000 - val_accuracy: 0.1318 - val_loss: -37814884368384.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1344 - loss: -42111558746112.0000 - val_accuracy: 0.1318 - val_loss: -55787699306496.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1321 - loss: -61245789044736.0000 - val_accuracy: 0.1318 - val_loss: -79245292339200.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1352 - loss: -86067747225600.0000 - val_accuracy: 0.1318 - val_loss: -109084409856000.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1347 - loss: -117606598049792.0000 - val_accuracy: 0.1318 - val_loss: -146334938038272.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1315 - loss: -157772721160192.0000 - val_accuracy: 0.1318 - val_loss: -191987336609792.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1304 - loss: -207100823207936.0000 - val_accuracy: 0.1318 - val_loss: -247260881354752.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1301 - loss: -264637949935616.0000 - val_accuracy: 0.1318 - val_loss: -313319005093888.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1323 - loss: -334560504053760.0000 - val_accuracy: 0.1318 - val_loss: -391511837507584.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1287 - loss: -416969316630528.0000 - val_accuracy: 0.1318 - val_loss: -483173553143808.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1340 - loss: -507761368498176.0000 - val_accuracy: 0.1318 - val_loss: -589689681608704.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1319 - loss: -622468939120640.0000 - val_accuracy: 0.1318 - val_loss: -712203825053696.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1341 - loss: -746387268435968.0000 - val_accuracy: 0.1318 - val_loss: -852498931777536.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1306 - loss: -896850173362176.0000 - val_accuracy: 0.1318 - val_loss: -1012131323445248.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1310 - loss: -1061924355702784.0000 - val_accuracy: 0.1318 - val_loss: -1192792143429632.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1334 - loss: -1255313848139776.0000 - val_accuracy: 0.1318 - val_loss: -1396423656472576.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1288 - loss: -1471353924354048.0000 - val_accuracy: 0.1318 - val_loss: -1624868135108608.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1331 - loss: -1693682101125120.0000 - val_accuracy: 0.1318 - val_loss: -1880299101224960.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1318 - loss: -1953848402903040.0000 - val_accuracy: 0.1318 - val_loss: -2163629235372032.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1323 - loss: -2249195989762048.0000 - val_accuracy: 0.1318 - val_loss: -2476773958746112.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1333 - loss: -2578643603685376.0000 - val_accuracy: 0.1318 - val_loss: -2822117246631936.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1335 - loss: -2925423289696256.0000 - val_accuracy: 0.1318 - val_loss: -3203190367453184.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1319 - loss: -3316307994869760.0000 - val_accuracy: 0.1318 - val_loss: -3620991364235264.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1310 - loss: -3750081169719296.0000 - val_accuracy: 0.1318 - val_loss: -4076903216447488.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1337 - loss: -4191150688698368.0000 - val_accuracy: 0.1318 - val_loss: -4575452819619840.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1316 - loss: -4737378992259072.0000 - val_accuracy: 0.1318 - val_loss: -5116123703934976.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1327 - loss: -5283828755070976.0000 - val_accuracy: 0.1318 - val_loss: -5703909842616320.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.1315 - loss: -5905620297318400.0000 - val_accuracy: 0.1318 - val_loss: -6338950822100992.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1310 - loss: -6595424794181632.0000 - val_accuracy: 0.1318 - val_loss: -7025115334180864.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1319 - loss: -7240458015080448.0000 - val_accuracy: 0.1318 - val_loss: -7768298758340608.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1346 - loss: -7988727217389568.0000 - val_accuracy: 0.1318 - val_loss: -8566164632371200.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1317 - loss: -8770022570721280.0000 - val_accuracy: 0.1318 - val_loss: -9425547322982400.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1345 - loss: -9709285747458048.0000 - val_accuracy: 0.1318 - val_loss: -10345784868339712.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1330 - loss: -10689073014374400.0000 - val_accuracy: 0.1318 - val_loss: -11331733265842176.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1314 - loss: -11691028754989056.0000 - val_accuracy: 0.1318 - val_loss: -12386116598497280.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1321 - loss: -12690645885911040.0000 - val_accuracy: 0.1318 - val_loss: -13511328236830720.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1315 - loss: -13988589297729536.0000 - val_accuracy: 0.1318 - val_loss: -14706297660243968.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1315 - loss: -15090143182454784.0000 - val_accuracy: 0.1318 - val_loss: -15984595891650560.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1314 - loss: -16333328982474752.0000 - val_accuracy: 0.1318 - val_loss: -17345549694926848.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.1320 - loss: -17723668951990272.0000 - val_accuracy: 0.1318 - val_loss: -18786408143519744.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1318 - loss: -19409489786568704.0000 - val_accuracy: 0.1318 - val_loss: -20315195310080000.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1321 - loss: -20889784624873472.0000 - val_accuracy: 0.1318 - val_loss: -21935183959687168.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m2093/2093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1342 - loss: -22357145169166336.0000 - val_accuracy: 0.1318 - val_loss: -23648558083211264.0000\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1329 - loss: -23640099145121792.0000\n",
      "\u001b[1m1121/1121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1292 - loss: -23705666115862528.0000\n",
      "Train Accuracy with Dropout: 0.13209711015224457\n",
      "Test Accuracy with Dropout: 0.13027235865592957\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define the model with Input layer\n",
    "model_with_dropout = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model_with_dropout.add(Input(shape=(X_train.shape[1],)))  \n",
    "\n",
    "# Hidden layers with Dropout\n",
    "model_with_dropout.add(Dense(64, activation='relu'))\n",
    "model_with_dropout.add(Dropout(0.2))  # Dropout rate of 20%\n",
    "\n",
    "model_with_dropout.add(Dense(64, activation='relu'))\n",
    "model_with_dropout.add(Dropout(0.2))  # Dropout rate of 20%\n",
    "\n",
    "model_with_dropout.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model_with_dropout.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model_with_dropout.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_with_dropout = model_with_dropout.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy_dropout = model_with_dropout.evaluate(X_train, y_train)\n",
    "test_accuracy_dropout = model_with_dropout.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Train Accuracy with Dropout: {train_accuracy_dropout[1]}\")\n",
    "print(f\"Test Accuracy with Dropout: {test_accuracy_dropout[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5389 - loss: 3.7931 - val_accuracy: 0.7284 - val_loss: 1.2451\n",
      "Epoch 2/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7122 - loss: 1.2765 - val_accuracy: 0.6611 - val_loss: 1.0970\n",
      "Epoch 3/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7471 - loss: 0.8942 - val_accuracy: 0.7590 - val_loss: 0.8578\n",
      "Epoch 4/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7695 - loss: 0.7384 - val_accuracy: 0.7356 - val_loss: 0.9204\n",
      "Epoch 5/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8008 - loss: 0.5757 - val_accuracy: 0.8296 - val_loss: 0.4622\n",
      "Epoch 6/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.5050 - val_accuracy: 0.8530 - val_loss: 0.4023\n",
      "Epoch 7/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8402 - loss: 0.4355 - val_accuracy: 0.8199 - val_loss: 0.5394\n",
      "Epoch 8/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.4192 - val_accuracy: 0.8772 - val_loss: 0.3360\n",
      "Epoch 9/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.3890 - val_accuracy: 0.8766 - val_loss: 0.3246\n",
      "Epoch 10/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 0.3602 - val_accuracy: 0.8695 - val_loss: 0.3356\n",
      "Epoch 11/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8740 - loss: 0.3354 - val_accuracy: 0.8766 - val_loss: 0.3358\n",
      "Epoch 12/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.3188 - val_accuracy: 0.8894 - val_loss: 0.2886\n",
      "Epoch 13/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8841 - loss: 0.3065 - val_accuracy: 0.8699 - val_loss: 0.3448\n",
      "Epoch 14/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.3033 - val_accuracy: 0.8950 - val_loss: 0.2778\n",
      "Epoch 15/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8864 - loss: 0.2969 - val_accuracy: 0.8949 - val_loss: 0.2745\n",
      "Epoch 16/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.2868 - val_accuracy: 0.9079 - val_loss: 0.2479\n",
      "Epoch 17/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.2826 - val_accuracy: 0.8934 - val_loss: 0.2775\n",
      "Epoch 18/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.2794 - val_accuracy: 0.9009 - val_loss: 0.2612\n",
      "Epoch 19/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2733 - val_accuracy: 0.8900 - val_loss: 0.2842\n",
      "Epoch 20/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.2694 - val_accuracy: 0.8752 - val_loss: 0.3266\n",
      "Epoch 21/100\n",
      "\u001b[1m2616/2616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8997 - loss: 0.2698 - val_accuracy: 0.8951 - val_loss: 0.2631\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Assuming y_train and y_test are original labels\n",
    "y_train_onehot = to_categorical(y_train, num_classes=5)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "# Build the model with 5 output units for 5 classes\n",
    "model = Sequential()\n",
    "\n",
    "# Use Input layer instead of specifying input_dim in Dense\n",
    "model.add(Input(shape=(X_train.shape[1],)))  # Define the input shape here\n",
    "\n",
    "# Add hidden layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output layer with 5 classes\n",
    "model.add(Dense(5, activation='softmax'))  # 5 units for 5 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_onehot, validation_data=(X_test, y_test_onehot), epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies to Prevent Overfitting in Neural Networks for feature selected data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Type of Travel', 'Online Boarding', 'In-flight Wifi Service',\n",
      "       'Ease of Online Booking', 'Age', 'In-flight Entertainment',\n",
      "       'Flight Distance', 'Departure and Arrival Time Convenience',\n",
      "       'Seat Comfort', 'Class', 'Cleanliness', 'On-board Service',\n",
      "       'Leg Room Service', 'Loyalty'],\n",
      "      dtype='object')\n",
      "Epoch 1/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8220 - loss: 0.4868 - val_accuracy: 0.8999 - val_loss: 0.2775\n",
      "Epoch 2/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8929 - loss: 0.2986 - val_accuracy: 0.9107 - val_loss: 0.2453\n",
      "Epoch 3/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.2738 - val_accuracy: 0.9137 - val_loss: 0.2351\n",
      "Epoch 4/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2614 - val_accuracy: 0.9154 - val_loss: 0.2275\n",
      "Epoch 5/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2560 - val_accuracy: 0.9173 - val_loss: 0.2253\n",
      "Epoch 6/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2506 - val_accuracy: 0.9203 - val_loss: 0.2149\n",
      "Epoch 7/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2437 - val_accuracy: 0.9199 - val_loss: 0.2177\n",
      "Epoch 8/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2421 - val_accuracy: 0.9194 - val_loss: 0.2186\n",
      "Epoch 9/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2393 - val_accuracy: 0.9223 - val_loss: 0.2088\n",
      "Epoch 10/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2319 - val_accuracy: 0.9218 - val_loss: 0.2096\n",
      "Epoch 11/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9153 - loss: 0.2331 - val_accuracy: 0.9245 - val_loss: 0.2045\n",
      "Epoch 12/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2304 - val_accuracy: 0.9225 - val_loss: 0.2061\n",
      "Epoch 13/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2303 - val_accuracy: 0.9246 - val_loss: 0.2037\n",
      "Epoch 14/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2262 - val_accuracy: 0.9244 - val_loss: 0.1988\n",
      "Epoch 15/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2279 - val_accuracy: 0.9257 - val_loss: 0.1987\n",
      "Epoch 16/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2232 - val_accuracy: 0.9267 - val_loss: 0.1965\n",
      "Epoch 17/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2212 - val_accuracy: 0.9274 - val_loss: 0.1967\n",
      "Epoch 18/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2207 - val_accuracy: 0.9259 - val_loss: 0.1987\n",
      "Epoch 19/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2185 - val_accuracy: 0.9264 - val_loss: 0.1980\n",
      "Epoch 20/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2157 - val_accuracy: 0.9261 - val_loss: 0.1973\n",
      "Epoch 21/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2195 - val_accuracy: 0.9263 - val_loss: 0.1966\n",
      "Epoch 22/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2198 - val_accuracy: 0.9293 - val_loss: 0.1888\n",
      "Epoch 23/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.2134 - val_accuracy: 0.9281 - val_loss: 0.1943\n",
      "Epoch 24/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2165 - val_accuracy: 0.9288 - val_loss: 0.1910\n",
      "Epoch 25/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2156 - val_accuracy: 0.9269 - val_loss: 0.1938\n",
      "Epoch 26/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.2135 - val_accuracy: 0.9294 - val_loss: 0.1935\n",
      "Epoch 27/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.2130 - val_accuracy: 0.9295 - val_loss: 0.1881\n",
      "Epoch 28/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2132 - val_accuracy: 0.9291 - val_loss: 0.1901\n",
      "Epoch 29/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.2150 - val_accuracy: 0.9282 - val_loss: 0.1893\n",
      "Epoch 30/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2119 - val_accuracy: 0.9295 - val_loss: 0.1878\n",
      "Epoch 31/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.2153 - val_accuracy: 0.9288 - val_loss: 0.1901\n",
      "Epoch 32/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9205 - loss: 0.2125 - val_accuracy: 0.9302 - val_loss: 0.1872\n",
      "Epoch 33/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.2138 - val_accuracy: 0.9288 - val_loss: 0.1883\n",
      "Epoch 34/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.2091 - val_accuracy: 0.9296 - val_loss: 0.1888\n",
      "Epoch 35/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.2148 - val_accuracy: 0.9302 - val_loss: 0.1882\n",
      "Epoch 36/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.2103 - val_accuracy: 0.9301 - val_loss: 0.1882\n",
      "Epoch 37/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.2090 - val_accuracy: 0.9307 - val_loss: 0.1859\n",
      "Epoch 38/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.2104 - val_accuracy: 0.9293 - val_loss: 0.1895\n",
      "Epoch 39/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2100 - val_accuracy: 0.9323 - val_loss: 0.1859\n",
      "Epoch 40/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2086 - val_accuracy: 0.9314 - val_loss: 0.1850\n",
      "Epoch 41/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9214 - loss: 0.2086 - val_accuracy: 0.9307 - val_loss: 0.1886\n",
      "Epoch 42/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9215 - loss: 0.2099 - val_accuracy: 0.9303 - val_loss: 0.1854\n",
      "Epoch 43/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2078 - val_accuracy: 0.9317 - val_loss: 0.1863\n",
      "Epoch 44/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.2078 - val_accuracy: 0.9306 - val_loss: 0.1868\n",
      "Epoch 45/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.2094 - val_accuracy: 0.9302 - val_loss: 0.1880\n",
      "Epoch 46/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9226 - loss: 0.2075 - val_accuracy: 0.9314 - val_loss: 0.1863\n",
      "Epoch 47/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9221 - loss: 0.2072 - val_accuracy: 0.9307 - val_loss: 0.1886\n",
      "Epoch 48/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9222 - loss: 0.2056 - val_accuracy: 0.9295 - val_loss: 0.1904\n",
      "Epoch 49/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9230 - loss: 0.2086 - val_accuracy: 0.9325 - val_loss: 0.1824\n",
      "Epoch 50/50\n",
      "\u001b[1m4225/4225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.2084 - val_accuracy: 0.9317 - val_loss: 0.1838\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9342 - loss: 0.1730\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.1839\n",
      "Train Accuracy with Dropout: 0.9342900514602661\n",
      "Test Accuracy with Dropout: 0.9300068616867065\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "Class 1:\n",
      "  True Positive (TP): 9606\n",
      "  False Positive (FP): 825\n",
      "  True Negative (TN): 30967\n",
      "  False Negative (FN): 849\n",
      "Class 2:\n",
      "  True Positive (TP): 10056\n",
      "  False Positive (FP): 946\n",
      "  True Negative (TN): 30642\n",
      "  False Negative (FN): 603\n",
      "Class 3:\n",
      "  True Positive (TP): 10135\n",
      "  False Positive (FP): 799\n",
      "  True Negative (TN): 30887\n",
      "  False Negative (FN): 426\n",
      "Class 4:\n",
      "  True Positive (TP): 9493\n",
      "  False Positive (FP): 387\n",
      "  True Negative (TN): 31288\n",
      "  False Negative (FN): 1079\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load your dataset (adjust path and filename as needed)\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/HWhr3000/F21DL_Coursework_grp2/main/data/feature_selected_data.csv')\n",
    "\n",
    "# Print column names \n",
    "print(data.columns)\n",
    "\n",
    "# Use the target column after inspecting the column names\n",
    "X = data.drop('Loyalty', axis=1)  \n",
    "y = data['Loyalty']  \n",
    "\n",
    "y = y - 1\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model with Input layer\n",
    "model_with_dropout = Sequential()\n",
    "\n",
    "# Input layer\n",
    "model_with_dropout.add(Input(shape=(X_train.shape[1],)))  # Use Input layer\n",
    "\n",
    "# Hidden layers with Dropout\n",
    "model_with_dropout.add(Dense(64, activation='relu'))\n",
    "model_with_dropout.add(Dropout(0.2))  # Dropout rate of 20%\n",
    "\n",
    "model_with_dropout.add(Dense(64, activation='relu'))\n",
    "model_with_dropout.add(Dropout(0.2))  # Dropout rate of 20%\n",
    "\n",
    "model_with_dropout.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Output layer with softmax activation for multiclass classification\n",
    "model_with_dropout.add(Dense(4, activation='softmax'))  # 4 classes for ranks 1, 2, 3, 4\n",
    "\n",
    "# Compile the model\n",
    "model_with_dropout.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_with_dropout = model_with_dropout.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy_dropout = model_with_dropout.evaluate(X_train, y_train)\n",
    "test_accuracy_dropout = model_with_dropout.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Train Accuracy with Dropout: {train_accuracy_dropout[1]}\")\n",
    "print(f\"Test Accuracy with Dropout: {test_accuracy_dropout[1]}\")\n",
    "\n",
    "# Make predictions on the test data (output probabilities for each class)\n",
    "y_pred_proba = model_with_dropout.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class predictions (argmax gives index of highest probability)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Compute confusion matrix for multiclass classification\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Extract TP, FP, TN, FN for each class (0-3)\n",
    "for i in range(4):\n",
    "    TP = cm[i, i]\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    TN = cm.sum() - (TP + FP + FN)\n",
    "    \n",
    "    print(f\"Class {i+1}:\")\n",
    "    print(f\"  True Positive (TP): {TP}\")\n",
    "    print(f\"  False Positive (FP): {FP}\")\n",
    "    print(f\"  True Negative (TN): {TN}\")\n",
    "    print(f\"  False Negative (FN): {FN}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.3752 - val_accuracy: 0.9092 - val_loss: 0.2450\n",
      "Epoch 2/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2325 - val_accuracy: 0.9172 - val_loss: 0.2206\n",
      "Epoch 3/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.2124 - val_accuracy: 0.9233 - val_loss: 0.2037\n",
      "Epoch 4/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9245 - loss: 0.1991 - val_accuracy: 0.9209 - val_loss: 0.2122\n",
      "Epoch 5/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.1888 - val_accuracy: 0.9263 - val_loss: 0.1916\n",
      "Epoch 6/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.1838 - val_accuracy: 0.9282 - val_loss: 0.1900\n",
      "Epoch 7/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9321 - loss: 0.1793 - val_accuracy: 0.9303 - val_loss: 0.1843\n",
      "Epoch 8/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9337 - loss: 0.1751 - val_accuracy: 0.9306 - val_loss: 0.1810\n",
      "Epoch 9/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.1718 - val_accuracy: 0.9283 - val_loss: 0.1850\n",
      "Epoch 10/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9353 - loss: 0.1708 - val_accuracy: 0.9304 - val_loss: 0.1806\n",
      "Epoch 11/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.1687 - val_accuracy: 0.9325 - val_loss: 0.1788\n",
      "Epoch 12/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.1653 - val_accuracy: 0.9313 - val_loss: 0.1785\n",
      "Epoch 13/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.1630 - val_accuracy: 0.9315 - val_loss: 0.1798\n",
      "Epoch 14/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.1602 - val_accuracy: 0.9334 - val_loss: 0.1748\n",
      "Epoch 15/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.1583 - val_accuracy: 0.9327 - val_loss: 0.1773\n",
      "Epoch 16/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.1577 - val_accuracy: 0.9329 - val_loss: 0.1752\n",
      "Epoch 17/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.1560 - val_accuracy: 0.9325 - val_loss: 0.1750\n",
      "Epoch 18/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.1557 - val_accuracy: 0.9331 - val_loss: 0.1751\n",
      "Epoch 19/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.1531 - val_accuracy: 0.9337 - val_loss: 0.1711\n",
      "Epoch 20/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9420 - loss: 0.1519 - val_accuracy: 0.9311 - val_loss: 0.1734\n",
      "Epoch 21/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.1493 - val_accuracy: 0.9351 - val_loss: 0.1699\n",
      "Epoch 22/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.1501 - val_accuracy: 0.9334 - val_loss: 0.1738\n",
      "Epoch 23/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.1490 - val_accuracy: 0.9356 - val_loss: 0.1686\n",
      "Epoch 24/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.1462 - val_accuracy: 0.9354 - val_loss: 0.1694\n",
      "Epoch 25/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.1448 - val_accuracy: 0.9353 - val_loss: 0.1733\n",
      "Epoch 26/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.1454 - val_accuracy: 0.9350 - val_loss: 0.1689\n",
      "Epoch 27/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1441 - val_accuracy: 0.9348 - val_loss: 0.1695\n",
      "Epoch 28/100\n",
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9445 - loss: 0.1430 - val_accuracy: 0.9354 - val_loss: 0.1713\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Assuming y_train and y_test are your original labels\n",
    "y_train_onehot = to_categorical(y_train, num_classes=5)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "# Build the model with 5 output units for 5 classes\n",
    "model = Sequential()\n",
    "\n",
    "# Use Input layer instead of specifying input_dim in Dense\n",
    "model.add(Input(shape=(X_train.shape[1],)))  # Define the input shape here\n",
    "\n",
    "# Add hidden layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Output layer with 5 classes\n",
    "model.add(Dense(5, activation='softmax'))  \n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_onehot, validation_data=(X_test, y_test_onehot), epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5281/5281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step\n",
      "\u001b[1m1321/1321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "Train Metrics:\n",
      "Class 0: TP=39689, FP=2653, TN=123979, FN=2664\n",
      "Class 1: TP=39952, FP=2361, TN=124475, FN=2197\n",
      "Class 2: TP=40573, FP=2413, TN=124325, FN=1674\n",
      "Class 3: TP=39490, FP=1854, TN=124895, FN=2746\n",
      "\n",
      "Test Metrics:\n",
      "Class 0: TP=9661, FP=761, TN=31031, FN=794\n",
      "Class 1: TP=10010, FP=707, TN=30881, FN=649\n",
      "Class 2: TP=10090, FP=696, TN=30990, FN=471\n",
      "Class 3: TP=9767, FP=555, TN=31120, FN=805\n",
      "\n",
      "Train Accuracy: 0.9450779557228088\n",
      "Test Accuracy: 0.9356403946876526\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming the model has been trained already with code\n",
    "\n",
    "# Make predictions on the training and test set\n",
    "y_train_pred_proba = model.predict(X_train)\n",
    "y_test_pred_proba = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class predictions (argmax gives the index of the highest probability)\n",
    "y_train_pred = np.argmax(y_train_pred_proba, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred_proba, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels back to class labels\n",
    "y_train = np.argmax(y_train_onehot, axis=1)\n",
    "y_test = np.argmax(y_test_onehot, axis=1)\n",
    "\n",
    "# Compute confusion matrix for train and test data\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Extract TP, FP, TN, FN for each class in the train and test confusion matrices\n",
    "def extract_metrics(cm):\n",
    "    metrics = {}\n",
    "    for i in range(cm.shape[0]):\n",
    "        TP = cm[i, i]\n",
    "        FP = cm[:, i].sum() - TP\n",
    "        FN = cm[i, :].sum() - TP\n",
    "        TN = cm.sum() - (TP + FP + FN)\n",
    "        \n",
    "        metrics[i] = {\n",
    "            'TP': TP,\n",
    "            'FP': FP,\n",
    "            'TN': TN,\n",
    "            'FN': FN\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "# Extract metrics for train and test confusion matrices\n",
    "train_metrics = extract_metrics(cm_train)\n",
    "test_metrics = extract_metrics(cm_test)\n",
    "\n",
    "# Print train and test metrics\n",
    "print(\"Train Metrics:\")\n",
    "for class_label, metrics in train_metrics.items():\n",
    "    print(f\"Class {class_label}: TP={metrics['TP']}, FP={metrics['FP']}, TN={metrics['TN']}, FN={metrics['FN']}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "for class_label, metrics in test_metrics.items():\n",
    "    print(f\"Class {class_label}: TP={metrics['TP']}, FP={metrics['FP']}, TN={metrics['TN']}, FN={metrics['FN']}\")\n",
    "\n",
    "# Train and Test Accuracy\n",
    "train_accuracy = model.evaluate(X_train, y_train_onehot, verbose=0)[1]\n",
    "test_accuracy = model.evaluate(X_test, y_test_onehot, verbose=0)[1]\n",
    "\n",
    "print(f\"\\nTrain Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (F21DL)",
   "language": "python",
   "name": "f21dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
